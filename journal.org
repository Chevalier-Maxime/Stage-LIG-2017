# -*- mode: org -*-
# -*- coding: utf-8 -*-
#+STARTUP: overview indent inlineimages logdrawer
#+TITLE:       Journal de bord
#+AUTHOR:      Maxime Chevalier 
#+LANGUAGE:    fr
#+TAGS: LIG(L) SimGrid(S) PSI3(P) CODES(C) ROSS(O) Space(A) Time(T)
#+TAGS: R(R) OrgMode(M) Deprecated(D) DUMPI(U)
#+EXPORT_SELECT_TAGS: Blog
#+OPTIONS:   H:3 num:t toc:t \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+OPTIONS:   TeX:t LaTeX:nil skip:nil d:nil todo:t pri:nil tags:not-in-toc
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+COLUMNS: %25ITEM %TODO %3PRIORITY %TAGS
#+SEQ_TODO: TODO(t!) STARTED(s!) WAITING(w@) APPT(a!) | DONE(d!) CANCELLED(c!) DEFERRED(f!)

* 2016
** 2016-03 March
*** 2016-03-07 Monday
**** [[https://github.com/alegrand/RR_webinars/blob/master/1_replicable_article_laboratory_notebook/index.org][First webinar on reproducible research: litterate programming]]
***** Emacs shortcuts
Here are a few convenient emacs shortcuts for those that have never
used emacs. In all of the emacs shortcuts, =C=Ctrl=, =M=Alt/Esc= and
=S=Shift=.  Note that you may want to use two hours to follow the emacs
tutorial (=C-h t=). In the configuration file CUA keys have been
activated and allow you to use classical copy/paste (=C-c/C-v=)
shortcuts. This can be changed from the Options menu.
  - =C-x C-c= exit
  - =C-x C-s= save buffer
  - =C-g= panic mode ;) type this whenever you want to exit an awful
    series of shortcuts
  - =C-Space= start selection marker although selection with shift and
    arrows should work as well
  - =C-l= reposition the screen
  - =C-_= (or =C-z= if CUA keys have been activated)
  - =C-s= search
  - =M-%= replace
  - =C-x C-h= get the list of emacs shortcuts
  - =C-c C-h= get the list of emacs shortcuts considering the mode you are
    currently using (e.g., C, Lisp, org, ...)
  There are a bunch of cheatsheets also available out there (e.g.,
  [[http://www.shortcutworld.com/en/linux/Emacs_23.2.1.html][this one for emacs]] and [[http://orgmode.org/orgcard.txt][this one for org-mode]] or this [[http://sachachua.com/blog/wp-content/uploads/2013/05/How-to-Learn-Emacs-v2-Large.png][graphical one]]).
***** Org-mode                                                  :OrgMode:
  Many emacs shortcuts start by =C-x=. Org-mode's shortcuts generaly
  start with =C-c=.
  - =Tab= fold/unfold
  - =C-c c= capture (finish capturing with =C-c C-c=, this is explained on
    the top of the buffer that just opened)
  - =C-c C-c= do something useful here (tag, execute, ...)
  - =C-c C-o= open link
  - =C-c C-t= switch todo
  - =C-c C-e= export
  - =M-Enter= new item/section
  - =C-c a= agenda (try the =L= option)
  - =C-c C-a= attach files
  - =C-c C-d= set a deadl1ine (use =S-arrows= to navigate in the dates)
  - =A-arrows= move subtree (add shift for the whole subtree)
***** Org-mode Babel (for literate programming)                 :OrgMode:
  - =<s + tab= template for source bloc. You can easily adapt it to get this:
      : #+BEGIN_SRC sh
      : ls
      : #+END_SRC
    Now if you =C-c C-c=, it will execute the block.
    #+BEGIN_EXAMPLE
  #+RESULTS:
  | #journal.org# |
  | journal.html  |
  | journal.org   |
  | journal.org~  |
    #+END_EXAMPLE
  
  - Source blocks have many options (formatting, arguments, names,
    sessions,...), which is why I have my own shortcuts =<b + tab= bash
    block (or =B= for sessions).
    #+BEGIN_EXAMPLE 
  #+begin_src sh :results output :exports both
  ls /tmp/*201*.pdf
  #+end_src

  #+RESULTS:
  : /tmp/2015_02_bordeaux_otl_tutorial.pdf
  : /tmp/2015-ASPLOS.pdf
  : /tmp/2015-Europar-Threadmap.pdf
  : /tmp/europar2016-1.pdf
  : /tmp/europar2016.pdf
  : /tmp/M2-PDES-planning-examens-janvier2016.pdf
    #+END_EXAMPLE
  - I have defined many such templates in my configuration. You can
    give a try to =<r=, =<R=, =<RR=, =<g=, =<p=, =<P=, =<m= ...
  - Some of these templates are not specific to babel: e.g., =<h=, =<l=,
    =<L=, =<c=, =<e=, ...
***** In case you want to play with ipython on a recent debian   :Python:
Here is what you should install:
#+begin_src sh :results output :exports both
sudo apt-get install python3-pip ipython3 ipython3-notebook python3-numpy python3-matplotlib
#+end_src

The ipython notebook can then be run with the following command:
#+begin_src sh :results output :exports both
ipython3 notebook
#+end_src

The latest version of this notebook is called [[http://jupyter.org/][Jupyter]] and is polyglot
like babel. Playing with it is easy as it's deployed on the cloud but
as I'm not a python expert I'm not sure to know how to deploy it locally.
***** In case you want to play with R/knitR/rstudio:                  :R:
Here is what you should install on debian:
#+BEGIN_SRC sh
sudo apt-get install r-base r-cran-ggplot2
#+END_SRC

Rstudio and knitr are unfortunately not packaged within debian so the
easiest is to download the corresponding debian package on the [[http://www.rstudio.com/ide/download/desktop][Rstudio
webpage]] and then to install it manually (depending on when you do
this, you can obviously change the version number).
#+BEGIN_SRC sh
wget https://download1.rstudio.org/rstudio-0.99.887-amd64.deb
sudo dpkg -i rstudio-0.99.887-amd64.deb
sudo apt-get -f install # to fix possibly missing dependencies
#+END_SRC
You will also need to install knitr. To this end, you should simply
run R (or Rstudio) and use the following command.
#+BEGIN_SRC R
install.packages("knitr")
#+END_SRC
If =r-cran-ggplot2= could not be installed for some reason, you can also
install it through R by doing:
#+BEGIN_SRC R
install.packages("ggplot2")
#+END_SRC

As you will experience, knitr is polyglot but not Rstudio, which
makes its use not as fluid when using other languages than R.
* 2017
** 2017-05 mai
*** 2017-05-09 mardi
**** DONE Lecture papiers [3/3]                                   :ATTACH:
:PROPERTIES:
:Attachments: PDS_fujimoto2015.pdf
:ID:       a3acf95b-21d5-4621-a955-41bab99b38f6
:END:
- [X] simulation «[[file:Papiers/Timeparallelsimulation.pdf][temps parallèle]]» (extrait du livre de
      Fujimoto, 2000)
  - *Space parallel approch* : C'est la decomposition horizontale d'un
    programme, où chaque process maintient ses variables d'état tout au long de la simulation.
    - Plus flexible, et plus applicable (dans la plupart des cas).
  - *Time parallel approch* :
    - Propriétés : Parallélisme massif, indépendance des processeurs
      logiques (moins de synchronisation)
    - Approches : comment déterminer l'état initial des process (sauf le premier process), il faut corriger la trajectoire.
      - *Fix-up computation* : Etat initial random, qui ne match presque
        jamais, donc il faut faire une correction avec une seconde
        simulation (et ca fonctionne grâce à la contraction des
        ensembles de trajectoires) prenant en état initial l'état
        final du process précédant. Et quand ca match, c'est gagné!
        Fonction le mieux lorsque l'état final ne dépend pas de l'état
        initial (2 itérations et c'est fini). Lorsque ce n'est pas le
        cas, (pire cas) il faut pour N intervals, N itérations, soit
        du sequentiel avec des ressources pour du parallèle
        (bad!). *Exemple ou ca fonctionne* cache LRU.
      - *Precomputation of state at specific time division points* : Il
        se peut que dans certains programmes on puisse déterminer des
        points spécifiques (débordement de buffer par exemple) qui
        vont arriver et donc en faire des états de départ. *Exemple* :
        buffer avec N entrées de capacité 1 et une sortie de capacité C.
        - Soit il y a overflow
        - Soit il y a underflow
        - Du coup chaque processus détermine si il part d'un
          over/under et effectue sa simulation pour X services. Quand
          il a fini, il envoie le reste de sa file d'attente au
          processus d'après qui se charge de simuler l'interval entre
          l'état d'arrêt du processus précédent, et son postulat de départ.
        - À la fin, on peut calculer le nombre de service et de perte
          en additionnant les résultats de chaque processus.
        - Cependant ca pet échouer car les processus peuvent ne pas
          atteindre l'objectif (overflow souvent car c'est très
          rare). Il est donc très difficile d'identifier les points de division.
      - *Parallel prefix computations* :
        - Utilisation de récurence car il existe de très bon
          algorithmes pour faire du calcul prefix sur des systèmes parallèles.
        - Il faut faire attention au ratio nbCalculs/nbProcesseurs. En
          effet, si ce ratio tend vers 1, il y a des pertes à cause du
          temps de communication entre les processeurs (qui est du
          temps de calcul perdu).
        - /!\ Je n'ai pas compris l'exemple de cette partie (page 9 et 10).
    - Plutôt utilisé pour développer des algo de simulation parallèle
      spécifique.
    - Permet de parralléliser des cas où le space parralélisme ne
      fonctionne pas (ou peu), comme dans les exemples.
  - Dans certain cas, il est possible de mélanger les deux approches.

- [X] Et un [[file:Papiers/PDS_fujimoto2015.pdf][autre]] Fujimoto (2015) pour avoir une vision d’ensemble sur la
      simulation parallèle (sauf sur la technique «  temps-parallèle »  qui
      n’est pas mentionnée dans cet article)
  - Lecture :
    - *PDES* : Parallel Discrete Event Simulation. But : accelerer
      l'execution des simulation. Les "pas" de simulations sont
      irrégulier. Peut être vu comme une collection d'evenements
      sequentiels discret, qui interagissent par des messages
      datés. Un PDES doit fournir les mêmes résutats que le programme
      en séquentiel (ou parfois aproximativement les mêmes). Le
      principal problèlme c'est la synchrinisation entre les
      differents processus.

    - *Simulation distribué* : concerne l'execution de simulation sur
      des machines séparé "géographiquement", où l'agrégation de
      simulation pour un environnement de simulation (*exemple*
      simulateur de vol,...). Synchronisation = time management. De
      gros efforts ont été fait pour developer des standards
      d'interconnection de simulation (DIS,HLA) qui, entre autre
      réduisent le nombre de message envoyé.

    - *Synchronisation conservative* : Permet d'avoir le même résultat
      qu'une exécution séquentielle sur un processeur monocœur. Cette
      propriété peut être montré en s'assurant que chaque processus
      logique traite les messages par leurs dates.

      - Première génération : Pour qu'il y ait du parallèlisme, il
        faut cependant que certains LP (processus logique) puissent
        prendre de l'avance. Pour cela il faut s'assurer que l'on ne
        recevera pas d'event avec un horadatage plus petit que celui
        qu'on va executer (*ALGO CMB). *Contraintes* : réseau FIFO. Tant qu'il y a
        des messages dans les buffers le LP à l'information. Si le
        buffer est vide, il doit se bloquer /!\ il peut y avoir des
        interblocages. Pour les éviter les LPs envoient des messages
        nulls qui garantissent les horodatages. Les LP ont aussi un
        *lookahead* qui defini le temps min avant l'envoie d'un autre
        message (l'horadatage du prochain evenement doit être bien
        plus grand que le temps actuel). Cependant, si il est trop petit, de nombreux messages
        inutiles peuvent être envoyé si il y a blocage (cf exemple
        fin page 4).

      - Seconde génération : Dans un premiers temps, les nouveaux algo
        ont tenté de supprimer le problème de lookahead en utilisant
        le plus petit horadatage d'event dans le système, pour passer
        directement à la suite. D'autres approche complétement
        différentes de CMB ont été tenté, avec par exemple YAWNS qui
        utilise des points globaux de synchronisation (des
        barrières). *Schéma lookahead* question : Je suis pas sûr de
        comprendre comment ca marche... *Réponse* : SimGrid ne
        fonctionne pas sur ce modèle. C'est juste dire aux autres LPs
        que le LP ne va pas envoyer de message avant T+L, et qu'ils
        peuvent donc process jusque là.

    - *Synchronisation optimiste* : Les events ne sont plus éxécutés
      strictement dans l'ordre.(*TIME WARP*)contrairement aux algorithmes
      précédents, les erreurs sont possible, mais un mécanisme de
      rollback permet de retourner dans un état sain grâce à deu
      mécanismes :

      - *Mécanisme de control local* : Si un LP recoit un event daté de
        50 et qu'il en est à 100, il va faire un rollback
        jusqu'a 50. Cependant, si il y a eu modification des variables
        d'état, ou envoie de message ca ne peut pas être annulé. Pour
        les variables d'état il est possible de les sauvegarder avant
        modification (*copy state saving*) qui a un *cout* en temps de
        copie et en mémoire) ou faire de *l'incremental state saving*
        qui sauvegarder seulement les infos qu'on a modifié mais qui
        nécessite d'avoir les adresses des variables (à
        modifier/backup). Une autre technique est le *reverse
        computation* (si un event fait +1, on fait -1) qui est la plus
        avantageuse des 3, mais ca peut de
        pas être réalisable. Pour les messages, un système anti
        message récursif a été mis au point. On r'envoie le message
        identique avec un marqueur, si il a pasété traité, il est
        supprimé de la file, sinon il y a rollback pour le LP qui
        recoit l'anti-message (et ainsi de suite, pouvant conduire à
        des rollbacks en cascade /!\)

      - *Mécanisme de contrôle global* : GVT : Pas compris. C'est un
        état global, mais j'ai pas compris comment il est utilisé/ce
        qui est sauvegardé. Mécanisme de coupe comme vu en algo
        distribué (RICM4). Ok donc GVT c'est une barrière dans le
        temps avant laquelle on ne peut pas revenir lors d'un
        rollback. Du coup, il est possible de libérer les ressources
        utilisé pour sauvegarder les états avant cette barrière.
        https://www.acm-sigsim-mskr.org/Courseware/Fujimoto/Slides/FujimotoSlides-12-ComputingGlobalVirtualTime.pdf

        - D'autres pistes sont envisagées, comme limiter dans une
          fenêtre de temps les LPs (ce qui empêche certains LP d'être
          trop en avance et de faire beaucoup de rollback). Une autre
          technique et de retarder les envoies de messages jusqu'a ce
          que ce soit garantie que l'envoie ne va pas être rollback
          plus tard.

- [X] Les outils : 
  - [X] SimGrid un simulateur d’applications parallèles 
    http://simgrid.gforge.inria.fr (présentation générale http://simgrid.gforge.inria.fr/tutorials/simgrid-101.pdf)

    - SimDag : Framework pour application parralèles. Les tâches avec
      dépendances limitent la parralèlisme. On fourni à SimDag le
      graphe des tâches et ça retourne des informations sur les
      machines qui ont fait tels taches.

    - MPI : couche d'abstracton adapté à la programation parallèle
      (partie communication).

    - SMPI : Simule des application // avec MPI. Réalise le calcul
      pour de vrais en simulant l'architecture, mais en séquentiel. LE
      but c'est pas forcément le résultat, mais plutôt de voir si
      l'algorithme fonctionne bien sur l'architecture choisie.

    - MSG : Visualisation de données

    - Fonctionne comme en RO pour simuler les architechtures.

    - Permet plusieurs approches :

      - On-line : simulation sur sa propre machine. Mais /!\ à la
        topologie logique (grille par ex) qui est ensuite mappé sur
        une topologie physique différente. SimGrid peut également
        simuler cette différence.

      - Off-line : Execution du programme sur un super-calculateur
        puis récupération des traces. Avec ces trâces, rejouer avec
        des topologies différentes. Cependant cette approche nécéssite
        d'avoir accès à un super-calculateur, mais est limité pas la
        taille initiale de la topologie (on peut difficilement
        extrapoler). De plus, pour pouvoir jouer avec les trâce sur
        des configurations différentes, il faut que le code soit
        déterministe, hors il ne l'est pas nécessairement.

  - [X] PSi3 : Perfect simulator. S'arrête à la districbution
    stationnaire /!\ coût élevé
    - [X] un simulateur [développé par Inria] contenant une version
      parallèle « à la Fujimoto/Nicol » 
      https://gforge.inria.fr/projects/psi/ dédié aux files d'attentes
      réseaux (en temps discret). Le logiciel fournis des traces
      d'éxecution qui sont ensuite utilisable pour analyse (avec R par
      exemple). Ressemble beaucoup aux TD/DM de EP (les exemples).
    - [X]  [[file:Papiers/PDS_fujimoto2015.pdf][slides de présentation ci-joints (Briot/Vincent)]] Simulation
      de chaine de Markov, et utilisation des processus de vie et de
      mort. Le nombre d'etat doit être inferieur à 10⁷ pour les
      calculs numériques. Pour les simulations le cout est
      linéaire. Le but est de générer beaucoup d'exemples grâce un
      script de simulation pour ensuite les analyser. Psi3 permet de
      faire des statistiques sur les réseaux à file finie sur des
      évènements rare : rejet, blocage, ... avec la garantie
      d'indépendance entre les traces. La simulation utilises
      plusieurs coeurs (framework OpenMP cf RICM3). Il y a plusieurs
      approches pour la simulation :
      - Space //, Time // et les deux

      - Backward simulation : chaque coeur fait une trace.

      - Forward simulation *?? question*

      - Peret la //isation des entrées sorties.
  - [X] CODES : un simulateur [développé par Argonne] un simulateur
                parallèle d’applications parallèles
                https://press3.mcs.anl.gov/codes/ basé sur le
    framework ROSS. Ce simulateur a pour but d'augmenter la
    parallélisation sur du stackage de masse et pour les applications
    qui utilisent beaucoups de données. Dans le but de tester des
    architectures Exascale qui n'existe pas encore. Ca permet de tester des
    algorithmes avec une simulation de réseau faite par ROSS et des
    simulations d'I/O modélisé par CODE. Avec ce simulateur on peut
    mettre en évidence des goulots, évaluer la tolérance aux fautes,
    la mise à l'échelle et les techniques de
    "recovery". L'architechture TORUS (architecture réseau à plusieurs
    dimmentions) a été directement ajouté dans CODES et non dans
    ROSS. On peut donc ajouter nos propres modèles. Voici en
    attachement 2 articles présentant CODES
    -[X] [[file:Papiers/P1884.pdf][1]] 
    - 4.2 - Figure 3 : pas compris les résultats de l'expérience. 
    -[X] [[file:Papiers/LiuCarothers2012.pdf][2]] Possibilité de s'inspirer de ce papier pour la démarche sur
    des études
  - [X] ROSS :  simulateur parallèle, lui-même basé sur le
                mécanisme Time Warp 
                http://carothersc.github.io/ROSS/about.html . La
    simulation est basé sur des LPs, chacun modélisant un composant du
    système. Pour communiquer, les LPs utilisent des message horodaté.
                https://github.com/carothersc/ROSS. 
                
  - [X] Time Warp : Pour Time Warp il y a l’[[file:Papiers/Jefferson87.pdf][article]] de Jefferson et
                    al. qui résume à peu près. Utilisation d'un temps
    virtuel pour la synchronisation (Jefferson, cf Cours AD
    RICM4). Principe du rollback cité plus haut. Time Warp est à la
    base un OS, car le faire au dessus d'un autre OS n'ayant pas la
    même logique doublé tous les éléments (scheduling, I/O, ...). Time
    Warp est destiné aux applications utilisant un temps logique ou un
    temps de simulation dans leur modèle. La condition FIFO n'est plus
    nécessaire même si elle est préférable. Il y a régulierement des
    sauvegarde globales du système (de type GVT je suppose).
    - Anti-message : Comme vu plus haut, mais plus détailé. Chaque
      message envoyé engendre un anti-message dans le "buffer"
      d'emission qui n'est pas envoyé. Cependant, si il y a un
      rollback, le LP reprend son exécution et à chaque envoie de
      message, il compare avec les anti-message : si il y a un même
      message anti + nouveau, les deux sont supprimé (on a déjà envoyé
      le message), si il n'y a pas correspondance, un anti-message du
      nouveau est conservé. Tous les anti-message non représenté
      durant la réexecution doivent être annulé chez les autres
      LPs. Ensuite c'est l'algo en cascade.

    - La communication entre les processus ne se fait pas via des
      pipe,... il n'est donc pas nécéssaire de déclarer quel process
      communique avec quel process. Il suffi de faire un
      send. Question : != entre QueryMessage et EventMessage

    - Structure d'un process : cf page 10

    - Les processus s'executent qu'a la réception de message et font
      le traitement, ils ne font pas de calcul en dehors. Ils peuvent
      cependant s'envoyer eux-même des messages. Les processus doivent
      être deterministe (l'execution d'une même entrée doit donner la
      même sortie pour eviter les rollback en cascade. Pour les nombre
      aléa jouer avec la seed).

    - Utilisation de beaucoup de mémoire pour le GVT et pour la
      sauvegarde des anti-messages. Si il y a plus de place, le plus
      grand message (T dans le système, le plus loin dans le futur) est désenvoyé ce qui cause un rollback quelque
      part et donc libère de la place. Le méssage sera réenvoyé plus tard.

  - [X] Slide d'Arnaud sur les infrastructures de calcul :
   http://mescal.imag.fr/membres/arnaud.legrand/blog/2015/03/25/intervention_isn-gz.pdf
    - Tentative de mélanger les calculs et les communication pour
      réduire les barrières (MUMPS)

    - Explication simple d'un calcul de pivot sur une matrice
      diagonale.



**** Réunion Maxime Chevalier, simulation parallèle
- Lu chapitre simulation time // de Fujimoto
- A lu papier sur SG, PSI, CODES/ROSS (torus)
- A commencé à intégrer les notions de simulation time //, space //,
  simulation parfaite, simulation de Monte Carlo, à évènements
  discrets (pas forcément de chaine de Markov).
- À faire:
  - Journal:
    - Créer un repos github privé et nous donner les droits
      (alegrand, fperronnin).
    - On vérifie la config org-mode
  - Simulation:
    - Installer CODES/ROSS
    - Récupérer une trace de HPL (générée "en vrai" ou avec SimGrid)
    - Rejouer cette trace au dessus de CODES en séquentiel
    - Rejouer cette trace au dessus de SimGrid (en séquentiel donc)
    - Rejouer cette trace au dessus de CODES en multi-core
    - Rejouer cette trace au dessus de CODES en distribué (MPI)
    - Puis on avise pour le time //
**** Premiers pas avec org-mode
#+begin_src sh :results output :exports both
ls /tmp/
#+end_src

#+RESULTS:
: babel-58401Ra
: babel-8460yua
: emacs8460hfp
: systemd-private-309cd01bea0a4d7cbb3d3706e339b36a-colord.service-6SHoQ5
: systemd-private-309cd01bea0a4d7cbb3d3706e339b36a-rtkit-daemon.service-DraqAW
: tracker-extract-files.1000

#+begin_src python :results output :exports both
print("Hello")
#+end_src

#+RESULTS:
: Hello

#+begin_src R :results output :session *R* :exports both
summary(cars)
#+end_src

#+BEGIN_EXAMPLE
This seminar took place on March 7, 2016. The link to the video is below. Do not forget to check the section on software installation if you want to test yourself the demoed tools.

Table of Contents
#+END_EXAMPLE

**** Réunion avec Florence et Arnaud
***** DONE Mettre en place mon cahier de laboratoire [3/3]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-05-09 mar. 15:05]
- State "TODO"       from "TODO"       [2017-05-09 mar. 15:05]
- State "TODO"       from "TODO"       [2017-05-09 mar. 13:54]
- State "TODO"       from "STARTED"    [2017-05-09 mar. 13:54]
- State "STARTED"    from "TODO"       [2017-05-09 mar. 13:52]
- State "TODO"       from              [2017-05-09 mar. 13:52]
:END:

- [X] github
- [X] org-mode
- [X] intégrer le mail

Entered on [2017-05-09 mar. 13:45]
******
*** 2017-05-11 jeudi
**** Fin des lectures
**** Installation CODES/ROSS sur ma machine
***** DEFERRED ROSS                                                :ROSS:
:LOGBOOK:
- State "DEFERRED"   from              [2017-05-15 lun. 13:35]
- State "DEFERRED"   from "CANCELLED"  [2017-05-15 lun. 13:35]
- State "CANCELLED"  from "DONE"       [2017-05-15 lun. 13:35]
- State "DONE"       from "APPT"       [2017-05-15 lun. 13:35]
- State "APPT"       from "WAITING"    [2017-05-15 lun. 13:35]
- State "STARTED"    from "TODO"       [2017-05-11 jeu. 17:51]
- State "TODO"       from              [2017-05-11 jeu. 17:51]
:END:
Lien Git : https://github.com/carothersc/ROSS
Requirement  : 
- C compiler (C11 prefered but not required)
- CMake : https://cmake.org (2.8 min) -> 3.6.2
#+begin_src sh
sudo yum install cmake
#+end_src
- Implémentation MPI : MPICH recommandé -> 3.2
#+begin_src sh
sudo yum install mpich
#+end_src
Machine : Fedora 25, gcc version 6.3.1, intel core i5, 8Go de RAM
****** Tentative installation 1
Ca ne fonctionne pas en suivant les étapes du git, je supprime le
dossier et je passe par un autre tuto.
****** Tentative d'installation 2
https://github.com/carothersc/ROSS/wiki/Installation
En fait j'ai une erreur dans la configuration de cmake...
#+BEGIN_EXAMPLE
CMake Error at /usr/share/cmake/Modules/CMakeDetermineCCompiler.cmake:57 (message):
  Could not find compiler set in environment variable CC:

  mpicc.
Call Stack (most recent call first):
  CMakeLists.txt:1 (PROJECT)


CMake Error: CMAKE_C_COMPILER not set, after EnableLanguage
-- Configuring incomplete, errors occurred!
See also "/home/chevamax/Documents/ross-build/CMakeFiles/CMakeOutput.log".
#+END_EXAMPLE

(lundi 15 mai)
En fait mpich n'était pas dans mon PATH...
On retante.
Ca ne marche toujours pas, mais je viens de
trouver. https://ask.fedoraproject.org/en/question/32864/mpirun-command-not-found/
Il faut charger le module pour pouvoir l'utiliser. Du coup il faut
ajouter cette ligne au fichier de conf : 

#+BEGIN_EXAMPLE
module load mpi/mpich-x86_64 
#+END_EXAMPLE

#+begin_src
cd
gedit .bash_profile
#+end_src

J'y ai cru mais en fait non...

*** 2017-05-15 lundi
**** DONE ROSS                                                      :ROSS:
:LOGBOOK:
- State "DONE"       from ""       [2017-05-15 lun. 14:35]
:END:
***** intallation                                            :Deprecated:
CF CODES pour l'instalation
Reprise de l'installation, sur un nouvel environnement, Ubuntu cette
foi-ci (17.04)
On repart du début.
https://github.com/carothersc/ROSS
Version gcc : 6.3.0 20170406
Version cmake : 3.7.2-1
Version MPICH : 3.2-7
Version Doxygen 1.8.13

C'est bon tout fonctionne !
#+BEGIN_EXAMPLE
git clone -b master --single-branch git@github.com:carothersc/ROSS.git
mkdir ROSS-build
cd ROSS-build
export ARCH=x86_64
export CC=mpicc
cmake -DROSS_BUILD_MODELS=ON ../ROSS
make
make test
#+END_EXAMPLE

Avec ces commandes, on peut tester si tout fonctionne bien (car on a
des modèles et des tests). Si tout passe c'est OK. Merci ubuntu.

**** DONE CODES                                                    :CODES:
:LOGBOOK:
- State "DONE"       from "APPT"       [2017-05-15 lun. 17:17]
- State "APPT"       from "WAITING"    [2017-05-15 lun. 17:17]
- State "STARTED"    from "TODO"       [2017-05-15 lun. 17:17]
- State "TODO"       from              [2017-05-11 jeu. 17:51]
:END:
Sources : https://press3.mcs.anl.gov/codes/downloads/
Version : 0.5.2
Entered on [2017-05-15 lun. 09:34]
Mainenant que ROSS a l'air de fonctionner on passe à CODES.

En fait pour installer les deux il suffi de suivre les consignes dans
le fichier d'installation de CODES.
/!\ insallation dumpi
**** Traces HPL
Maintenant que tout est installé et que je commence à comprendre, il
faut se diriger vers le premier objectif.
Je lis donc la doc GETTING STARTED, pour comprendre comment se compose
le logiciel, et avoir un point d'entrée.
***** Meeting avec Florence
CODES utilise DUMPI pour les traces. Il faut donc que je génère des
trâces avec mon PC grace à un logiciel HPL en MPI, que je pourrais
réinjecter. On tente de voir Arnaud demain.
*** 2017-05-16 mardi
**** DONE DUMPI
http://sst.sandia.gov/about_dumpi.html
J'ai l'impression qu'il faut installer tout le simulateur(SST) pour pouvoir
profiter de DUMPI. Cependant ils parlent le package, alors c'est peut
être un standalone 
profiter de DUMPI. 
**** Meeting avec Florence et Arnaud
- Les sources de DUMPI sont en fait sur [[https://github.com/sstsimulator/sst-dumpi][github]].
- D'après la [[https://github.com/sstsimulator/sst-dumpi/blob/master/docs/traceformat.dox][documentation]], c'est un format binaire et je ne suis pas
  sûr qu'il y ait moyen de générer de telles traces sans passer par
  leur bibliothèque. Si on veut de grosses traces (pour donner à
  manger à CODES), ça va être compliqué. Il aurait été pratique de les
  obtenir avec SimGrid (et le travail de Tom) mais il faudrait que
  SimGrid puisse générer du DUMPI.
- Après discussion rapide avec Lucas Schnorr, il est possible que
  DUMPI fonctionne avec SMPI puisque SMPI implémente PMPI sur lequel
  DUMPI se branche. Lucas avait réussi avec akypuera
  (http://github.com/schnorr/akypuera). On verra plus tard de toutes
  façons, il faut commencer par une petite trace.
- On n'a aucune idée de comment visualiser ou analyser les traces
  DUMPI. Je ne sais pas comment les convertir vers un autre
  format. Une possibilité serait de passer par [[https://github.com/hkustliqi/DUMPI_parser][ce parseur]] mais ça
  reste un pari.
- Il existe deux types de trâces, profiling (info de bases) ou une
  trâce complète (avec des outils comme DUMPI, EXTRAE, TAU/SCALASCA,
  OTF2 (format vers lequel tout le monde tend mais encore incomplet),
  POTI, ...
- DUMPI fait parti du projet SST, qui rassemble plusieurs projets
  - SST-MACRO : ressemble à SimGrid mais fonctionne en C++, et a des
    contraintes différentes. Il est encore en activité.
  - SST-Micro : pour simuler des tous petits systèmes de manière très
    détaillée.

À faire (sur ta machine pour commencer):
- Lancer HPL avec 12 processus (par exemple) et une matrice de taille
  20,000. Ne pas hésiter à aller voir Tom ou Christian si tu veux un
  fichier d'entrée pour HPL qui correspond à ceci.
- Suivre les informations de traçage de DUMPI (probablement à base de
  =LD_PRELOAD= et de =-ldumpi=) pour tracer HPL.
- Essayer de la rejouer sur ROSS.
**** Instalation DUMPI                                        :Deprecated:
Après le clonage du repo, il faut s'assurer d'avoir les bons outils :
- libtool
- m4
- automake
- autoconf
Une foi dans le dossier, il faut faire les commandes suivantes :
#+begin_src sh
./bootstrap.sh
mkdir build
cd build
../configure --enable-libdumpi --enable-test --prefix=$HOME/dumpi_inst CC=mpicc CXX=mpiCC
make
make install
make doc
#+end_src
J'ai cependant un problème, de nombreuses erreurs surviennent. En
effet, les signatures entre les .h de mpi et l'implémentation de DUMPI
diffèrent. Je vais donc voir si je dois prendre une version moins
récente de MPICH.
*** 2017-05-17 mercredi
**** DONE Installation de DUMPI/CODES                              :CODES:
En reregardant la doc de CODES, il y a justement un avertissement sur
DUMPI. 
"To enable network tracing with dumpi
    (http://sst.sandia.gov/about_dumpi.html), use the option
    --with-dumpi=/path/to/dumpi/install with configure.

    NOTE: we only require libundumpi for trace processing. Hence, if building
    dumpi from source you may configure with --disable-libdumpi and
    --enable-libundumpi (this is especially useful if you have mpich3, which
    breaks libdumpi's function wrappers through const'ifying the MPI
    interface)."

Du coup pour l'installation ca donne ca :
#+begin_src sh
./bootstrap.sh
mkdir build
cd build
../configure --disable-libdumpi --enable-libundumpi --prefix=/home/chevamax/Documents/Stage_LIG_2017/sst-dumpi/dumpi_inst CC=mpicc CXX=mpiCC
make
make install
make doc
#+end_src
EDIT : il faut ensuite ajouter le chemin vers ~/dumpi-inst/lib dans le
fichier /etc/ld.so.conf et faire un ldconfig

Du coup il faut que je réinstalle CODES avec les le chemin vers dumpi.

#+begin_src sh
./prepare.sh
mkdir build
cd build
apt-get install flex
apt-get install bison
apt-get install pkg-config
../configure --with-dumpi=/home/chevamax/Documents/Stage_LIG_2017/sst-dumpi/dumpi_inst --prefix=/home/chevamax/Documents/Stage_LIG_2017/CODES/install CC=mpicc PKG_CONFIG_PATH=../../ROSS/install/lib/pkgconfig
make && make install
make tests && make check
#+end_src

Maintenant les tests ne passent plus ...
#+BEGIN_EXAMPLE
tests/workload/codes-workload-test: error while loading shared libraries: libundumpi.so.3: cannot open shared object file: No such file or directory
FAIL tests/workload/codes-workload-test.sh (exit status: 127)
#+END_EXAMPLE

J'ai du louper une étape.
En cherchant sur internet j'ai vu qu'on pouvait ajouter des librairies
dans le fichier /etc/ld.so.conf En ajoutant le chemin vers la
librairie dumpi ca fonctionne.

**** Installation de HPL
lien : http://www.netlib.org/benchmark/hpl/software.html
inspiration de : [[https://www.howtoforge.com/tutorial/hpl-high-performance-linpack-benchmark-raspberry-pi/][installation raspberry pi]] [[http://www.crc.nd.edu/~rich/CRC_Summer_Scholars_2014/HPL-HowTo.pdf][How to sur cluster]]

#+begin_src sh
sudo apt-get install libatlas-base-dev libmpich2-dev gfortran
#+end_src

le paquet libmpich2-dev n'existe plus dans les repos, j'ai donc pris
libmpich-dev qui la remplace (il y a cependant une version :i386 qui
existe, je sais pas si elle optimise certain processeurs).

MPdir = /usr/lib/mpich

En suivant le tuto pour raspberry pi, j'ai un problème (surement de
configuration). Voici la trace de l'erreur pour la partie 4 du tuto :

#+BEGIN_EXAMPLE
make[2] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/hpl-2.2/testing/ptest/linux »
mpif77  -o /home/chevamax/Documents/Stage_LIG_2017/hpl-2.2/bin/linux/xhpl HPL_pddriver.o         HPL_pdinfo.o           HPL_pdtest.o /home/chevamax/Documents/Stage_LIG_2017/hpl-2.2/lib/linux/libhpl.a  /usr/lib/atlas-base/libf77blas.a /usr/lib/atlas-base/libatlas.a -lblas /usr/lib/mpich/lib/libmpich.a
/usr/lib/mpich/lib/libmpich.a(lib_libmpich_la-initthread.o) : Dans la fonction « MPIR_Init_thread » :
(.text+0xb8) : référence indéfinie vers « pthread_mutexattr_init »
/usr/lib/mpich/lib/libmpich.a(lib_libmpich_la-initthread.o) : Dans la
fonction « MPIR_Init_thread » :
#+END_EXAMPLE

En ajoutant -pthread dans les flag on arrive à compiler.

Maintenant nouveau problème : 
#+Begin_Example
mpif77 -pthread -o /home/chevamax/Documents/Stage_LIG_2017/hpl-2.2/bin/linux/xhpl HPL_pddriver.o         HPL_pdinfo.o           HPL_pdtest.o /home/chevamax/Documents/Stage_LIG_2017/hpl-2.2/lib/linux/libhpl.a  /usr/lib/atlas-base/libf77blas.a /usr/lib/atlas-base/libatlas.a -lblas /usr/lib/mpich/lib/libmpich.a
/usr/lib/mpich/lib/libmpich.a(lib_libmpich_la-mpid_nem_ckpt.o) : Dans la fonction « ckpt_cb » :
(.text+0x342) : référence indéfinie vers « cr_checkpoint »
/usr/lib/mpich/lib/libmpich.a(lib_libmpich_la-mpid_nem_ckpt.o) : Dans la fonction « ckpt_cb » :
(.text+0x3e3) : référence indéfinie vers « cr_get_restart_info »
/usr/lib/mpich/lib/libmpich.a(lib_libmpich_la-mpid_nem_ckpt.o) : Dans la fonction « MPIDI_nem_ckpt_init » :
(.text+0xca5) : référence indéfinie vers « cr_init »
#+END_EXAMPLE

Je sais pas du tout qu'est ce qui manque. Est-ce que ça a un lien avec
BLCR ? Si oui il va falloir que je me lance dans l'installation.

*** 2017-05-18 jeudi

**** Mail Arnaud

1. Quand tu indiques "J'ai cependant un problème, de nombreuses
   erreurs surviennent. En effet, les signatures entre les .h de mpi
   et l'implémentation de DUMPI diffèrent. Je vais donc voir si je
   dois prendre une version moins récente de MPICH." Ça vaut le coup
   que tu indiques les erreurs (au moins les premières) dans une
   balise #+BEGIN_EXAMPLE   #+END_EXAMPLE
2. À propos de
   #+BEGIN_EXAMPLE
   tests/workload/codes-workload-test: error while loading shared
libraries: libundumpi.so.3:
   cannot open shared object file: No such file or directory FAIL
tests/workload/codes-workload-test.sh (exit status: 127)
   #+END_EXAMPLE
   Mettons que tu ais installé DUMPI dans /home/maxime/toto/lib (i.e.,
   le libundumpi.so est dans ce répertoire là).
   #+BEGIN_EXAMPLE
   export LD_LIBRARY_PATH=/home/maxime/toto/lib:$LD_LIBRARY_PATH
   #+END_EXAMPLE
   Ça devrait permettre au linker de trouver la bibliothèque. Modifier
   /etc/ld/so.conf me parait une mauvaise idée...
3. "Est-ce que ça a un lien avec BLCR ?" Ouh là, non, tu n'as pas
   besoin de ça. C'est une librairie de checkpoint qui permet de
   redémarer le code même quand on perd un noeud. Je ne sais pas d'où
   ça sort c'est anormal, tu ne devrais pas en avoir besoin.

**** Reprise installation HPL
En regardant sur internet, je vois que les fonctions font parties d'un
package blcr-util. Je tente donc de l'installer pour voir.
Effectivement ca ne résoud pas le soucis...
Et mpiexec prend en charge bclr c'est étrange.

***** Tentative d'installation sur une machine virtuelle
Je vais tenter d'installer HPL sur un linux vierge, pour voir si il
n'y a pas conflit avec autre chose de déjà installé.
J'ai exactement la même erreure...

Après plusieurs tests de configurations trouvé sur plusieurs tuto,
j'en ai finalement trouvé un qui fonctionne ! (sur la machine
virtuelle pour le moment). [[http://jahanzebnotes.blogspot.fr/2013/06/how-to-run-hpl-benchmark-with-atlas.html][lien]]

*** 2017-05-19 vendredi

**** Changement des paramètres sur ma machine
#+BEGIN_EXAMPLE
#  
#  -- High Performance Computing Linpack Benchmark (HPL)                
#     HPL - 2.2 - February 24, 2016                          
#     Antoine P. Petitet                                                
#     University of Tennessee, Knoxville                                
#     Innovative Computing Laboratory                                 
#     (C) Copyright 2000-2008 All Rights Reserved                       
#                                                                       
#  -- Copyright notice and Licensing terms:                             
#                                                                       
#  Redistribution  and  use in  source and binary forms, with or without
#  modification, are  permitted provided  that the following  conditions
#  are met:                                                             
#                                                                       
#  1. Redistributions  of  source  code  must retain the above copyright
#  notice, this list of conditions and the following disclaimer.        
#                                                                       
#  2. Redistributions in binary form must reproduce  the above copyright
#  notice, this list of conditions,  and the following disclaimer in the
#  documentation and/or other materials provided with the distribution. 
#                                                                       
#  3. All  advertising  materials  mentioning  features  or  use of this
#  software must display the following acknowledgement:                 
#  This  product  includes  software  developed  at  the  University  of
#  Tennessee, Knoxville, Innovative Computing Laboratory.             
#                                                                       
#  4. The name of the  University,  the name of the  Laboratory,  or the
#  names  of  its  contributors  may  not  be used to endorse or promote
#  products  derived   from   this  software  without  specific  written
#  permission.                                                          
#                                                                       
#  -- Disclaimer:                                                       
#                                                                       
#  THIS  SOFTWARE  IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
#  ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES,  INCLUDING,  BUT NOT
#  LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
#  A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE UNIVERSITY
#  OR  CONTRIBUTORS  BE  LIABLE FOR ANY  DIRECT,  INDIRECT,  INCIDENTAL,
#  SPECIAL,  EXEMPLARY,  OR  CONSEQUENTIAL DAMAGES  (INCLUDING,  BUT NOT
#  LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
#  DATA OR PROFITS; OR BUSINESS INTERRUPTION)  HOWEVER CAUSED AND ON ANY
#  THEORY OF LIABILITY, WHETHER IN CONTRACT,  STRICT LIABILITY,  OR TORT
#  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
#  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. 
# ######################################################################
#  
# ----------------------------------------------------------------------
# - shell --------------------------------------------------------------
# ----------------------------------------------------------------------
#
SHELL        = /bin/sh
#
CD           = cd
CP           = cp
LN_S         = ln -s
MKDIR        = mkdir
RM           = /bin/rm -f
TOUCH        = touch
#
# ----------------------------------------------------------------------
# - Platform identifier ------------------------------------------------
# ----------------------------------------------------------------------
#
ARCH         = linux
#
# ----------------------------------------------------------------------
# - HPL Directory Structure / HPL library ------------------------------
# ----------------------------------------------------------------------
#
TOPdir       = $(HOME)/Documents/Stage_LIG_2017/hpl
INCdir       = $(TOPdir)/include
BINdir       = $(TOPdir)/bin/$(ARCH)
LIBdir       = $(TOPdir)/lib/$(ARCH)
#
HPLlib       = $(LIBdir)/libhpl.a 
#
# ----------------------------------------------------------------------
# - Message Passing library (MPI) --------------------------------------
# ----------------------------------------------------------------------
# MPinc tells the  C  compiler where to find the Message Passing library
# header files,  MPlib  is defined  to be the name of  the library to be 
# used. The variable MPdir is only used for defining MPinc and MPlib.
#
MPdir        = /usr/lib/mpich
MPinc        = -I $(MPdir)/include
MPlib        = -L $(MPdir)/lib
#
# ----------------------------------------------------------------------
# - Linear Algebra library (BLAS or VSIPL) -----------------------------
# ----------------------------------------------------------------------
# LAinc tells the  C  compiler where to find the Linear Algebra  library
# header files,  LAlib  is defined  to be the name of  the library to be 
# used. The variable LAdir is only used for defining LAinc and LAlib.
#
LAdir        = /usr/lib/atlas-base
LAinc        = 
LAlib        = $(LAdir)/libf77blas.a $(LAdir)/libatlas.a -lblas
#
# ----------------------------------------------------------------------
# - F77 / C interface --------------------------------------------------
# ----------------------------------------------------------------------
# You can skip this section  if and only if  you are not planning to use
# a  BLAS  library featuring a Fortran 77 interface.  Otherwise,  it  is
# necessary  to  fill out the  F2CDEFS  variable  with  the  appropriate
# options.  **One and only one**  option should be chosen in **each** of
# the 3 following categories:
#
# 1) name space (How C calls a Fortran 77 routine)
#
# -DAdd_              : all lower case and a suffixed underscore  (Suns,
#                       Intel, ...),                           [default]
# -DNoChange          : all lower case (IBM RS6000),
# -DUpCase            : all upper case (Cray),
# -DAdd__             : the FORTRAN compiler in use is f2c.
#
# 2) C and Fortran 77 integer mapping
#
# -DF77_INTEGER=int   : Fortran 77 INTEGER is a C int,         [default]
# -DF77_INTEGER=long  : Fortran 77 INTEGER is a C long,
# -DF77_INTEGER=short : Fortran 77 INTEGER is a C short.
#
# 3) Fortran 77 string handling
#
# -DStringSunStyle    : The string address is passed at the string loca-
#                       tion on the stack, and the string length is then
#                       passed as  an  F77_INTEGER  after  all  explicit
#                       stack arguments,                       [default]
# -DStringStructPtr   : The address  of  a  structure  is  passed  by  a
#                       Fortran 77  string,  and the structure is of the
#                       form: struct {char *cp; F77_INTEGER len;},
# -DStringStructVal   : A structure is passed by value for each  Fortran
#                       77 string,  and  the  structure is  of the form:
#                       struct {char *cp; F77_INTEGER len;},
# -DStringCrayStyle   : Special option for  Cray  machines,  which  uses
#                       Cray  fcd  (fortran  character  descriptor)  for
#                       interoperation.
#
F2CDEFS      = -DAdd_ -DF77_INTEGER=int -DStringSunStyle
#
# ----------------------------------------------------------------------
# - HPL includes / libraries / specifics -------------------------------
# ----------------------------------------------------------------------
#
HPL_INCLUDES = -I$(INCdir) -I$(INCdir)/$(ARCH) $(LAinc) $(MPinc)
HPL_LIBS     = $(HPLlib) $(LAlib) $(MPlib) -lmpl
#
# - Compile time options -----------------------------------------------
#
# -DHPL_COPY_L           force the copy of the panel L before bcast;
# -DHPL_CALL_CBLAS       call the cblas interface;
# -DHPL_CALL_VSIPL       call the vsip  library;
# -DHPL_DETAILED_TIMING  enable detailed timers;
#
# By default HPL will:
#    *) not copy L before broadcast,
#    *) call the BLAS Fortran 77 interface,
#    *) not display detailed timing information.
#
HPL_OPTS     = -DHPL_CALL_CBLAS
# 
# ----------------------------------------------------------------------
#
HPL_DEFS     = $(F2CDEFS) $(HPL_OPTS) $(HPL_INCLUDES) 
#
# ----------------------------------------------------------------------
# - Compilers / linkers - Optimization flags ---------------------------
# ----------------------------------------------------------------------
#
CC           = /usr/bin/mpicc
CCNOOPT      = $(HPL_DEFS) 
CCFLAGS      = $(HPL_DEFS) -fomit-frame-pointer -O3 -funroll-loops
#
LINKER       = /usr/bin/mpicc
LINKFLAGS    = $(CCFLAGS) -pthread
#
ARCHIVER     = ar
ARFLAGS      = r
RANLIB       = echo
#
# ----------------------------------------------------------------------
#+END_EXAMPLE

Le soucis avait l'air de se trouver dans la configuration de LPlib. En
effet, dans tous les exemple vu c'était de la sorte :
~$(MPdir)/lib/libmpich.a~ hors en le changeant en ~MPlib= -L $(MPdir)/lib~
l'erreur disparait et le programme tourne.

**** Lancement de HPL
Je vais utiliser ce [[http://www.advancedclustering.com/act_kb/tune-hpl-dat-file/][site]] pour m'aider à faire les paramètres sur
ma machine.

***** Premier test
Pour voir si tout fonctionne je fais sur un seul thread.

****** HPL.dat
#+begin_example
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
14208        Ns
1            # of NBs
192          NBs
0            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
2            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
1            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM)
1            # of lookahead depth
1            DEPTHs (>=0)
2            SWAP (0=bin-exch,1=long,2=mix)
64           swapping threshold
0            L1 in (0=transposed,1=no-transposed) form
0            U  in (0=transposed,1=no-transposed) form
1            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
#+end_example

avec la sortie suivante :
#+begin_example
================================================================================
T/V                N    NB     P     Q               Time                 Gflops
--------------------------------------------------------------------------------
WR11C2R4       14208   192     1     1             201.68              9.482e+00
HPL_pdgesv() start time Fri May 19 10:17:35 2017

HPL_pdgesv() end time   Fri May 19 10:20:57 2017

--------------------------------------------------------------------------------
||Ax-b||_oo/(eps*(||A||_oo*||x||_oo+||b||_oo)*N)=        0.0018179 ...... PASSED
================================================================================

Finished      1 tests with the following results:
              1 tests completed and passed residual checks,
              0 tests completed and failed residual checks,
              0 tests skipped because of illegal input values.
--------------------------------------------------------------------------------

End of Tests.
================================================================================
#+end_example

***** Second test

#+begin_src sh :results output :exports both
lscpu
#+end_src

#+RESULTS:
#+begin_example
Architecture:          x86_64
Mode(s) opératoire(s) des processeurs :32-bit, 64-bit
Byte Order:            Little Endian
CPU(s):                4
On-line CPU(s) list:   0-3
Thread(s) par cœur : 2
Cœur(s) par socket : 2
Socket(s):             1
Nœud(s) NUMA :       1
Identifiant constructeur :GenuineIntel
Famille de processeur :6
Modèle :             69
Model name:            Intel(R) Core(TM) i5-4210U CPU @ 1.70GHz
Révision :           1
Vitesse du processeur en MHz :1853.613
CPU max MHz:           2700,0000
CPU min MHz:           800,0000
BogoMIPS:              4789.03
Virtualisation :      VT-x
Cache L1d :           32K
Cache L1i :           32K
Cache L2 :            256K
Cache L3 :            3072K
NUMA node0 CPU(s):     0-3
Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt dtherm ida arat pln pts
#+end_example

J'ai donc un socket, avec deux coeurs et 2 threads par coeurs. Je
pense donc pouvoir faire peut être du 2x2

J'ai 8Go de RAM. Ils conseillent d'en alouer au maximum 80% (le reste
pour l'OS &co).

Je vais donc faire le test avec ce fichier :
#+BEGIN_EXAMPLE
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any) 
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
18048         Ns
1            # of NBs
192           NBs
0            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
2            Ps
2            Qs
16.0         threshold
1            # of panel fact
2            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
1            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM)
1            # of lookahead depth
1            DEPTHs (>=0)
2            SWAP (0=bin-exch,1=long,2=mix)
64           swapping threshold
0            L1 in (0=transposed,1=no-transposed) form
0            U  in (0=transposed,1=no-transposed) form
1            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
#+END_EXAMPLE

#+begin_src sh :results output :exports both
mpiexec -n 4 ./xhpl 
#+end_src

#+RESULTS:
#+BEGIN_EXAMPLE
================================================================================
HPLinpack 2.2  --  High-Performance Linpack benchmark  --   February 24, 2016
Written by A. Petitet and R. Clint Whaley,  Innovative Computing Laboratory, UTK
Modified by Piotr Luszczek, Innovative Computing Laboratory, UTK
Modified by Julien Langou, University of Colorado Denver
================================================================================

An explanation of the input/output parameters follows:
T/V    : Wall time / encoded variant.
N      : The order of the coefficient matrix A.
NB     : The partitioning blocking factor.
P      : The number of process rows.
Q      : The number of process columns.
Time   : Time in seconds to solve the linear system.
Gflops : Rate of execution for solving the linear system.

The following parameter values will be used:

N      :   18048 
NB     :     192 
PMAP   : Row-major process mapping
P      :       2 
Q      :       2 
PFACT  :   Right 
NBMIN  :       4 
NDIV   :       2 
RFACT  :   Crout 
BCAST  :  1ringM 
DEPTH  :       1 
SWAP   : Mix (threshold = 64)
L1     : transposed form
U      : transposed form
EQUIL  : yes
ALIGN  : 8 double precision words

--------------------------------------------------------------------------------

- The matrix A is randomly generated for each test.
- The following scaled residual check will be computed:
      ||Ax-b||_oo / ( eps * ( || x ||_oo * || A ||_oo + || b ||_oo ) * N )
- The relative machine precision (eps) is taken to be               1.110223e-16
- Computational tests pass if scaled residuals are less than                16.0

================================================================================
T/V                N    NB     P     Q               Time                 Gflops
--------------------------------------------------------------------------------
WR11C2R4       18048   192     2     2             309.73              1.265e+01
HPL_pdgesv() start time Fri May 19 10:59:50 2017

HPL_pdgesv() end time   Fri May 19 11:04:59 2017

--------------------------------------------------------------------------------
||Ax-b||_oo/(eps*(||A||_oo*||x||_oo+||b||_oo)*N)=        0.0014193 ...... PASSED
================================================================================

Finished      1 tests with the following results:
              1 tests completed and passed residual checks,
              0 tests completed and failed residual checks,
              0 tests skipped because of illegal input values.
--------------------------------------------------------------------------------

End of Tests.
================================================================================
#+END_EXAMPLE

C'est la première fois que je vois mes 4 "CPU" à 100% !

Entre les deux tests je suis passé de 9.482 à 12.65 Gflops.
Je pense qu'il est possible d'augmenter encoreun peu, mais le but est
de faire le lien avec DUMPI.


**** Lien avec DUMPI
Il semblerais que j'ai installé seulement undumpi, vu que dumpi ne
fonctionne pas avec les dernières version de mpich...
J'ai peut être trouvé un moyen : [[https://xgitlab.cels.anl.gov/codes/codes/blob/db787d9f77786b8682ab8746942e3e6037cacfd7/doc/BUILD_STEPS][ici]]
- DUMPI :
Je décide de l'installer sur ma machine virtuelle (vu que mon dumpi
est installé seulement avec undumpi sur ma machine et qu'il est lié à CODES).

#+begin_src sh
../configure --enable-libdumpi --prefix=/home/chevamax/sst-dumpi/install CC=mpicc CXX=mpiCC CFLAGS="-DMPICH_SUPPRESS_PROTOTYPES=1 -DHAVE_PRAGMA_HP_SEC_DEF=1"
#+end_src
Permet de passe le make

DONE : faire un test avec mpi tuto helloworld.
#+BEGIN_EXAMPLE
Linking with C/C++

We can use libdumpi that we generated above:

user@machine:~/play/mpi$ mpicc hello.c -c
user@machine:~/play/mpi$ mpicc hello.o -L$HOME/dumpi_inst/lib -ldumpi -o hello
user@machine:~/play/mpi$ LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$HOME/dumpi_inst/lib ./hello 
Hello!
user@machine:~/play/mpi$ ls
dumpi-2011.01.25.15.46.10-0000.bin  hello    hello.o
dumpi-2011.01.25.15.46.10.meta      hello.c

In this instance there is a single MPI rank created. There are two files created: a metafile and a file for our MPI rank zero. The date and time are encoded into the filename to prevent accidental overwrite of DUMPI trace files.

We can print the trace file using dumpi2ascii to verify a simple 'hello world' that does, an init, comm_rank, comm_size, and a finalize as its only MPI calls:

user@machine:~/play/mpi$ $HOME/dumpi_inst/bin/dumpi2ascii dumpi-2011.01.25.15.46.10-0000.bin 
MPI_Init entering at walltime 20120.589738643, cputime 0.023382031 seconds in thread 0.
int argc=1
string argv[1]=["./hello"]
MPI_Init returning at walltime 20120.589752472, cputime 0.023385336 seconds in thread 0.
MPI_Comm_rank entering at walltime 20120.589793260, cputime 0.023437127 seconds in thread 0.
MPI_Comm comm=2 (MPI_COMM_WORLD)
int rank=0
MPI_Comm_rank returning at walltime 20120.589796683, cputime 0.023440692 seconds in thread 0.
MPI_Comm_size entering at walltime 20120.589810022, cputime 0.023453983 seconds in thread 0.
MPI_Comm comm=2 (MPI_COMM_WORLD)
int size=1
MPI_Comm_size returning at walltime 20120.589813095, cputime 0.023457038 seconds in thread 0.
MPI_Finalize entering at walltime 20120.589841172, cputime 0.023484981 seconds in thread 0.
MPI_Finalize returning at walltime 20120.590067322, cputime 0.023710703 seconds in thread 0.

Libdumpi uses the PMPI interface, so you shouldn't have to use any included header files, or make any subroutine/function calls to DUMPI for most use cases of DUMPI. Of course, when you use libdumpi, you can't use or link against any other tools that use the PMPI interface in the same executable.

By default, DUMPI will emit trace information for every MPI call, with a timestamp for entry and exit to each routine.
#+END_EXAMPLE

En suivant la méthode du dessus, j'ai été capable de générer des
traces dumpi pour un programme helloWorld disponible [[http://mpitutorial.com/tutorials/mpi-hello-world/][ici]].

***** HPL + DUMPI
En ajoutant ~-L path/to/dumpi_inst/lib -ldumpi~ à la fin de la ligne
MPlib dans le Make.linux de HPL, j'ai réussi à générer une trâce!
/!\ Ca ne fonctionne pas si on met cette ligne sur *HPL_LIBS* ou sur le *LINKFLAGS*

Je n'ai pas encore compris comment on utilise =LD_PRELOAD= j'ai donc
compilé directement HPL avec le lien DUMPI. Je pense donc installer
deux versions, une avec les TRACES et l'autre sans. Christian m'a dit
de faire un lien entre les deux dossiers pour s'assurer que le HPL.dat
soit toujours le même.

***** Rencontre avec Christian
Florence m'a présenté Christian aujourd'hui qui travail sur
SimGrid. Il est très intéréssé par l'objectif de mon stage et aimerait
ajouter SST à la comparaison. En effet, il a écrit un papier sur ses
traveaux et on lui a reproché de ne pas avoir de comparaison avec
SST. J'espère avancer vite pour qu'il puisse se servir de mon travail!

***** Recherche
En faisant des recherche pour installer dumpi, j'ai vu qu'il y a un
convertisseur vers l'ASCII, mais aussi un convertisseur (experimental)
vers du DOT.

*** 2017-05-22 lundi

**** Configuration du system
Maintenant que tout marche séparément il faut que je rassemble tout
ça. Je pense faire un HowTo pour tout installer dans le bon
ordre. J'aurais du commencer par installer HPL et DUMPI avant de faire
le reste. Let's start again !

***** apt-get + versions
- gcc => 6.3.020170406
- mpich => 3.2-7
- cmake => 3.7.2-1
- doxygen => 1.8.13
- libtool => 2.4.6-2
- m4 => 1.4.18-1
- automake => 1:1.15-5ubuntu1
- autoconf => 2.69-10
- libatlas-base-dev => 3.10.3-1ubuntu1
- libmpich-dev => 3.2-7 build1
- gfortran 4 => 6.3.0-2ubuntu1
- flex => 2.6.2-1.3
- bison => 2:3.0.4.dfsg-1build1
- pkg-config => 0.29.1-0ubuntu1
- blcr-util => 0.8.5-2.3 (ce dernier et peut-être inutile, mais
  présent sur ma machine lors de l'installation)

***** DUMPI

#+begin_src sh :session foo
mkdir logiciels
cd logiciels
#+end_src

#+begin_src sh :session foo :results output :exports both 
git clone https://github.com/sstsimulator/sst-dumpi.git
cd sst-dumpi
./bootstrap.sh
mkdir build
cd build
../configure --enable-libdumpi --prefix=/home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/install CC=mpicc CXX=mpiCC CFLAGS="-DMPICH_SUPPRESS_PROTOTYPES=1 -DHAVE_PRAGMA_HP_SEC_DEF=1"
make
make install
make doc
#+end_src

#+RESULTS:
#+begin_example
Clonage dans 'sst-dumpi'...
remote: Counting objects: 329, done.
(1/3)           remote: Compressing objects:  66% (2/3)           remote: Compressing objects: 100% (3/3)           remote: Compressing objects: 100% (3/3), done.
(1/329)   Réception d'objets:   1% (4/329)   Réception d'objets:   2% (7/329)   Réception d'objets:   3% (10/329)   Réception d'objets:   4% (14/329)   Réception d'objets:   5% (17/329)   Réception d'objets:   6% (20/329)   Réception d'objets:   7% (24/329)   Réception d'objets:   8% (27/329)   Réception d'objets:   9% (30/329)   Réception d'objets:  10% (33/329)   Réception d'objets:  11% (37/329)   Réception d'objets:  12% (40/329)   Réception d'objets:  13% (43/329)   Réception d'objets:  14% (47/329)   Réception d'objets:  15% (50/329)   Réception d'objets:  16% (53/329)   Réception d'objets:  17% (56/329)   Réception d'objets:  18% (60/329)   Réception d'objets:  19% (63/329)   Réception d'objets:  20% (66/329)   Réception d'objets:  21% (70/329)   Réception d'objets:  22% (73/329)   Réception d'objets:  23% (76/329)   Réception d'objets:  24% (79/329)   Réception d'objets:  25% (83/329)   Réception d'objets:  26% (86/329)   Réception d'objets:  27% (89/329)   Réception d'objets:  28% (93/329)   Réception d'objets:  29% (96/329)   Réception d'objets:  30% (99/329)   Réception d'objets:  31% (102/329)   Réception d'objets:  32% (106/329)   Réception d'objets:  33% (109/329)   Réception d'objets:  34% (112/329)   Réception d'objets:  35% (116/329)   Réception d'objets:  36% (119/329)   Réception d'objets:  37% (122/329)   Réception d'objets:  38% (126/329)   Réception d'objets:  39% (129/329)   Réception d'objets:  40% (132/329)   Réception d'objets:  41% (135/329)   Réception d'objets:  42% (139/329)   Réception d'objets:  43% (142/329)   Réception d'objets:  44% (145/329)   Réception d'objets:  45% (149/329)   Réception d'objets:  46% (152/329)   Réception d'objets:  47% (155/329)   Réception d'objets:  48% (158/329)   Réception d'objets:  49% (162/329)   Réception d'objets:  50% (165/329)   Réception d'objets:  51% (168/329)   Réception d'objets:  52% (172/329)   Réception d'objets:  53% (175/329)   Réception d'objets:  54% (178/329)   Réception d'objets:  55% (181/329)   Réception d'objets:  56% (185/329)   Réception d'objets:  57% (188/329)   Réception d'objets:  58% (191/329)   Réception d'objets:  59% (195/329)   Réception d'objets:  60% (198/329)   Réception d'objets:  61% (201/329)   Réception d'objets:  62% (204/329)   Réception d'objets:  63% (208/329)   Réception d'objets:  64% (211/329)   Réception d'objets:  65% (214/329)   Réception d'objets:  66% (218/329)   Réception d'objets:  67% (221/329)   Réception d'objets:  68% (224/329)   Réception d'objets:  69% (228/329)   Réception d'objets:  70% (231/329)   Réception d'objets:  71% (234/329)   Réception d'objets:  72% (237/329)   Réception d'objets:  73% (241/329)   Réception d'objets:  74% (244/329)   Réception d'objets:  75% (247/329)   Réception d'objets:  76% (251/329)   Réception d'objets:  77% (254/329)   Réception d'objets:  78% (257/329)   Réception d'objets:  79% (260/329), 492.01 KiB | 951.00 KiB/s   Réception d'objets:  80% (264/329), 492.01 KiB | 951.00 KiB/s   Réception d'objets:  81% (267/329), 492.01 KiB | 951.00 KiB/s   Réception d'objets:  82% (270/329), 492.01 KiB | 951.00 KiB/s   remote: Total 329 (delta 0), reused 1 (delta 0), pack-reused 326
(274/329), 492.01 KiB | 951.00 KiB/s   Réception d'objets:  84% (277/329), 492.01 KiB | 951.00 KiB/s   Réception d'objets:  85% (280/329), 492.01 KiB | 951.00 KiB/s   Réception d'objets:  86% (283/329), 492.01 KiB | 951.00 KiB/s   Réception d'objets:  87% (287/329), 492.01 KiB | 951.00 KiB/s   Réception d'objets:  88% (290/329), 492.01 KiB | 951.00 KiB/s   Réception d'objets:  89% (293/329), 492.01 KiB | 951.00 KiB/s   Réception d'objets:  90% (297/329), 492.01 KiB | 951.00 KiB/s   Réception d'objets:  91% (300/329), 492.01 KiB | 951.00 KiB/s   Réception d'objets:  92% (303/329), 492.01 KiB | 951.00 KiB/s   Réception d'objets:  93% (306/329), 492.01 KiB | 951.00 KiB/s   Réception d'objets:  94% (310/329), 492.01 KiB | 951.00 KiB/s   Réception d'objets:  95% (313/329), 492.01 KiB | 951.00 KiB/s   Réception d'objets:  96% (316/329), 492.01 KiB | 951.00 KiB/s   Réception d'objets:  97% (320/329), 492.01 KiB | 951.00 KiB/s   Réception d'objets:  98% (323/329), 492.01 KiB | 951.00 KiB/s   Réception d'objets:  99% (326/329), 492.01 KiB | 951.00 KiB/s   Réception d'objets: 100% (329/329), 492.01 KiB | 951.00 KiB/s   Réception d'objets: 100% (329/329), 536.61 KiB | 951.00 KiB/s, fait.
(0/147)   Résolution des deltas:   1% (2/147)   Résolution des deltas:   2% (4/147)   Résolution des deltas:   4% (6/147)   Résolution des deltas:   5% (8/147)   Résolution des deltas:   7% (11/147)   Résolution des deltas:   8% (12/147)   Résolution des deltas:  10% (15/147)   Résolution des deltas:  11% (17/147)   Résolution des deltas:  12% (18/147)   Résolution des deltas:  14% (21/147)   Résolution des deltas:  15% (23/147)   Résolution des deltas:  17% (25/147)   Résolution des deltas:  18% (27/147)   Résolution des deltas:  19% (28/147)   Résolution des deltas:  20% (30/147)   Résolution des deltas:  21% (31/147)   Résolution des deltas:  22% (33/147)   Résolution des deltas:  23% (35/147)   Résolution des deltas:  25% (38/147)   Résolution des deltas:  27% (41/147)   Résolution des deltas:  30% (45/147)   Résolution des deltas:  31% (47/147)   Résolution des deltas:  34% (50/147)   Résolution des deltas:  35% (52/147)   Résolution des deltas:  37% (55/147)   Résolution des deltas:  38% (56/147)   Résolution des deltas:  40% (59/147)   Résolution des deltas:  42% (63/147)   Résolution des deltas:  44% (66/147)   Résolution des deltas:  45% (67/147)   Résolution des deltas:  46% (68/147)   Résolution des deltas:  47% (70/147)   Résolution des deltas:  48% (71/147)   Résolution des deltas:  49% (73/147)   Résolution des deltas:  51% (75/147)   Résolution des deltas:  52% (77/147)   Résolution des deltas:  53% (78/147)   Résolution des deltas:  55% (81/147)   Résolution des deltas:  56% (83/147)   Résolution des deltas:  57% (84/147)   Résolution des deltas:  59% (87/147)   Résolution des deltas:  60% (89/147)   Résolution des deltas:  61% (91/147)   Résolution des deltas:  62% (92/147)   Résolution des deltas:  64% (95/147)   Résolution des deltas:  65% (96/147)   Résolution des deltas:  66% (98/147)   Résolution des deltas:  68% (100/147)   Résolution des deltas:  69% (102/147)   Résolution des deltas:  70% (103/147)   Résolution des deltas:  71% (105/147)   Résolution des deltas:  72% (107/147)   Résolution des deltas:  73% (108/147)   Résolution des deltas:  74% (109/147)   Résolution des deltas:  76% (113/147)   Résolution des deltas:  77% (114/147)   Résolution des deltas:  78% (115/147)   Résolution des deltas:  81% (120/147)   Résolution des deltas:  82% (121/147)   Résolution des deltas:  83% (123/147)   Résolution des deltas:  84% (124/147)   Résolution des deltas:  85% (125/147)   Résolution des deltas:  86% (127/147)   Résolution des deltas:  87% (128/147)   Résolution des deltas:  90% (133/147)   Résolution des deltas:  91% (134/147)   Résolution des deltas:  92% (136/147)   Résolution des deltas:  94% (139/147)   Résolution des deltas:  95% (141/147)   Résolution des deltas:  96% (142/147)   Résolution des deltas:  97% (143/147)   Résolution des deltas:  98% (145/147)   Résolution des deltas: 100% (147/147)   Résolution des deltas: 100% (147/147), fait.
$ ./bootstrap.sh: 14: ./bootstrap.sh: glibtoolize: not found
libtoolize: putting auxiliary files in AC_CONFIG_AUX_DIR, 'bin'.
libtoolize: linking file 'bin/ltmain.sh'
libtoolize: putting macros in AC_CONFIG_MACRO_DIRS, 'acinclude'.
libtoolize: linking file 'acinclude/libtool.m4'
libtoolize: linking file 'acinclude/ltoptions.m4'
libtoolize: linking file 'acinclude/ltsugar.m4'
libtoolize: linking file 'acinclude/ltversion.m4'
libtoolize: linking file 'acinclude/lt~obsolete.m4'
libtoolize: putting auxiliary files in AC_CONFIG_AUX_DIR, 'bin'.
libtoolize: copying file 'bin/ltmain.sh'
libtoolize: putting macros in AC_CONFIG_MACRO_DIRS, 'acinclude'.
libtoolize: copying file 'acinclude/libtool.m4'
libtoolize: copying file 'acinclude/ltoptions.m4'
libtoolize: copying file 'acinclude/ltsugar.m4'
libtoolize: copying file 'acinclude/ltversion.m4'
libtoolize: copying file 'acinclude/lt~obsolete.m4'
configure.ac:53: installing 'bin/ar-lib'
configure.ac:53: installing 'bin/compile'
configure.ac:51: installing 'bin/config.guess'
configure.ac:51: installing 'bin/config.sub'
configure.ac:52: installing 'bin/install-sh'
configure.ac:52: installing 'bin/missing'
dumpi/bin/Makefile.am: installing 'bin/depcomp'
parallel-tests: installing 'bin/test-driver'
checking build system type... x86_64-pc-linux-gnu
checking host system type... x86_64-pc-linux-gnu
checking target system type... x86_64-pc-linux-gnu
checking for a BSD-compatible install... /usr/bin/install -c
checking whether build environment is sane... yes
checking for a thread-safe mkdir -p... /bin/mkdir -p
checking for gawk... no
checking for mawk... mawk
(MAKE)... yes
checking whether make supports nested variables... yes
checking for style of include used by make... GNU
checking for gcc... mpicc
checking whether the C compiler works... yes
checking for C compiler default output file name... a.out
checking for suffix of executables... 
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether mpicc accepts -g... yes
checking for mpicc option to accept ISO C89... none needed
checking whether mpicc understands -c and -o together... yes
checking dependency style of mpicc... gcc3
checking for ar... ar
checking the archiver (ar) interface... ar
checking whether make supports nested variables... (cached) yes
checking for gcc... (cached) mpicc
checking whether we are using the GNU C compiler... (cached) yes
checking whether mpicc accepts -g... (cached) yes
checking for mpicc option to accept ISO C89... (cached) none needed
checking whether mpicc understands -c and -o together... (cached) yes
checking dependency style of mpicc... (cached) gcc3
checking whether we are using the GNU C++ compiler... yes
checking whether mpiCC accepts -g... yes
checking dependency style of mpiCC... gcc3
checking how to print strings... printf
checking for a sed that does not truncate output... /bin/sed
checking for grep that handles long lines and -e... /bin/grep
checking for egrep... /bin/grep -E
checking for fgrep... /bin/grep -F
checking for ld used by mpicc... /usr/bin/ld
checking if the linker (/usr/bin/ld) is GNU ld... yes
checking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B
checking the name lister (/usr/bin/nm -B) interface... BSD nm
checking whether ln -s works... yes
checking the maximum length of command line arguments... 1635000
checking how to convert x86_64-pc-linux-gnu file names to x86_64-pc-linux-gnu format... func_convert_file_noop
checking how to convert x86_64-pc-linux-gnu file names to toolchain format... func_convert_file_noop
checking for /usr/bin/ld option to reload object files... -r
checking for objdump... objdump
checking how to recognize dependent libraries... pass_all
checking for dlltool... no
s\n
checking for archiver @FILE support... @
checking for strip... strip
checking for ranlib... ranlib
checking command to parse /usr/bin/nm -B output from mpicc object... ok
checking for sysroot... no
checking for a working dd... /bin/dd
checking how to truncate binary pipes... /bin/dd bs=4096 count=1
checking for mt... mt
checking if mt is a manifest tool... no
checking how to run the C preprocessor... mpicc -E
checking for ANSI C header files... yes
checking for sys/types.h... yes
checking for sys/stat.h... yes
checking for stdlib.h... yes
checking for string.h... yes
checking for memory.h... yes
checking for strings.h... yes
checking for inttypes.h... yes
checking for stdint.h... yes
checking for unistd.h... yes
checking for dlfcn.h... yes
checking for objdir... .libs
checking if mpicc supports -fno-rtti -fno-exceptions... no
checking for mpicc option to produce PIC... -fPIC -DPIC
checking if mpicc PIC flag -fPIC -DPIC works... yes
checking if mpicc static flag -static works... no
checking if mpicc supports -c -o file.o... yes
checking if mpicc supports -c -o file.o... (cached) yes
checking whether the mpicc linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes
checking whether -lc should be explicitly linked in... no
checking dynamic linker characteristics... GNU/Linux ld.so
checking how to hardcode library paths into programs... immediate
checking whether stripping libraries is possible... yes
checking if libtool supports shared libraries... yes
checking whether to build shared libraries... yes
checking whether to build static libraries... yes
checking how to run the C++ preprocessor... mpiCC -E
checking for ld used by mpiCC... /usr/bin/ld -m elf_x86_64
checking if the linker (/usr/bin/ld -m elf_x86_64) is GNU ld... yes
checking whether the mpiCC linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes
checking for mpiCC option to produce PIC... -fPIC -DPIC
checking if mpiCC PIC flag -fPIC -DPIC works... yes
checking if mpiCC static flag -static works... no
checking if mpiCC supports -c -o file.o... yes
checking if mpiCC supports -c -o file.o... (cached) yes
checking whether the mpiCC linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes
checking dynamic linker characteristics... (cached) GNU/Linux ld.so
checking how to hardcode library paths into programs... immediate
checking whether POSIX timers should be used... available without linking -lrt
"enable_test=no"
checking wheter OTF library and header file can be found... no
checking whether mpicc can compile and link an MPI program... yes
checking whether mpi.h is found... yes
checking whether pthreads provide thread-local storage... no
checking whether HOST_NAME_MAX is declared... no
checking for gettimeofday... yes
checking for getrusage... yes
checking papi support... no
checking instrumentation settings... instrumentation not enabled
checking for dot... no
checking that generated files are newer than configure... done
configure: creating ./config.status
config.status: creating Makefile
config.status: creating dumpi/Makefile
config.status: creating dumpi/common/Makefile
config.status: creating dumpi/libdumpi/Makefile
config.status: creating dumpi/libundumpi/Makefile
config.status: creating dumpi/bin/Makefile
config.status: creating dumpi/test/Makefile
config.status: creating tests/Makefile
config.status: creating docs/doxygen.cfg
config.status: creating dumpi/dumpiconfig-generated.h
config.status: executing depfiles commands
config.status: executing libtool commands
Making all in dumpi
make[1] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/dumpi »
make  all-recursive
make[2] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/dumpi »
Making all in common
make[3] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/dumpi/common »
  CC       types.lo
  CC       funcs.lo
  CC       io.lo
  CC       dumpiio.lo
  CC       funclabels.lo
  CC       gettime.lo
  CC       constants.lo
  CC       perfctrs.lo
  CC       perfctrtags.lo
  CC       iodefs.lo
  CC       debugflags.lo
  CCLD     libdumpi_common.la
ar: `u' modifier ignored since `D' is the default (see `U')
make[3] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/dumpi/common »
Making all in libdumpi
make[3] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/dumpi/libdumpi »
  CC       data.lo
  CC       init.lo
  CC       libdumpi.lo
  CC       callprofile.lo
  CC       callprofile-addrset.lo
  CC       mpibindings-utils.lo
  CC       mpibindings-maps.lo
  CC       mpibindings2.lo
../../../dumpi/libdumpi/mpibindings2.c: In function ‘MPI_Pcontrol’:
llu’ expects argument of type ‘long long unsigned int’, but argument 3 has type ‘uint64_t {aka long unsigned int}’ [-Wformat=]
         fprintf(stderr, "WARNING:  DUMPI:  MPI_Pcontrol(3, ...):  "
                         ^
  CCLD     libdumpi.la
ar: `u' modifier ignored since `D' is the default (see `U')
make[3] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/dumpi/libdumpi »
Making all in libundumpi
make[3] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/dumpi/libundumpi »
  CC       libundumpi.lo
  CC       callbacks.lo
  CC       bindings.lo
  CCLD     libundumpi.la
ar: `u' modifier ignored since `D' is the default (see `U')
make[3] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/dumpi/libundumpi »
Making all in bin
make[3] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/dumpi/bin »
  CC       dumpi2ascii.o
../../../dumpi/bin/dumpi2ascii.c: In function ‘print_addresses’:
llu’ expects argument of type ‘long long unsigned int’, but argument 3 has type ‘uint64_t {aka const long unsigned int}’ [-Wformat=]
llu has label %s\n", addresses[i], names[i]);
                                          ^
  CC       dumpi2ascii-callbacks.o
  CCLD     dumpi2ascii
  CC       dumpi2dumpi.o
  CC       dumpi2dumpi-opts.o
  CC       dumpi2dumpi-help.o
  CC       dumpi2dumpi-meta.o
  CC       dumpi2dumpi-callbacks.o
  CCLD     dumpi2dumpi
  CXX      dumpistats.o
  CXX      dumpistats-timebin.o
  CXX      dumpistats-gatherbin.o
  CXX      dumpistats-callbacks.o
  CXX      dumpistats-handlers.o
  CXX      trace.o
  CXX      metadata.o
  CXX      sharedstate.o
  CXX      sharedstate-commconstruct.o
  CXXLD    dumpistats
  CC       ascii2dumpi.o
../../../dumpi/bin/ascii2dumpi.c: In function ‘save_old_starttime’:
../../../dumpi/bin/ascii2dumpi.c:449:3: warning: implicit declaration of function ‘strptime’ [-Wimplicit-function-declaration]
a %b %d %T %Z %Y", &tmo);
   ^~~~~~~~
  CCLD     ascii2dumpi
make[3] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/dumpi/bin »
make[3] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/dumpi »
make[3] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/dumpi »
make[2] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/dumpi »
make[1] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/dumpi »
Making all in tests
make[1] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/tests »
make[1]: rien à faire pour « all ».
make[1] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/tests »
make[1] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build »
make[1]: rien à faire pour « all-am ».
make[1] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build »
Making install in dumpi
make[1] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/dumpi »
Making install in common
make[2] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/dumpi/common »
make[3] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/dumpi/common »
make[3]: rien à faire pour « install-exec-am ».
 /bin/mkdir -p '/home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/install/include/dumpi/common'
 /usr/bin/install -c -m 644 ../../../dumpi/common/argtypes.h ../../../dumpi/common/debugflags.h ../../../dumpi/common/funclabels.h ../../../dumpi/common/gettime.h ../../../dumpi/common/io.h ../../../dumpi/common/perfctrs.h ../../../dumpi/common/settings.h ../../../dumpi/common/constants.h ../../../dumpi/common/dumpiio.h ../../../dumpi/common/funcs.h ../../../dumpi/common/hashmap.h ../../../dumpi/common/iodefs.h ../../../dumpi/common/perfctrtags.h ../../../dumpi/common/types.h ../../../dumpi/common/byteswap.h '/home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/install/include/dumpi/common'
make[3] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/dumpi/common »
make[2] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/dumpi/common »
Making install in libdumpi
make[2] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/dumpi/libdumpi »
make[3] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/dumpi/libdumpi »
 /bin/mkdir -p '/home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/install/lib'
 /bin/bash ../../libtool   --mode=install /usr/bin/install -c   libdumpi.la '/home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/install/lib'
libtool: install: /usr/bin/install -c .libs/libdumpi.so.7.0.0 /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/install/lib/libdumpi.so.7.0.0
libtool: install: (cd /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/install/lib && { ln -s -f libdumpi.so.7.0.0 libdumpi.so.7 || { rm -f libdumpi.so.7 && ln -s libdumpi.so.7.0.0 libdumpi.so.7; }; })
libtool: install: (cd /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/install/lib && { ln -s -f libdumpi.so.7.0.0 libdumpi.so || { rm -f libdumpi.so && ln -s libdumpi.so.7.0.0 libdumpi.so; }; })
libtool: install: /usr/bin/install -c .libs/libdumpi.lai /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/install/lib/libdumpi.la
libtool: install: /usr/bin/install -c .libs/libdumpi.a /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/install/lib/libdumpi.a
libtool: install: chmod 644 /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/install/lib/libdumpi.a
libtool: install: ranlib /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/install/lib/libdumpi.a
libtool: finish: PATH="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/sbin" ldconfig -n /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/install/lib
----------------------------------------------------------------------
Libraries have been installed in:
   /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/install/lib

If you ever happen to want to link against installed libraries
in a given directory, LIBDIR, you must either use libtool, and
specify the full pathname of the library, or use the '-LLIBDIR'
flag during linking and do at least one of the following:
   - add LIBDIR to the 'LD_LIBRARY_PATH' environment variable
     during execution
   - add LIBDIR to the 'LD_RUN_PATH' environment variable
     during linking
   - use the '-Wl,-rpath -Wl,LIBDIR' linker flag
   - have your system administrator add LIBDIR to '/etc/ld.so.conf'

See any operating system documentation about shared libraries for
more information, such as the ld(1) and ld.so(8) manual pages.
----------------------------------------------------------------------
 /bin/mkdir -p '/home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/install/include/dumpi/libdumpi'
 /usr/bin/install -c -m 644 ../../../dumpi/libdumpi/callprofile-addrset.h ../../../dumpi/libdumpi/callprofile.h ../../../dumpi/libdumpi/data.h ../../../dumpi/libdumpi/fused-bindings.h ../../../dumpi/libdumpi/init.h ../../../dumpi/libdumpi/libdumpi.h ../../../dumpi/libdumpi/mpibindings-maps.h ../../../dumpi/libdumpi/mpibindings.h ../../../dumpi/libdumpi/mpibindings-utils.h ../../../dumpi/libdumpi/tof77.h '/home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/install/include/dumpi/libdumpi'
make[3] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/dumpi/libdumpi »
make[2] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/dumpi/libdumpi »
Making install in libundumpi
make[2] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/dumpi/libundumpi »
make[3] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/dumpi/libundumpi »
 /bin/mkdir -p '/home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/install/lib'
 /bin/bash ../../libtool   --mode=install /usr/bin/install -c   libundumpi.la '/home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/install/lib'
libtool: install: /usr/bin/install -c .libs/libundumpi.so.7.0.0 /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/install/lib/libundumpi.so.7.0.0
libtool: install: (cd /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/install/lib && { ln -s -f libundumpi.so.7.0.0 libundumpi.so.7 || { rm -f libundumpi.so.7 && ln -s libundumpi.so.7.0.0 libundumpi.so.7; }; })
libtool: install: (cd /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/install/lib && { ln -s -f libundumpi.so.7.0.0 libundumpi.so || { rm -f libundumpi.so && ln -s libundumpi.so.7.0.0 libundumpi.so; }; })
libtool: install: /usr/bin/install -c .libs/libundumpi.lai /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/install/lib/libundumpi.la
libtool: install: /usr/bin/install -c .libs/libundumpi.a /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/install/lib/libundumpi.a
libtool: install: chmod 644 /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/install/lib/libundumpi.a
libtool: install: ranlib /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/install/lib/libundumpi.a
libtool: finish: PATH="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/sbin" ldconfig -n /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/install/lib
----------------------------------------------------------------------
Libraries have been installed in:
   /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/install/lib

If you ever happen to want to link against installed libraries
in a given directory, LIBDIR, you must either use libtool, and
specify the full pathname of the library, or use the '-LLIBDIR'
flag during linking and do at least one of the following:
   - add LIBDIR to the 'LD_LIBRARY_PATH' environment variable
     during execution
   - add LIBDIR to the 'LD_RUN_PATH' environment variable
     during linking
   - use the '-Wl,-rpath -Wl,LIBDIR' linker flag
   - have your system administrator add LIBDIR to '/etc/ld.so.conf'

See any operating system documentation about shared libraries for
more information, such as the ld(1) and ld.so(8) manual pages.
----------------------------------------------------------------------
 /bin/mkdir -p '/home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/install/include/dumpi/libundumpi'
 /usr/bin/install -c -m 644 ../../../dumpi/libundumpi/bindings.h ../../../dumpi/libundumpi/callbacks.h ../../../dumpi/libundumpi/dumpistate.h ../../../dumpi/libundumpi/freedefs.h ../../../dumpi/libundumpi/libundumpi.h '/home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/install/include/dumpi/libundumpi'
make[3] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/dumpi/libundumpi »
make[2] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/dumpi/libundumpi »
Making install in bin
make[2] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/dumpi/bin »
make[3] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/dumpi/bin »
 /bin/mkdir -p '/home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/install/bin'
  /bin/bash ../../libtool   --mode=install /usr/bin/install -c dumpi2ascii dumpi2dumpi dumpistats ascii2dumpi '/home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/install/bin'
libtool: install: /usr/bin/install -c .libs/dumpi2ascii /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/install/bin/dumpi2ascii
libtool: install: /usr/bin/install -c .libs/dumpi2dumpi /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/install/bin/dumpi2dumpi
libtool: install: /usr/bin/install -c .libs/dumpistats /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/install/bin/dumpistats
libtool: install: /usr/bin/install -c .libs/ascii2dumpi /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/install/bin/ascii2dumpi
make[3]: rien à faire pour « install-data-am ».
make[3] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/dumpi/bin »
make[2] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/dumpi/bin »
make[2] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/dumpi »
make[3] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/dumpi »
make[3]: rien à faire pour « install-exec-am ».
 /bin/mkdir -p '/home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/install/include/dumpi'
 /usr/bin/install -c -m 644 ../../dumpi/dumpiconfig.h dumpiconfig-generated.h '/home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/install/include/dumpi'
make[3] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/dumpi »
make[2] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/dumpi »
make[1] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/dumpi »
Making install in tests
make[1] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/tests »
make[2] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/tests »
make[2]: rien à faire pour « install-exec-am ».
make[2]: rien à faire pour « install-data-am ».
make[2] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/tests »
make[1] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build/tests »
make[1] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build »
make[2] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build »
make[2]: rien à faire pour « install-exec-am ».
make[2]: rien à faire pour « install-data-am ».
make[2] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build »
make[1] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/build »
cd docs && doxygen doxygen.cfg
warning: Tag `USE_WINDOWS_ENCODING' at line 54 of file `doxygen.cfg' has become obsolete.
         To avoid this warning please remove this line from your configuration file or upgrade it using "doxygen -u"
warning: Tag `DETAILS_AT_TOP' at line 136 of file `doxygen.cfg' has become obsolete.
         To avoid this warning please remove this line from your configuration file or upgrade it using "doxygen -u"
warning: Tag `HTML_ALIGN_MEMBERS' at line 579 of file `doxygen.cfg' has become obsolete.
         To avoid this warning please remove this line from your configuration file or upgrade it using "doxygen -u"
warning: Tag `XML_SCHEMA' at line 811 of file `doxygen.cfg' has become obsolete.
         To avoid this warning please remove this line from your configuration file or upgrade it using "doxygen -u"
warning: Tag `XML_DTD' at line 817 of file `doxygen.cfg' has become obsolete.
         To avoid this warning please remove this line from your configuration file or upgrade it using "doxygen -u"
warning: Tag `MAX_DOT_GRAPH_WIDTH' at line 1078 of file `doxygen.cfg' has become obsolete.
         To avoid this warning please remove this line from your configuration file or upgrade it using "doxygen -u"
warning: Tag `MAX_DOT_GRAPH_HEIGHT' at line 1086 of file `doxygen.cfg' has become obsolete.
         To avoid this warning please remove this line from your configuration file or upgrade it using "doxygen -u"
Notice: Output directory `../docs/dumpi' does not exist. I have created it for you.
Searching for include files...
Searching for example files...
Searching for images...
Searching for dot files...
Searching for msc files...
Searching for dia files...
Searching for files to exclude
Searching INPUT for files to process...
Searching for files in directory /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi
Searching for files in directory /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin
Searching for files in directory /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common
Searching for files in directory /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libdumpi
Searching for files in directory /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libundumpi
Searching for files in directory /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/test
Searching for files in directory /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/docs
Reading and parsing tag files
Parsing files
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/comm.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/comm.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/dumpi2ascii-callbacks.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/dumpi2ascii-callbacks.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/dumpi2ascii-defs.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/dumpi2ascii-defs.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/dumpi2dumpi.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/dumpi2dumpi.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/dumpistats-binbase.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/dumpistats-binbase.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/dumpistats-callbacks.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/dumpistats-callbacks.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/dumpistats-gatherbin.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/dumpistats-gatherbin.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/dumpistats-handlers.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/dumpistats-handlers.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/dumpistats-timebin.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/dumpistats-timebin.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/group.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/group.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/metadata.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/metadata.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/otfcomplete.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/otfcomplete.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/otfwriter.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/otfwriter.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/sharedstate-commconstruct.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/sharedstate-commconstruct.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/sharedstate.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/sharedstate.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/timeutils.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/timeutils.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/trace.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/trace.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/type.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/type.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/argtypes.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/argtypes.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/byteswap.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/byteswap.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/constants.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/constants.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/debugflags.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/debugflags.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/dumpiio.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/dumpiio.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/funclabels.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/funclabels.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/funcs.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/funcs.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/gettime.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/gettime.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/hashmap.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/hashmap.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/io.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/io.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/iodefs.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/iodefs.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/perfctrs.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/perfctrs.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/perfctrtags.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/perfctrtags.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/settings.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/settings.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/types.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/types.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/dumpiconfig.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/dumpiconfig.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libdumpi/callprofile-addrset.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libdumpi/callprofile-addrset.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libdumpi/callprofile.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libdumpi/callprofile.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libdumpi/data.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libdumpi/data.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libdumpi/fused-bindings.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libdumpi/fused-bindings.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libdumpi/init.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libdumpi/init.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libdumpi/libdumpi.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libdumpi/libdumpi.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libdumpi/mpibindings-maps.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libdumpi/mpibindings-maps.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libdumpi/mpibindings-utils.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libdumpi/mpibindings-utils.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libdumpi/mpibindings.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libdumpi/mpibindings.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libdumpi/tof77.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libdumpi/tof77.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libundumpi/bindings.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libundumpi/bindings.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libundumpi/callbacks.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libundumpi/callbacks.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libundumpi/dumpistate.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libundumpi/dumpistate.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libundumpi/freedefs.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libundumpi/freedefs.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libundumpi/libundumpi.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libundumpi/libundumpi.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/test/coll.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/test/coll.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/test/manip.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/test/manip.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/test/p2p.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/test/p2p.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/test/probe.h...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/test/probe.h...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/docs/compiling.dox...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/docs/compiling.dox...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/docs/dumpi.dox...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/docs/dumpi.dox...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/docs/issues.dox...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/docs/issues.dox...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/docs/oaq.dox...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/docs/oaq.dox...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/docs/tools.dox...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/docs/tools.dox...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/docs/traceformat.dox...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/docs/traceformat.dox...
Preprocessing /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/docs/user.dox...
Parsing file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/docs/user.dox...
Building group list...
Building directory list...
Building namespace list...
Building file list...
Building class list...
Associating documentation with classes...
Computing nesting relations for classes...
Building example list...
Searching for enumerations...
Searching for documented typedefs...
Searching for members imported via using declarations...
Searching for included using directives...
Searching for documented variables...
Building interface member list...
Building member list...
Searching for friends...
Searching for documented defines...
Computing class inheritance relations...
Computing class usage relations...
Flushing cached template relations that have become invalid...
Computing class relations...
Add enum values to enums...
Searching for member function documentation...
Creating members for template instances...
Building page list...
Search for main page...
Computing page relations...
Determining the scope of groups...
Sorting lists...
Freeing entry tree
Determining which enums are documented
Computing member relations...
Building full member lists recursively...
Adding members to member groups.
Computing member references...
Inheriting documentation...
Generating disk names...
Adding source references...
Adding xrefitems...
Sorting member lists...
Computing dependencies between directories...
Generating citations page...
Counting data structures...
Resolving user defined references...
Finding anchors and sections in the documentation...
Transferring function references...
Combining using relations...
Adding members to index pages...
Generating style sheet...
Generating search indices...
Generating example documentation...
Generating file sources...
Parsing code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/docs/compiling.dox...
Parsing code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/docs/dumpi.dox...
Parsing code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/docs/issues.dox...
Parsing code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/docs/oaq.dox...
Parsing code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/docs/tools.dox...
Parsing code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/docs/traceformat.dox...
Parsing code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/docs/user.dox...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/comm.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/dumpi2ascii-callbacks.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/dumpi2ascii-defs.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/dumpi2dumpi.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/dumpistats-binbase.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/dumpistats-callbacks.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/dumpistats-gatherbin.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/dumpistats-handlers.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/dumpistats-timebin.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/group.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/metadata.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/otfcomplete.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/otfwriter.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/sharedstate-commconstruct.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/sharedstate.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/timeutils.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/trace.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/type.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/argtypes.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/byteswap.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/constants.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/debugflags.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/dumpiio.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/funclabels.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/funcs.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/gettime.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/hashmap.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/io.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/iodefs.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/perfctrs.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/perfctrtags.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/settings.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/types.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/dumpiconfig.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libdumpi/callprofile-addrset.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libdumpi/callprofile.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libdumpi/data.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libdumpi/fused-bindings.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libdumpi/init.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libdumpi/libdumpi.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libdumpi/mpibindings-maps.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libdumpi/mpibindings-utils.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libdumpi/mpibindings.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libdumpi/tof77.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libundumpi/bindings.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libundumpi/callbacks.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libundumpi/dumpistate.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libundumpi/freedefs.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libundumpi/libundumpi.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/test/coll.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/test/manip.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/test/p2p.h...
Generating code for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/test/probe.h...
Generating file documentation...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/docs/compiling.dox...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/docs/dumpi.dox...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/docs/issues.dox...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/docs/oaq.dox...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/docs/tools.dox...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/docs/traceformat.dox...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/docs/user.dox...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/comm.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/dumpi2ascii-callbacks.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/dumpi2ascii-defs.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/dumpi2dumpi.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/dumpistats-binbase.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/dumpistats-callbacks.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/dumpistats-gatherbin.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/dumpistats-handlers.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/dumpistats-timebin.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/group.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/metadata.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/otfcomplete.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/otfwriter.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/sharedstate-commconstruct.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/sharedstate.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/timeutils.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/trace.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/type.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/argtypes.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/byteswap.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/constants.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/debugflags.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/dumpiio.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/funclabels.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/funcs.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/gettime.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/hashmap.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/io.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/iodefs.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/perfctrs.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/perfctrtags.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/settings.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/common/types.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/dumpiconfig.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libdumpi/callprofile-addrset.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libdumpi/callprofile.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libdumpi/data.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libdumpi/fused-bindings.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libdumpi/init.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libdumpi/libdumpi.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libdumpi/mpibindings-maps.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libdumpi/mpibindings-utils.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libdumpi/mpibindings.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libdumpi/tof77.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libundumpi/bindings.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libundumpi/callbacks.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libundumpi/dumpistate.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libundumpi/freedefs.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libundumpi/libundumpi.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/test/coll.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/test/manip.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/test/p2p.h...
Generating docs for file /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/test/probe.h...
Generating page documentation...
Generating docs for page compiling...
Generating docs for page known_issues...
Generating docs for page oaq...
Generating docs for page tools...
Generating docs for page traceformat...
Generating docs for page using...
/home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/docs/user.dox:77: warning: Found unknown command `\machine'
/home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/docs/user.dox:88: warning: Found unknown command `\machine'
/home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/docs/user.dox:89: warning: Found unknown command `\machine'
/home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/docs/user.dox:90: warning: Found unknown command `\machine'
/home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/docs/user.dox:92: warning: explicit link request to 'PBS' could not be resolved
/home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/docs/user.dox:93: warning: explicit link request to 'PBS' could not be resolved
/home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/docs/user.dox:94: warning: explicit link request to 'PBS' could not be resolved
/home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/docs/user.dox:95: warning: explicit link request to 'PBS' could not be resolved
/home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/docs/user.dox:96: warning: explicit link request to 'PBS' could not be resolved
/home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/docs/user.dox:101: warning: Found unknown command `\machine'
/home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/docs/user.dox:106: warning: Found unknown command `\machine'
/home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/docs/user.dox:109: warning: Found unknown command `\machine'
found
Generating group documentation...
found
found
found
/home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/libundumpi/libundumpi.h:112: warning: The following parameters of undumpi_read_stream_full(const char *metaname, dumpi_profile *profile, const libundumpi_callbacks *callback, void *userarg, bool print_progress, double percent_terminate) are not documented:
  parameter 'metaname'
  parameter 'print_progress'
  parameter 'percent_terminate'
Generating class documentation...
Generating docs for compound d2a_addrmap...
Generating docs for compound d2dmeta...
Generating docs for compound d2dopts...
Generating docs for compound dumpi_abort...
Generating docs for compound dumpi_accumulate...
Generating docs for compound dumpi_add_error_class...
Generating docs for compound dumpi_add_error_code...
Generating docs for compound dumpi_add_error_string...
Generating docs for compound dumpi_addr_iterator...
Generating docs for compound dumpi_address...
Generating docs for compound dumpi_allgather...
Generating docs for compound dumpi_allgatherv...
Generating docs for compound dumpi_alloc_mem...
Generating docs for compound dumpi_allreduce...
Generating docs for compound dumpi_alltoall...
Generating docs for compound dumpi_alltoallv...
Generating docs for compound dumpi_alltoallw...
Generating docs for compound dumpi_attr_delete...
Generating docs for compound dumpi_attr_get...
Generating docs for compound dumpi_attr_put...
Generating docs for compound dumpi_barrier...
Generating docs for compound dumpi_bcast...
Generating docs for compound dumpi_bsend...
Generating docs for compound dumpi_bsend_init...
Generating docs for compound dumpi_buffer_attach...
Generating docs for compound dumpi_buffer_detach...
Generating docs for compound dumpi_cancel...
Generating docs for compound dumpi_cart_coords...
Generating docs for compound dumpi_cart_create...
Generating docs for compound dumpi_cart_get...
Generating docs for compound dumpi_cart_map...
Generating docs for compound dumpi_cart_rank...
Generating docs for compound dumpi_cart_shift...
Generating docs for compound dumpi_cart_sub...
Generating docs for compound dumpi_cartdim_get...
Generating docs for compound dumpi_clock...
Generating docs for compound dumpi_clock_pair...
Generating docs for compound dumpi_close_port...
Generating docs for compound dumpi_comm_accept...
Generating docs for compound dumpi_comm_call_errhandler...
Generating docs for compound dumpi_comm_compare...
Generating docs for compound dumpi_comm_connect...
Generating docs for compound dumpi_comm_create...
Generating docs for compound dumpi_comm_create_errhandler...
Generating docs for compound dumpi_comm_create_keyval...
Generating docs for compound dumpi_comm_delete_attr...
Generating docs for compound dumpi_comm_disconnect...
Generating docs for compound dumpi_comm_dup...
Generating docs for compound dumpi_comm_free...
Generating docs for compound dumpi_comm_free_keyval...
Generating docs for compound dumpi_comm_get_attr...
Generating docs for compound dumpi_comm_get_errhandler...
Generating docs for compound dumpi_comm_get_name...
Generating docs for compound dumpi_comm_get_parent...
Generating docs for compound dumpi_comm_group...
Generating docs for compound dumpi_comm_join...
Generating docs for compound dumpi_comm_rank...
Generating docs for compound dumpi_comm_remote_group...
Generating docs for compound dumpi_comm_remote_size...
Generating docs for compound dumpi_comm_set_attr...
Generating docs for compound dumpi_comm_set_errhandler...
Generating docs for compound dumpi_comm_set_name...
Generating docs for compound dumpi_comm_size...
Generating docs for compound dumpi_comm_spawn...
Generating docs for compound dumpi_comm_spawn_multiple...
Generating docs for compound dumpi_comm_split...
Generating docs for compound dumpi_comm_test_inter...
Generating docs for compound dumpi_dims_create...
Generating docs for compound dumpi_errhandler_create...
Generating docs for compound dumpi_errhandler_free...
Generating docs for compound dumpi_errhandler_get...
Generating docs for compound dumpi_errhandler_set...
Generating docs for compound dumpi_error_class...
Generating docs for compound dumpi_error_string...
Generating docs for compound dumpi_exscan...
Generating docs for compound dumpi_file_call_errhandler...
Generating docs for compound dumpi_file_close...
Generating docs for compound dumpi_file_create_errhandler...
Generating docs for compound dumpi_file_delete...
Generating docs for compound dumpi_file_get_amode...
Generating docs for compound dumpi_file_get_atomicity...
Generating docs for compound dumpi_file_get_byte_offset...
Generating docs for compound dumpi_file_get_errhandler...
Generating docs for compound dumpi_file_get_group...
Generating docs for compound dumpi_file_get_info...
Generating docs for compound dumpi_file_get_position...
Generating docs for compound dumpi_file_get_position_shared...
Generating docs for compound dumpi_file_get_size...
Generating docs for compound dumpi_file_get_type_extent...
Generating docs for compound dumpi_file_get_view...
Generating docs for compound dumpi_file_iread...
Generating docs for compound dumpi_file_iread_at...
Generating docs for compound dumpi_file_iread_shared...
Generating docs for compound dumpi_file_iwrite...
Generating docs for compound dumpi_file_iwrite_at...
Generating docs for compound dumpi_file_iwrite_shared...
Generating docs for compound dumpi_file_open...
Generating docs for compound dumpi_file_preallocate...
Generating docs for compound dumpi_file_read...
Generating docs for compound dumpi_file_read_all...
Generating docs for compound dumpi_file_read_all_begin...
Generating docs for compound dumpi_file_read_all_end...
Generating docs for compound dumpi_file_read_at...
Generating docs for compound dumpi_file_read_at_all...
Generating docs for compound dumpi_file_read_at_all_begin...
Generating docs for compound dumpi_file_read_at_all_end...
Generating docs for compound dumpi_file_read_ordered...
Generating docs for compound dumpi_file_read_ordered_begin...
Generating docs for compound dumpi_file_read_ordered_end...
Generating docs for compound dumpi_file_read_shared...
Generating docs for compound dumpi_file_seek...
Generating docs for compound dumpi_file_seek_shared...
Generating docs for compound dumpi_file_set_atomicity...
Generating docs for compound dumpi_file_set_errhandler...
Generating docs for compound dumpi_file_set_info...
Generating docs for compound dumpi_file_set_size...
Generating docs for compound dumpi_file_set_view...
Generating docs for compound dumpi_file_sync...
Generating docs for compound dumpi_file_write...
Generating docs for compound dumpi_file_write_all...
Generating docs for compound dumpi_file_write_all_begin...
Generating docs for compound dumpi_file_write_all_end...
Generating docs for compound dumpi_file_write_at...
Generating docs for compound dumpi_file_write_at_all...
Generating docs for compound dumpi_file_write_at_all_begin...
Generating docs for compound dumpi_file_write_at_all_end...
Generating docs for compound dumpi_file_write_ordered...
Generating docs for compound dumpi_file_write_ordered_begin...
Generating docs for compound dumpi_file_write_ordered_end...
Generating docs for compound dumpi_file_write_shared...
Generating docs for compound dumpi_finalize...
Generating docs for compound dumpi_finalized...
Generating docs for compound dumpi_footer...
Generating docs for compound dumpi_free_mem...
Generating docs for compound dumpi_func_call...
Generating docs for compound dumpi_gather...
Generating docs for compound dumpi_gatherv...
Generating docs for compound dumpi_get...
Generating docs for compound dumpi_get_address...
Generating docs for compound dumpi_get_count...
Generating docs for compound dumpi_get_elements...
Generating docs for compound dumpi_get_processor_name...
Generating docs for compound dumpi_get_version...
Generating docs for compound dumpi_global_t...
Generating docs for compound dumpi_graph_create...
Generating docs for compound dumpi_graph_get...
Generating docs for compound dumpi_graph_map...
Generating docs for compound dumpi_graph_neighbors...
Generating docs for compound dumpi_graph_neighbors_count...
Generating docs for compound dumpi_graphdims_get...
Generating docs for compound dumpi_grequest_complete...
Generating docs for compound dumpi_grequest_start...
Generating docs for compound dumpi_group_compare...
Generating docs for compound dumpi_group_difference...
Generating docs for compound dumpi_group_excl...
Generating docs for compound dumpi_group_free...
Generating docs for compound dumpi_group_incl...
Generating docs for compound dumpi_group_intersection...
Generating docs for compound dumpi_group_range_excl...
Generating docs for compound dumpi_group_range_incl...
Generating docs for compound dumpi_group_rank...
Generating docs for compound dumpi_group_size...
Generating docs for compound dumpi_group_translate_ranks...
Generating docs for compound dumpi_group_union...
Generating docs for compound dumpi_header...
Generating docs for compound dumpi_ibsend...
Generating docs for compound dumpi_info_create...
Generating docs for compound dumpi_info_delete...
Generating docs for compound dumpi_info_dup...
Generating docs for compound dumpi_info_free...
Generating docs for compound dumpi_info_get...
Generating docs for compound dumpi_info_get_nkeys...
Generating docs for compound dumpi_info_get_nthkey...
Generating docs for compound dumpi_info_get_valuelen...
Generating docs for compound dumpi_info_set...
Generating docs for compound dumpi_init...
Generating docs for compound dumpi_init_thread...
Generating docs for compound dumpi_initialized...
Generating docs for compound dumpi_intercomm_create...
Generating docs for compound dumpi_intercomm_merge...
Generating docs for compound dumpi_iprobe...
Generating docs for compound dumpi_irecv...
Generating docs for compound dumpi_irsend...
Generating docs for compound dumpi_is_thread_main...
Generating docs for compound dumpi_isend...
Generating docs for compound dumpi_issend...
Generating docs for compound dumpi_keyval_create...
Generating docs for compound dumpi_keyval_entry...
Generating docs for compound dumpi_keyval_free...
Generating docs for compound dumpi_keyval_record...
Generating docs for compound dumpi_lookup_name...
Generating docs for compound dumpi_op_create...
Generating docs for compound dumpi_op_free...
Generating docs for compound dumpi_open_port...
Generating docs for compound dumpi_outputs...
Generating docs for compound dumpi_pack...
Generating docs for compound dumpi_pack_external...
Generating docs for compound dumpi_pack_external_size...
Generating docs for compound dumpi_pack_size...
Generating docs for compound dumpi_perfinfo...
Generating docs for compound dumpi_probe...
Generating docs for compound dumpi_profile...
Generating docs for compound dumpi_publish_name...
Generating docs for compound dumpi_put...
Generating docs for compound dumpi_query_thread...
Generating docs for compound dumpi_recv...
Generating docs for compound dumpi_recv_init...
Generating docs for compound dumpi_reduce...
Generating docs for compound dumpi_reduce_scatter...
Generating docs for compound dumpi_register_datarep...
Generating docs for compound dumpi_request_free...
Generating docs for compound dumpi_request_get_status...
Generating docs for compound dumpi_rsend...
Generating docs for compound dumpi_rsend_init...
Generating docs for compound dumpi_scan...
Generating docs for compound dumpi_scatter...
Generating docs for compound dumpi_scatterv...
Generating docs for compound dumpi_send...
Generating docs for compound dumpi_send_init...
Generating docs for compound dumpi_sendrecv...
Generating docs for compound dumpi_sendrecv_replace...
Generating docs for compound dumpi_sizeof...
Generating docs for compound dumpi_ssend...
Generating docs for compound dumpi_ssend_init...
Generating docs for compound dumpi_start...
Generating docs for compound dumpi_startall...
Generating docs for compound dumpi_status...
Generating docs for compound dumpi_status_set_cancelled...
Generating docs for compound dumpi_status_set_elements...
Generating docs for compound dumpi_test...
Generating docs for compound dumpi_test_cancelled...
Generating docs for compound dumpi_testall...
Generating docs for compound dumpi_testany...
Generating docs for compound dumpi_testsome...
Generating docs for compound dumpi_time...
Generating docs for compound dumpi_topo_test...
Generating docs for compound dumpi_type_commit...
Generating docs for compound dumpi_type_contiguous...
Generating docs for compound dumpi_type_create_darray...
Generating docs for compound dumpi_type_create_hindexed...
Generating docs for compound dumpi_type_create_hvector...
Generating docs for compound dumpi_type_create_indexed_block...
Generating docs for compound dumpi_type_create_keyval...
Generating docs for compound dumpi_type_create_resized...
Generating docs for compound dumpi_type_create_struct...
Generating docs for compound dumpi_type_create_subarray...
Generating docs for compound dumpi_type_delete_attr...
Generating docs for compound dumpi_type_dup...
Generating docs for compound dumpi_type_extent...
Generating docs for compound dumpi_type_free...
Generating docs for compound dumpi_type_free_keyval...
Generating docs for compound dumpi_type_get_attr...
Generating docs for compound dumpi_type_get_contents...
Generating docs for compound dumpi_type_get_envelope...
Generating docs for compound dumpi_type_get_extent...
Generating docs for compound dumpi_type_get_name...
Generating docs for compound dumpi_type_get_true_extent...
Generating docs for compound dumpi_type_hindexed...
Generating docs for compound dumpi_type_hvector...
Generating docs for compound dumpi_type_indexed...
Generating docs for compound dumpi_type_lb...
Generating docs for compound dumpi_type_match_size...
Generating docs for compound dumpi_type_set_attr...
Generating docs for compound dumpi_type_set_name...
Generating docs for compound dumpi_type_size...
Generating docs for compound dumpi_type_struct...
Generating docs for compound dumpi_type_ub...
Generating docs for compound dumpi_type_vector...
Generating docs for compound dumpi_unpack...
Generating docs for compound dumpi_unpack_external...
Generating docs for compound dumpi_unpublish_name...
Generating docs for compound dumpi_wait...
Generating docs for compound dumpi_waitall...
Generating docs for compound dumpi_waitany...
Generating docs for compound dumpi_waitsome...
Generating docs for compound dumpi_win_call_errhandler...
Generating docs for compound dumpi_win_complete...
Generating docs for compound dumpi_win_create...
Generating docs for compound dumpi_win_create_errhandler...
Generating docs for compound dumpi_win_create_keyval...
Generating docs for compound dumpi_win_delete_attr...
Generating docs for compound dumpi_win_fence...
Generating docs for compound dumpi_win_free...
Generating docs for compound dumpi_win_free_keyval...
Generating docs for compound dumpi_win_get_attr...
Generating docs for compound dumpi_win_get_errhandler...
Generating docs for compound dumpi_win_get_group...
Generating docs for compound dumpi_win_get_name...
Generating docs for compound dumpi_win_lock...
Generating docs for compound dumpi_win_post...
Generating docs for compound dumpi_win_set_attr...
Generating docs for compound dumpi_win_set_errhandler...
Generating docs for compound dumpi_win_set_name...
Generating docs for compound dumpi_win_start...
Generating docs for compound dumpi_win_test...
Generating docs for compound dumpi_win_unlock...
Generating docs for compound dumpi_win_wait...
Generating docs for compound dumpi_wtick...
Generating docs for compound dumpi_wtime...
Generating docs for compound dumpio_test...
Generating docs for compound dumpio_testall...
Generating docs for compound dumpio_testany...
Generating docs for compound dumpio_testsome...
Generating docs for compound dumpio_wait...
Generating docs for compound dumpio_waitall...
Generating docs for compound dumpio_waitany...
Generating docs for compound dumpio_waitsome...
Generating docs for compound libundumpi_callbacks...
Generating docs for compound libundumpi_cbpair...
Generating namespace index...
Generating docs for namespace dumpi
Generating docs for compound dumpi::binbase...
Generating docs for compound dumpi::callbacks...
Generating docs for compound dumpi::comm...
Generating docs for compound dumpi::counter...
Generating docs for compound dumpi::exchanger...
Generating docs for compound dumpi::gatherbin...
/home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/dumpistats-gatherbin.h:138: warning: argument 'start_patt' of command @param is not found in the argument list of dumpi::gatherbin::gatherbin(const std::string &expression, bool accumulate)
/home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/dumpistats-gatherbin.h:138: warning: argument 'end_patt' of command @param is not found in the argument list of dumpi::gatherbin::gatherbin(const std::string &expression, bool accumulate)
/home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/dumpi/bin/dumpistats-gatherbin.h:144: warning: The following parameters of dumpi::gatherbin::gatherbin(const std::string &expression, bool accumulate) are not documented:
  parameter 'expression'
found
found
found
Generating docs for compound dumpi::group...
Generating docs for compound dumpi::handlerbase...
Generating docs for compound dumpi::lumper...
Generating docs for compound dumpi::metadata...
Generating docs for compound dumpi::otfcomplete...
Generating docs for nested compound dumpi::otfcomplete::args...
Generating docs for compound dumpi::otfwriter...
Generating docs for compound dumpi::perfcounter...
Generating docs for compound dumpi::recver...
Generating docs for compound dumpi::sender...
Generating docs for compound dumpi::sharedstate...
Generating docs for nested compound dumpi::sharedstate::commconstruct...
Generating docs for nested compound dumpi::sharedstate::commcreate...
Generating docs for nested compound dumpi::sharedstate::commdup...
Generating docs for nested compound dumpi::sharedstate::commsplit...
Generating docs for nested compound dumpi::sharedstate::entrant...
Generating docs for compound dumpi::timebin...
found
found
found
Generating docs for compound dumpi::timer...
Generating docs for compound dumpi::trace...
Generating docs for nested compound dumpi::trace::commentry...
Generating docs for nested compound dumpi::trace::groupentry...
Generating docs for nested compound dumpi::trace::typeentry...
Generating docs for compound dumpi::type...
Generating graph info page...
Generating directory documentation...
Generating index page...
Generating page index...
Generating module index...
Generating namespace index...
Generating namespace member index...
Generating annotated compound index...
Generating alphabetical compound index...
Generating hierarchical class index...
Generating member index...
Generating file index...
Generating file member index...
Generating example index...
finalizing index lists...
writing tag file...
lookup cache used 8226/65536 hits=64609 misses=8674
finished...
#+end_example

Il faut ensuite ajouter le chemin de la librairie dans
=LD_LIBRARY_PATH=.

***** HPL

Téléchargez le programme [[http://www.netlib.org/benchmark/hpl/hpl-2.2.tar.gz][ici]], ou en ligne de commande
#+begin_src sh :session foo
cd ~/Documents/Stage_LIG_2017/logiciels
wget http://www.netlib.org/benchmark/hpl/hpl-2.2.tar.gz
tar -xvf hpl-2.2.tar.gz
mv hpl-2.2 hpl
cd hpl/setup
sh make_generic
cp Make.UNKNOWN ../Make.linux
cd ..
#+end_src

Puis remplacer le contenu du fichier par celui ci dessous, en
remplacent les lignes avec commentaire #path/to.

#+BEGIN_EXAMPLE
#  
#  -- High Performance Computing Linpack Benchmark (HPL)                
#     HPL - 2.2 - February 24, 2016                          
#     Antoine P. Petitet                                                
#     University of Tennessee, Knoxville                                
#     Innovative Computing Laboratory                                 
#     (C) Copyright 2000-2008 All Rights Reserved                       
#                                                                       
#  -- Copyright notice and Licensing terms:                             
#                                                                       
#  Redistribution  and  use in  source and binary forms, with or without
#  modification, are  permitted provided  that the following  conditions
#  are met:                                                             
#                                                                       
#  1. Redistributions  of  source  code  must retain the above copyright
#  notice, this list of conditions and the following disclaimer.        
#                                                                       
#  2. Redistributions in binary form must reproduce  the above copyright
#  notice, this list of conditions,  and the following disclaimer in the
#  documentation and/or other materials provided with the distribution. 
#                                                                       
#  3. All  advertising  materials  mentioning  features  or  use of this
#  software must display the following acknowledgement:                 
#  This  product  includes  software  developed  at  the  University  of
#  Tennessee, Knoxville, Innovative Computing Laboratory.             
#                                                                       
#  4. The name of the  University,  the name of the  Laboratory,  or the
#  names  of  its  contributors  may  not  be used to endorse or promote
#  products  derived   from   this  software  without  specific  written
#  permission.                                                          
#                                                                       
#  -- Disclaimer:                                                       
#                                                                       
#  THIS  SOFTWARE  IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
#  ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES,  INCLUDING,  BUT NOT
#  LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
#  A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE UNIVERSITY
#  OR  CONTRIBUTORS  BE  LIABLE FOR ANY  DIRECT,  INDIRECT,  INCIDENTAL,
#  SPECIAL,  EXEMPLARY,  OR  CONSEQUENTIAL DAMAGES  (INCLUDING,  BUT NOT
#  LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
#  DATA OR PROFITS; OR BUSINESS INTERRUPTION)  HOWEVER CAUSED AND ON ANY
#  THEORY OF LIABILITY, WHETHER IN CONTRACT,  STRICT LIABILITY,  OR TORT
#  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
#  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. 
# ######################################################################
#  
# ----------------------------------------------------------------------
# - shell --------------------------------------------------------------
# ----------------------------------------------------------------------
#
SHELL        = /bin/sh
#
CD           = cd
CP           = cp
LN_S         = ln -s
MKDIR        = mkdir
RM           = /bin/rm -f
TOUCH        = touch
#
# ----------------------------------------------------------------------
# - Platform identifier ------------------------------------------------
# ----------------------------------------------------------------------
#
ARCH         = linux #ici mettre le même nom que l'extension donnée au fichier
#
# ----------------------------------------------------------------------
# - HPL Directory Structure / HPL library ------------------------------
# ----------------------------------------------------------------------
#
TOPdir       = $(HOME)/Documents/Stage_LIG_2017/logiciels/hpl #path/to/hpl 
INCdir       = $(TOPdir)/include
BINdir       = $(TOPdir)/bin/$(ARCH)
LIBdir       = $(TOPdir)/lib/$(ARCH)
#
HPLlib       = $(LIBdir)/libhpl.a 
#
# ----------------------------------------------------------------------
# - Message Passing library (MPI) --------------------------------------
# ----------------------------------------------------------------------
# MPinc tells the  C  compiler where to find the Message Passing library
# header files,  MPlib  is defined  to be the name of  the library to be 
# used. The variable MPdir is only used for defining MPinc and MPlib.
#
MPdir        = /usr/lib/mpich      #path/to/mpich
MPinc        = -I $(MPdir)/include
MPlib        = -L $(MPdir)/lib -L /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/install/lib -ldumpi #path/to/dumpi
#
# ----------------------------------------------------------------------
# - Linear Algebra library (BLAS or VSIPL) -----------------------------
# ----------------------------------------------------------------------
# LAinc tells the  C  compiler where to find the Linear Algebra  library
# header files,  LAlib  is defined  to be the name of  the library to be 
# used. The variable LAdir is only used for defining LAinc and LAlib.
#
LAdir        = /usr/lib/atlas-base #path/to/lib-atlas
LAinc        = 
LAlib        = $(LAdir)/libf77blas.a $(LAdir)/libatlas.a -lblas
#
# ----------------------------------------------------------------------
# - F77 / C interface --------------------------------------------------
# ----------------------------------------------------------------------
# You can skip this section  if and only if  you are not planning to use
# a  BLAS  library featuring a Fortran 77 interface.  Otherwise,  it  is
# necessary  to  fill out the  F2CDEFS  variable  with  the  appropriate
# options.  **One and only one**  option should be chosen in **each** of
# the 3 following categories:
#
# 1) name space (How C calls a Fortran 77 routine)
#
# -DAdd_              : all lower case and a suffixed underscore  (Suns,
#                       Intel, ...),                           [default]
# -DNoChange          : all lower case (IBM RS6000),
# -DUpCase            : all upper case (Cray),
# -DAdd__             : the FORTRAN compiler in use is f2c.
#
# 2) C and Fortran 77 integer mapping
#
# -DF77_INTEGER=int   : Fortran 77 INTEGER is a C int,         [default]
# -DF77_INTEGER=long  : Fortran 77 INTEGER is a C long,
# -DF77_INTEGER=short : Fortran 77 INTEGER is a C short.
#
# 3) Fortran 77 string handling
#
# -DStringSunStyle    : The string address is passed at the string loca-
#                       tion on the stack, and the string length is then
#                       passed as  an  F77_INTEGER  after  all  explicit
#                       stack arguments,                       [default]
# -DStringStructPtr   : The address  of  a  structure  is  passed  by  a
#                       Fortran 77  string,  and the structure is of the
#                       form: struct {char *cp; F77_INTEGER len;},
# -DStringStructVal   : A structure is passed by value for each  Fortran
#                       77 string,  and  the  structure is  of the form:
#                       struct {char *cp; F77_INTEGER len;},
# -DStringCrayStyle   : Special option for  Cray  machines,  which  uses
#                       Cray  fcd  (fortran  character  descriptor)  for
#                       interoperation.
#
F2CDEFS      = -DAdd_ -DF77_INTEGER=int -DStringSunStyle
#
# ----------------------------------------------------------------------
# - HPL includes / libraries / specifics -------------------------------
# ----------------------------------------------------------------------
#
HPL_INCLUDES = -I$(INCdir) -I$(INCdir)/$(ARCH) $(LAinc) $(MPinc)
HPL_LIBS     = $(HPLlib) $(LAlib) $(MPlib) -lmpl
#
# - Compile time options -----------------------------------------------
#
# -DHPL_COPY_L           force the copy of the panel L before bcast;
# -DHPL_CALL_CBLAS       call the cblas interface;
# -DHPL_CALL_VSIPL       call the vsip  library;
# -DHPL_DETAILED_TIMING  enable detailed timers;
#
# By default HPL will:
#    *) not copy L before broadcast,
#    *) call the BLAS Fortran 77 interface,
#    *) not display detailed timing information.
#
HPL_OPTS     = -DHPL_CALL_CBLAS
# 
# ----------------------------------------------------------------------
#
HPL_DEFS     = $(F2CDEFS) $(HPL_OPTS) $(HPL_INCLUDES) 
#
# ----------------------------------------------------------------------
# - Compilers / linkers - Optimization flags ---------------------------
# ----------------------------------------------------------------------
#
CC           = /usr/bin/mpicc
CCNOOPT      = $(HPL_DEFS) 
CCFLAGS      = $(HPL_DEFS) -fomit-frame-pointer -O3 -funroll-loops
#
LINKER       = /usr/bin/mpicc
LINKFLAGS    = $(CCFLAGS) -pthread
#
ARCHIVER     = ar
ARFLAGS      = r
RANLIB       = echo
#
# ----------------------------------------------------------------------
#+END_EXAMPLE

#+begin_src sh :session foo :results output :exports both 
make arch=linux
#+end_src

#+RESULTS:
#+begin_example
make -f Make.top startup_dir     arch=linux
make[1] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
mkdir include/linux
mkdir: impossible de créer le répertoire «include/linux»: Le fichier existe
Make.top:74 : la recette pour la cible « startup_dir » a échouée
make[1]: [startup_dir] Erreur 1 (ignorée)
mkdir lib
mkdir: impossible de créer le répertoire «lib»: Le fichier existe
Make.top:74 : la recette pour la cible « startup_dir » a échouée
make[1]: [startup_dir] Erreur 1 (ignorée)
mkdir lib/linux
mkdir: impossible de créer le répertoire «lib/linux»: Le fichier existe
Make.top:74 : la recette pour la cible « startup_dir » a échouée
make[1]: [startup_dir] Erreur 1 (ignorée)
mkdir bin
mkdir: impossible de créer le répertoire «bin»: Le fichier existe
Make.top:74 : la recette pour la cible « startup_dir » a échouée
make[1]: [startup_dir] Erreur 1 (ignorée)
mkdir bin/linux
mkdir: impossible de créer le répertoire «bin/linux»: Le fichier existe
Make.top:74 : la recette pour la cible « startup_dir » a échouée
make[1]: [startup_dir] Erreur 1 (ignorée)
make[1] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
make -f Make.top startup_src     arch=linux
make[1] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
make -f Make.top leaf le=src/auxil       arch=linux
make[2] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
( cd src/auxil ; mkdir linux )
mkdir: impossible de créer le répertoire «linux»: Le fichier existe
Make.top:188 : la recette pour la cible « leaf » a échouée
make[2]: [leaf] Erreur 1 (ignorée)
( cd src/auxil/linux ; \
            ln -s /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/Make.linux Make.inc )
ln: impossible de créer le lien symbolique 'Make.inc': Le fichier existe
Make.top:188 : la recette pour la cible « leaf » a échouée
make[2]: [leaf] Erreur 1 (ignorée)
make[2] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
make -f Make.top leaf le=src/blas        arch=linux
make[2] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
( cd src/blas ; mkdir linux )
mkdir: impossible de créer le répertoire «linux»: Le fichier existe
Make.top:188 : la recette pour la cible « leaf » a échouée
make[2]: [leaf] Erreur 1 (ignorée)
( cd src/blas/linux ; \
            ln -s /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/Make.linux Make.inc )
ln: impossible de créer le lien symbolique 'Make.inc': Le fichier existe
Make.top:188 : la recette pour la cible « leaf » a échouée
make[2]: [leaf] Erreur 1 (ignorée)
make[2] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
make -f Make.top leaf le=src/comm        arch=linux
make[2] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
( cd src/comm ; mkdir linux )
mkdir: impossible de créer le répertoire «linux»: Le fichier existe
Make.top:188 : la recette pour la cible « leaf » a échouée
make[2]: [leaf] Erreur 1 (ignorée)
( cd src/comm/linux ; \
            ln -s /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/Make.linux Make.inc )
ln: impossible de créer le lien symbolique 'Make.inc': Le fichier existe
Make.top:188 : la recette pour la cible « leaf » a échouée
make[2]: [leaf] Erreur 1 (ignorée)
make[2] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
make -f Make.top leaf le=src/grid        arch=linux
make[2] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
( cd src/grid ; mkdir linux )
mkdir: impossible de créer le répertoire «linux»: Le fichier existe
Make.top:188 : la recette pour la cible « leaf » a échouée
make[2]: [leaf] Erreur 1 (ignorée)
( cd src/grid/linux ; \
            ln -s /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/Make.linux Make.inc )
ln: impossible de créer le lien symbolique 'Make.inc': Le fichier existe
Make.top:188 : la recette pour la cible « leaf » a échouée
make[2]: [leaf] Erreur 1 (ignorée)
make[2] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
make -f Make.top leaf le=src/panel       arch=linux
make[2] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
( cd src/panel ; mkdir linux )
mkdir: impossible de créer le répertoire «linux»: Le fichier existe
Make.top:188 : la recette pour la cible « leaf » a échouée
make[2]: [leaf] Erreur 1 (ignorée)
( cd src/panel/linux ; \
            ln -s /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/Make.linux Make.inc )
ln: impossible de créer le lien symbolique 'Make.inc': Le fichier existe
Make.top:188 : la recette pour la cible « leaf » a échouée
make[2]: [leaf] Erreur 1 (ignorée)
make[2] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
make -f Make.top leaf le=src/pauxil      arch=linux
make[2] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
( cd src/pauxil ; mkdir linux )
mkdir: impossible de créer le répertoire «linux»: Le fichier existe
Make.top:188 : la recette pour la cible « leaf » a échouée
make[2]: [leaf] Erreur 1 (ignorée)
( cd src/pauxil/linux ; \
            ln -s /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/Make.linux Make.inc )
ln: impossible de créer le lien symbolique 'Make.inc': Le fichier existe
Make.top:188 : la recette pour la cible « leaf » a échouée
make[2]: [leaf] Erreur 1 (ignorée)
make[2] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
make -f Make.top leaf le=src/pfact       arch=linux
make[2] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
( cd src/pfact ; mkdir linux )
mkdir: impossible de créer le répertoire «linux»: Le fichier existe
Make.top:188 : la recette pour la cible « leaf » a échouée
make[2]: [leaf] Erreur 1 (ignorée)
( cd src/pfact/linux ; \
            ln -s /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/Make.linux Make.inc )
ln: impossible de créer le lien symbolique 'Make.inc': Le fichier existe
Make.top:188 : la recette pour la cible « leaf » a échouée
make[2]: [leaf] Erreur 1 (ignorée)
make[2] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
make -f Make.top leaf le=src/pgesv       arch=linux
make[2] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
( cd src/pgesv ; mkdir linux )
mkdir: impossible de créer le répertoire «linux»: Le fichier existe
Make.top:188 : la recette pour la cible « leaf » a échouée
make[2]: [leaf] Erreur 1 (ignorée)
( cd src/pgesv/linux ; \
            ln -s /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/Make.linux Make.inc )
ln: impossible de créer le lien symbolique 'Make.inc': Le fichier existe
Make.top:188 : la recette pour la cible « leaf » a échouée
make[2]: [leaf] Erreur 1 (ignorée)
make[2] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
make[1] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
make -f Make.top startup_tst     arch=linux
make[1] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
make -f Make.top leaf le=testing/matgen  arch=linux
make[2] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
( cd testing/matgen ; mkdir linux )
mkdir: impossible de créer le répertoire «linux»: Le fichier existe
Make.top:188 : la recette pour la cible « leaf » a échouée
make[2]: [leaf] Erreur 1 (ignorée)
( cd testing/matgen/linux ; \
            ln -s /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/Make.linux Make.inc )
ln: impossible de créer le lien symbolique 'Make.inc': Le fichier existe
Make.top:188 : la recette pour la cible « leaf » a échouée
make[2]: [leaf] Erreur 1 (ignorée)
make[2] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
make -f Make.top leaf le=testing/timer   arch=linux
make[2] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
( cd testing/timer ; mkdir linux )
mkdir: impossible de créer le répertoire «linux»: Le fichier existe
Make.top:188 : la recette pour la cible « leaf » a échouée
make[2]: [leaf] Erreur 1 (ignorée)
( cd testing/timer/linux ; \
            ln -s /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/Make.linux Make.inc )
ln: impossible de créer le lien symbolique 'Make.inc': Le fichier existe
Make.top:188 : la recette pour la cible « leaf » a échouée
make[2]: [leaf] Erreur 1 (ignorée)
make[2] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
make -f Make.top leaf le=testing/pmatgen arch=linux
make[2] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
( cd testing/pmatgen ; mkdir linux )
mkdir: impossible de créer le répertoire «linux»: Le fichier existe
Make.top:188 : la recette pour la cible « leaf » a échouée
make[2]: [leaf] Erreur 1 (ignorée)
( cd testing/pmatgen/linux ; \
            ln -s /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/Make.linux Make.inc )
ln: impossible de créer le lien symbolique 'Make.inc': Le fichier existe
Make.top:188 : la recette pour la cible « leaf » a échouée
make[2]: [leaf] Erreur 1 (ignorée)
make[2] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
make -f Make.top leaf le=testing/ptimer  arch=linux
make[2] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
( cd testing/ptimer ; mkdir linux )
mkdir: impossible de créer le répertoire «linux»: Le fichier existe
Make.top:188 : la recette pour la cible « leaf » a échouée
make[2]: [leaf] Erreur 1 (ignorée)
( cd testing/ptimer/linux ; \
            ln -s /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/Make.linux Make.inc )
ln: impossible de créer le lien symbolique 'Make.inc': Le fichier existe
Make.top:188 : la recette pour la cible « leaf » a échouée
make[2]: [leaf] Erreur 1 (ignorée)
make[2] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
make -f Make.top leaf le=testing/ptest   arch=linux
make[2] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
( cd testing/ptest ; mkdir linux )
mkdir: impossible de créer le répertoire «linux»: Le fichier existe
Make.top:188 : la recette pour la cible « leaf » a échouée
make[2]: [leaf] Erreur 1 (ignorée)
( cd testing/ptest/linux ; \
            ln -s /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/Make.linux Make.inc )
ln: impossible de créer le lien symbolique 'Make.inc': Le fichier existe
Make.top:188 : la recette pour la cible « leaf » a échouée
make[2]: [leaf] Erreur 1 (ignorée)
make[2] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
make[1] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
make -f Make.top refresh_src     arch=linux
make[1] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
cp makes/Make.auxil    src/auxil/linux/Makefile
cp makes/Make.blas     src/blas/linux/Makefile
cp makes/Make.comm     src/comm/linux/Makefile
cp makes/Make.grid     src/grid/linux/Makefile
cp makes/Make.panel    src/panel/linux/Makefile
cp makes/Make.pauxil   src/pauxil/linux/Makefile
cp makes/Make.pfact    src/pfact/linux/Makefile
cp makes/Make.pgesv    src/pgesv/linux/Makefile
make[1] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
make -f Make.top refresh_tst     arch=linux
make[1] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
cp makes/Make.matgen   testing/matgen/linux/Makefile
cp makes/Make.timer    testing/timer/linux/Makefile
cp makes/Make.pmatgen  testing/pmatgen/linux/Makefile
cp makes/Make.ptimer   testing/ptimer/linux/Makefile
cp makes/Make.ptest    testing/ptest/linux/Makefile
make[1] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
make -f Make.top refresh_src     arch=linux
make[1] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
cp makes/Make.auxil    src/auxil/linux/Makefile
cp makes/Make.blas     src/blas/linux/Makefile
cp makes/Make.comm     src/comm/linux/Makefile
cp makes/Make.grid     src/grid/linux/Makefile
cp makes/Make.panel    src/panel/linux/Makefile
cp makes/Make.pauxil   src/pauxil/linux/Makefile
cp makes/Make.pfact    src/pfact/linux/Makefile
cp makes/Make.pgesv    src/pgesv/linux/Makefile
make[1] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
make -f Make.top refresh_tst     arch=linux
make[1] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
cp makes/Make.matgen   testing/matgen/linux/Makefile
cp makes/Make.timer    testing/timer/linux/Makefile
cp makes/Make.pmatgen  testing/pmatgen/linux/Makefile
cp makes/Make.ptimer   testing/ptimer/linux/Makefile
cp makes/Make.ptest    testing/ptest/linux/Makefile
make[1] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
make -f Make.top build_src       arch=linux
make[1] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
( cd src/auxil/linux;         make )
make[2] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/src/auxil/linux »
/usr/bin/mpicc -o HPL_dlacpy.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_dlacpy.c
/usr/bin/mpicc -o HPL_dlatcpy.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_dlatcpy.c
/usr/bin/mpicc -o HPL_fprintf.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_fprintf.c
/usr/bin/mpicc -o HPL_warn.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_warn.c
/usr/bin/mpicc -o HPL_abort.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_abort.c
/usr/bin/mpicc -o HPL_dlaprnt.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_dlaprnt.c
/usr/bin/mpicc -o HPL_dlange.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_dlange.c
/usr/bin/mpicc -o HPL_dlamch.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include    ../HPL_dlamch.c
ar r /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/lib/linux/libhpl.a  HPL_dlacpy.o           HPL_dlatcpy.o          HPL_fprintf.o HPL_warn.o             HPL_abort.o            HPL_dlaprnt.o HPL_dlange.o HPL_dlamch.o
echo /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/lib/linux/libhpl.a 
/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/lib/linux/libhpl.a
touch lib.grd
make[2] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/src/auxil/linux »
( cd src/blas/linux;          make )
make[2] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/src/blas/linux »
/usr/bin/mpicc -o HPL_dcopy.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_dcopy.c
/usr/bin/mpicc -o HPL_daxpy.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_daxpy.c
/usr/bin/mpicc -o HPL_dscal.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_dscal.c
/usr/bin/mpicc -o HPL_idamax.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_idamax.c
/usr/bin/mpicc -o HPL_dgemv.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_dgemv.c
/usr/bin/mpicc -o HPL_dtrsv.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_dtrsv.c
/usr/bin/mpicc -o HPL_dger.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_dger.c
/usr/bin/mpicc -o HPL_dgemm.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_dgemm.c
/usr/bin/mpicc -o HPL_dtrsm.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_dtrsm.c
ar r /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/lib/linux/libhpl.a  HPL_dcopy.o            HPL_daxpy.o            HPL_dscal.o HPL_idamax.o           HPL_dgemv.o            HPL_dtrsv.o HPL_dger.o             HPL_dgemm.o            HPL_dtrsm.o
echo /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/lib/linux/libhpl.a 
/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/lib/linux/libhpl.a
touch lib.grd
make[2] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/src/blas/linux »
( cd src/comm/linux;          make )
make[2] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/src/comm/linux »
/usr/bin/mpicc -o HPL_1ring.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_1ring.c
/usr/bin/mpicc -o HPL_1rinM.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_1rinM.c
/usr/bin/mpicc -o HPL_2ring.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_2ring.c
/usr/bin/mpicc -o HPL_2rinM.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_2rinM.c
/usr/bin/mpicc -o HPL_blong.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_blong.c
/usr/bin/mpicc -o HPL_blonM.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_blonM.c
/usr/bin/mpicc -o HPL_packL.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_packL.c
/usr/bin/mpicc -o HPL_copyL.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_copyL.c
/usr/bin/mpicc -o HPL_binit.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_binit.c
/usr/bin/mpicc -o HPL_bcast.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_bcast.c
/usr/bin/mpicc -o HPL_bwait.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_bwait.c
/usr/bin/mpicc -o HPL_send.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_send.c
/usr/bin/mpicc -o HPL_recv.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_recv.c
/usr/bin/mpicc -o HPL_sdrv.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_sdrv.c
ar r /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/lib/linux/libhpl.a  HPL_1ring.o            HPL_1rinM.o            HPL_2ring.o HPL_2rinM.o            HPL_blong.o            HPL_blonM.o HPL_packL.o            HPL_copyL.o            HPL_binit.o HPL_bcast.o            HPL_bwait.o            HPL_send.o HPL_recv.o             HPL_sdrv.o
echo /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/lib/linux/libhpl.a 
/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/lib/linux/libhpl.a
touch lib.grd
make[2] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/src/comm/linux »
( cd src/grid/linux;          make )
make[2] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/src/grid/linux »
/usr/bin/mpicc -o HPL_grid_init.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_grid_init.c
/usr/bin/mpicc -o HPL_pnum.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pnum.c
/usr/bin/mpicc -o HPL_grid_info.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_grid_info.c
/usr/bin/mpicc -o HPL_grid_exit.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_grid_exit.c
/usr/bin/mpicc -o HPL_broadcast.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_broadcast.c
/usr/bin/mpicc -o HPL_reduce.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_reduce.c
/usr/bin/mpicc -o HPL_all_reduce.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_all_reduce.c
/usr/bin/mpicc -o HPL_barrier.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_barrier.c
/usr/bin/mpicc -o HPL_min.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_min.c
/usr/bin/mpicc -o HPL_max.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_max.c
/usr/bin/mpicc -o HPL_sum.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_sum.c
ar r /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/lib/linux/libhpl.a  HPL_grid_init.o        HPL_pnum.o             HPL_grid_info.o HPL_grid_exit.o        HPL_broadcast.o        HPL_reduce.o HPL_all_reduce.o       HPL_barrier.o          HPL_min.o HPL_max.o              HPL_sum.o
echo /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/lib/linux/libhpl.a 
/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/lib/linux/libhpl.a
touch lib.grd
make[2] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/src/grid/linux »
( cd src/panel/linux;         make )
make[2] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/src/panel/linux »
/usr/bin/mpicc -o HPL_pdpanel_new.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pdpanel_new.c
/usr/bin/mpicc -o HPL_pdpanel_init.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pdpanel_init.c
/usr/bin/mpicc -o HPL_pdpanel_disp.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pdpanel_disp.c
/usr/bin/mpicc -o HPL_pdpanel_free.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pdpanel_free.c
ar r /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/lib/linux/libhpl.a  HPL_pdpanel_new.o      HPL_pdpanel_init.o     HPL_pdpanel_disp.o HPL_pdpanel_free.o
echo /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/lib/linux/libhpl.a 
/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/lib/linux/libhpl.a
touch lib.grd
make[2] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/src/panel/linux »
( cd src/pauxil/linux;        make )
make[2] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/src/pauxil/linux »
/usr/bin/mpicc -o HPL_indxg2l.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_indxg2l.c
/usr/bin/mpicc -o HPL_indxg2lp.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_indxg2lp.c
/usr/bin/mpicc -o HPL_indxg2p.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_indxg2p.c
/usr/bin/mpicc -o HPL_indxl2g.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_indxl2g.c
/usr/bin/mpicc -o HPL_infog2l.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_infog2l.c
/usr/bin/mpicc -o HPL_numroc.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_numroc.c
/usr/bin/mpicc -o HPL_numrocI.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_numrocI.c
/usr/bin/mpicc -o HPL_dlaswp00N.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_dlaswp00N.c
/usr/bin/mpicc -o HPL_dlaswp10N.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_dlaswp10N.c
/usr/bin/mpicc -o HPL_dlaswp01N.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_dlaswp01N.c
/usr/bin/mpicc -o HPL_dlaswp01T.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_dlaswp01T.c
/usr/bin/mpicc -o HPL_dlaswp02N.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_dlaswp02N.c
/usr/bin/mpicc -o HPL_dlaswp03N.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_dlaswp03N.c
/usr/bin/mpicc -o HPL_dlaswp03T.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_dlaswp03T.c
/usr/bin/mpicc -o HPL_dlaswp04N.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_dlaswp04N.c
/usr/bin/mpicc -o HPL_dlaswp04T.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_dlaswp04T.c
/usr/bin/mpicc -o HPL_dlaswp05N.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_dlaswp05N.c
/usr/bin/mpicc -o HPL_dlaswp05T.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_dlaswp05T.c
/usr/bin/mpicc -o HPL_dlaswp06N.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_dlaswp06N.c
/usr/bin/mpicc -o HPL_dlaswp06T.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_dlaswp06T.c
/usr/bin/mpicc -o HPL_pwarn.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pwarn.c
/usr/bin/mpicc -o HPL_pabort.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pabort.c
/usr/bin/mpicc -o HPL_pdlaprnt.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pdlaprnt.c
/usr/bin/mpicc -o HPL_pdlamch.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pdlamch.c
/usr/bin/mpicc -o HPL_pdlange.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pdlange.c
ar r /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/lib/linux/libhpl.a  HPL_indxg2l.o          HPL_indxg2lp.o         HPL_indxg2p.o HPL_indxl2g.o          HPL_infog2l.o          HPL_numroc.o HPL_numrocI.o          HPL_dlaswp00N.o        HPL_dlaswp10N.o HPL_dlaswp01N.o        HPL_dlaswp01T.o        HPL_dlaswp02N.o HPL_dlaswp03N.o        HPL_dlaswp03T.o        HPL_dlaswp04N.o HPL_dlaswp04T.o        HPL_dlaswp05N.o        HPL_dlaswp05T.o HPL_dlaswp06N.o        HPL_dlaswp06T.o        HPL_pwarn.o HPL_pabort.o           HPL_pdlaprnt.o         HPL_pdlamch.o HPL_pdlange.o
echo /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/lib/linux/libhpl.a 
/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/lib/linux/libhpl.a
touch lib.grd
make[2] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/src/pauxil/linux »
( cd src/pfact/linux;         make )
make[2] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/src/pfact/linux »
/usr/bin/mpicc -o HPL_dlocmax.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_dlocmax.c
/usr/bin/mpicc -o HPL_dlocswpN.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_dlocswpN.c
/usr/bin/mpicc -o HPL_dlocswpT.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_dlocswpT.c
/usr/bin/mpicc -o HPL_pdmxswp.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pdmxswp.c
/usr/bin/mpicc -o HPL_pdpancrN.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pdpancrN.c
/usr/bin/mpicc -o HPL_pdpancrT.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pdpancrT.c
/usr/bin/mpicc -o HPL_pdpanllN.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pdpanllN.c
/usr/bin/mpicc -o HPL_pdpanllT.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pdpanllT.c
/usr/bin/mpicc -o HPL_pdpanrlN.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pdpanrlN.c
/usr/bin/mpicc -o HPL_pdpanrlT.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pdpanrlT.c
/usr/bin/mpicc -o HPL_pdrpanllN.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pdrpanllN.c
/usr/bin/mpicc -o HPL_pdrpanllT.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pdrpanllT.c
/usr/bin/mpicc -o HPL_pdrpancrN.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pdrpancrN.c
/usr/bin/mpicc -o HPL_pdrpancrT.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pdrpancrT.c
/usr/bin/mpicc -o HPL_pdrpanrlN.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pdrpanrlN.c
/usr/bin/mpicc -o HPL_pdrpanrlT.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pdrpanrlT.c
/usr/bin/mpicc -o HPL_pdfact.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pdfact.c
ar r /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/lib/linux/libhpl.a  HPL_dlocmax.o          HPL_dlocswpN.o         HPL_dlocswpT.o HPL_pdmxswp.o          HPL_pdpancrN.o         HPL_pdpancrT.o HPL_pdpanllN.o         HPL_pdpanllT.o         HPL_pdpanrlN.o HPL_pdpanrlT.o         HPL_pdrpanllN.o        HPL_pdrpanllT.o HPL_pdrpancrN.o        HPL_pdrpancrT.o        HPL_pdrpanrlN.o HPL_pdrpanrlT.o        HPL_pdfact.o
echo /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/lib/linux/libhpl.a 
/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/lib/linux/libhpl.a
touch lib.grd
make[2] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/src/pfact/linux »
( cd src/pgesv/linux;         make )
make[2] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/src/pgesv/linux »
/usr/bin/mpicc -o HPL_pipid.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pipid.c
/usr/bin/mpicc -o HPL_plindx0.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_plindx0.c
/usr/bin/mpicc -o HPL_pdlaswp00N.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pdlaswp00N.c
/usr/bin/mpicc -o HPL_pdlaswp00T.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pdlaswp00T.c
/usr/bin/mpicc -o HPL_perm.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_perm.c
/usr/bin/mpicc -o HPL_logsort.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_logsort.c
/usr/bin/mpicc -o HPL_plindx10.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_plindx10.c
/usr/bin/mpicc -o HPL_plindx1.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_plindx1.c
/usr/bin/mpicc -o HPL_spreadN.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_spreadN.c
/usr/bin/mpicc -o HPL_spreadT.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_spreadT.c
/usr/bin/mpicc -o HPL_rollN.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_rollN.c
/usr/bin/mpicc -o HPL_rollT.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_rollT.c
/usr/bin/mpicc -o HPL_equil.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_equil.c
/usr/bin/mpicc -o HPL_pdlaswp01N.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pdlaswp01N.c
/usr/bin/mpicc -o HPL_pdlaswp01T.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pdlaswp01T.c
/usr/bin/mpicc -o HPL_pdupdateNN.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pdupdateNN.c
/usr/bin/mpicc -o HPL_pdupdateNT.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pdupdateNT.c
/usr/bin/mpicc -o HPL_pdupdateTN.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pdupdateTN.c
/usr/bin/mpicc -o HPL_pdupdateTT.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pdupdateTT.c
/usr/bin/mpicc -o HPL_pdtrsv.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pdtrsv.c
/usr/bin/mpicc -o HPL_pdgesv0.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pdgesv0.c
/usr/bin/mpicc -o HPL_pdgesvK1.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pdgesvK1.c
/usr/bin/mpicc -o HPL_pdgesvK2.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pdgesvK2.c
/usr/bin/mpicc -o HPL_pdgesv.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pdgesv.c
ar r /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/lib/linux/libhpl.a  HPL_pipid.o            HPL_plindx0.o          HPL_pdlaswp00N.o HPL_pdlaswp00T.o       HPL_perm.o             HPL_logsort.o HPL_plindx10.o         HPL_plindx1.o          HPL_spreadN.o HPL_spreadT.o          HPL_rollN.o            HPL_rollT.o HPL_equil.o            HPL_pdlaswp01N.o       HPL_pdlaswp01T.o HPL_pdupdateNN.o       HPL_pdupdateNT.o       HPL_pdupdateTN.o HPL_pdupdateTT.o       HPL_pdtrsv.o           HPL_pdgesv0.o HPL_pdgesvK1.o         HPL_pdgesvK2.o         HPL_pdgesv.o
echo /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/lib/linux/libhpl.a 
/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/lib/linux/libhpl.a
touch lib.grd
make[2] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/src/pgesv/linux »
make[1] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
make -f Make.top build_tst       arch=linux
make[1] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
( cd testing/matgen/linux;    make )
make[2] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/testing/matgen/linux »
/usr/bin/mpicc -o HPL_dmatgen.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_dmatgen.c
/usr/bin/mpicc -o HPL_ladd.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_ladd.c
/usr/bin/mpicc -o HPL_lmul.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_lmul.c
/usr/bin/mpicc -o HPL_xjumpm.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_xjumpm.c
/usr/bin/mpicc -o HPL_jumpit.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_jumpit.c
/usr/bin/mpicc -o HPL_rand.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_rand.c
/usr/bin/mpicc -o HPL_setran.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_setran.c
ar r /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/lib/linux/libhpl.a  HPL_dmatgen.o          HPL_ladd.o             HPL_lmul.o HPL_xjumpm.o           HPL_jumpit.o           HPL_rand.o HPL_setran.o
echo /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/lib/linux/libhpl.a 
/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/lib/linux/libhpl.a
touch lib.grd
make[2] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/testing/matgen/linux »
( cd testing/timer/linux;     make )
make[2] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/testing/timer/linux »
/usr/bin/mpicc -o HPL_timer.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_timer.c
/usr/bin/mpicc -o HPL_timer_cputime.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_timer_cputime.c
/usr/bin/mpicc -o HPL_timer_walltime.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_timer_walltime.c
ar r /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/lib/linux/libhpl.a  HPL_timer.o            HPL_timer_cputime.o    HPL_timer_walltime.o
echo /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/lib/linux/libhpl.a 
/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/lib/linux/libhpl.a
touch lib.grd
make[2] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/testing/timer/linux »
( cd testing/pmatgen/linux;   make )
make[2] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/testing/pmatgen/linux »
/usr/bin/mpicc -o HPL_pdmatgen.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pdmatgen.c
ar r /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/lib/linux/libhpl.a  HPL_pdmatgen.o
echo /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/lib/linux/libhpl.a 
/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/lib/linux/libhpl.a
touch lib.grd
make[2] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/testing/pmatgen/linux »
( cd testing/ptimer/linux;    make )
make[2] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/testing/ptimer/linux »
/usr/bin/mpicc -o HPL_ptimer.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_ptimer.c
/usr/bin/mpicc -o HPL_ptimer_cputime.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_ptimer_cputime.c
/usr/bin/mpicc -o HPL_ptimer_walltime.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_ptimer_walltime.c
ar r /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/lib/linux/libhpl.a  HPL_ptimer.o           HPL_ptimer_cputime.o   HPL_ptimer_walltime.o
echo /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/lib/linux/libhpl.a 
/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/lib/linux/libhpl.a
touch lib.grd
make[2] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/testing/ptimer/linux »
( cd testing/ptest/linux;     make )
make[2] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/testing/ptest/linux »
/usr/bin/mpicc -o HPL_pddriver.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pddriver.c
/usr/bin/mpicc -o HPL_pdinfo.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pdinfo.c
../HPL_pdinfo.c: In function ‘HPL_pdinfo’:
../HPL_pdinfo.c:304:7: warning: ignoring return value of ‘fgets’, declared with attribute warn_unused_result [-Wunused-result]
       (void) fgets( line, HPL_LINE_MAX - 2, infp );
       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
../HPL_pdinfo.c:305:7: warning: ignoring return value of ‘fgets’, declared with attribute warn_unused_result [-Wunused-result]
       (void) fgets( auth, HPL_LINE_MAX - 2, infp );
       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
../HPL_pdinfo.c:309:7: warning: ignoring return value of ‘fgets’, declared with attribute warn_unused_result [-Wunused-result]
       (void) fgets( line, HPL_LINE_MAX - 2, infp );
       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
../HPL_pdinfo.c:311:7: warning: ignoring return value of ‘fgets’, declared with attribute warn_unused_result [-Wunused-result]
       (void) fgets( line, HPL_LINE_MAX - 2, infp );
       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
../HPL_pdinfo.c:327:7: warning: ignoring return value of ‘fgets’, declared with attribute warn_unused_result [-Wunused-result]
       (void) fgets( line, HPL_LINE_MAX - 2, infp );
       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
../HPL_pdinfo.c:337:7: warning: ignoring return value of ‘fgets’, declared with attribute warn_unused_result [-Wunused-result]
       (void) fgets( line, HPL_LINE_MAX - 2, infp ); lineptr = line;
       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
../HPL_pdinfo.c:351:7: warning: ignoring return value of ‘fgets’, declared with attribute warn_unused_result [-Wunused-result]
       (void) fgets( line, HPL_LINE_MAX - 2, infp );
       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
../HPL_pdinfo.c:361:7: warning: ignoring return value of ‘fgets’, declared with attribute warn_unused_result [-Wunused-result]
       (void) fgets( line, HPL_LINE_MAX - 2, infp ); lineptr = line;
       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
../HPL_pdinfo.c:375:7: warning: ignoring return value of ‘fgets’, declared with attribute warn_unused_result [-Wunused-result]
       (void) fgets( line, HPL_LINE_MAX - 2, infp );
       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
../HPL_pdinfo.c:379:7: warning: ignoring return value of ‘fgets’, declared with attribute warn_unused_result [-Wunused-result]
       (void) fgets( line, HPL_LINE_MAX - 2, infp );
       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
../HPL_pdinfo.c:389:7: warning: ignoring return value of ‘fgets’, declared with attribute warn_unused_result [-Wunused-result]
       (void) fgets( line, HPL_LINE_MAX - 2, infp ); lineptr = line;
       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
../HPL_pdinfo.c:400:7: warning: ignoring return value of ‘fgets’, declared with attribute warn_unused_result [-Wunused-result]
       (void) fgets( line, HPL_LINE_MAX - 2, infp ); lineptr = line;
       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
../HPL_pdinfo.c:426:7: warning: ignoring return value of ‘fgets’, declared with attribute warn_unused_result [-Wunused-result]
       (void) fgets( line, HPL_LINE_MAX - 2, infp );
       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
../HPL_pdinfo.c:431:7: warning: ignoring return value of ‘fgets’, declared with attribute warn_unused_result [-Wunused-result]
       (void) fgets( line, HPL_LINE_MAX - 2, infp );
       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
../HPL_pdinfo.c:440:7: warning: ignoring return value of ‘fgets’, declared with attribute warn_unused_result [-Wunused-result]
       (void) fgets( line, HPL_LINE_MAX - 2, infp ); lineptr = line;
       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
../HPL_pdinfo.c:453:7: warning: ignoring return value of ‘fgets’, declared with attribute warn_unused_result [-Wunused-result]
       (void) fgets( line, HPL_LINE_MAX - 2, infp );
       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
../HPL_pdinfo.c:462:7: warning: ignoring return value of ‘fgets’, declared with attribute warn_unused_result [-Wunused-result]
       (void) fgets( line, HPL_LINE_MAX - 2, infp ); lineptr = line;
       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
../HPL_pdinfo.c:476:7: warning: ignoring return value of ‘fgets’, declared with attribute warn_unused_result [-Wunused-result]
       (void) fgets( line, HPL_LINE_MAX - 2, infp );
       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
../HPL_pdinfo.c:485:7: warning: ignoring return value of ‘fgets’, declared with attribute warn_unused_result [-Wunused-result]
       (void) fgets( line, HPL_LINE_MAX - 2, infp ); lineptr = line;
       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
../HPL_pdinfo.c:499:7: warning: ignoring return value of ‘fgets’, declared with attribute warn_unused_result [-Wunused-result]
       (void) fgets( line, HPL_LINE_MAX - 2, infp );
       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
../HPL_pdinfo.c:508:7: warning: ignoring return value of ‘fgets’, declared with attribute warn_unused_result [-Wunused-result]
       (void) fgets( line, HPL_LINE_MAX - 2, infp ); lineptr = line;
       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
../HPL_pdinfo.c:521:7: warning: ignoring return value of ‘fgets’, declared with attribute warn_unused_result [-Wunused-result]
       (void) fgets( line, HPL_LINE_MAX - 2, infp );
       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
../HPL_pdinfo.c:530:7: warning: ignoring return value of ‘fgets’, declared with attribute warn_unused_result [-Wunused-result]
       (void) fgets( line, HPL_LINE_MAX - 2, infp ); lineptr = line;
       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
../HPL_pdinfo.c:546:7: warning: ignoring return value of ‘fgets’, declared with attribute warn_unused_result [-Wunused-result]
       (void) fgets( line, HPL_LINE_MAX - 2, infp );
       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
../HPL_pdinfo.c:555:7: warning: ignoring return value of ‘fgets’, declared with attribute warn_unused_result [-Wunused-result]
       (void) fgets( line, HPL_LINE_MAX - 2, infp ); lineptr = line;
       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
../HPL_pdinfo.c:570:7: warning: ignoring return value of ‘fgets’, declared with attribute warn_unused_result [-Wunused-result]
       (void) fgets( line, HPL_LINE_MAX - 2, infp );
       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
../HPL_pdinfo.c:579:7: warning: ignoring return value of ‘fgets’, declared with attribute warn_unused_result [-Wunused-result]
       (void) fgets( line, HPL_LINE_MAX - 2, infp );
       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
../HPL_pdinfo.c:585:7: warning: ignoring return value of ‘fgets’, declared with attribute warn_unused_result [-Wunused-result]
       (void) fgets( line, HPL_LINE_MAX - 2, infp );
       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
../HPL_pdinfo.c:591:7: warning: ignoring return value of ‘fgets’, declared with attribute warn_unused_result [-Wunused-result]
       (void) fgets( line, HPL_LINE_MAX - 2, infp );
       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
../HPL_pdinfo.c:597:7: warning: ignoring return value of ‘fgets’, declared with attribute warn_unused_result [-Wunused-result]
       (void) fgets( line, HPL_LINE_MAX - 2, infp );
       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
../HPL_pdinfo.c:603:7: warning: ignoring return value of ‘fgets’, declared with attribute warn_unused_result [-Wunused-result]
       (void) fgets( line, HPL_LINE_MAX - 2, infp );
       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/usr/bin/mpicc -o HPL_pdtest.o -c -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops  ../HPL_pdtest.c
/usr/bin/mpicc -DAdd_ -DF77_INTEGER=int -DStringSunStyle -DHPL_CALL_CBLAS -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include -I/home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/include/linux  -I /usr/lib/mpich/include  -fomit-frame-pointer -O3 -funroll-loops -pthread -o /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/bin/linux/xhpl HPL_pddriver.o         HPL_pdinfo.o           HPL_pdtest.o /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/lib/linux/libhpl.a  /usr/lib/atlas-base/libf77blas.a /usr/lib/atlas-base/libatlas.a -lblas -L /usr/lib/mpich/lib -L /home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/install/lib -ldumpi -lmpl
make /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/bin/linux/HPL.dat
make[3] : on entre dans le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/testing/ptest/linux »
( cp ../HPL.dat /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/bin/linux )
make[3] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/testing/ptest/linux »
touch dexe.grd
make[2] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl/testing/ptest/linux »
make[1] : on quitte le répertoire « /home/chevamax/Documents/Stage_LIG_2017/logiciels/hpl »
#+end_example

On peut ensuite lancer une execution d'HPL dans =~/hpl/bin/linux=. Il
faut modifier le fichier HPL.dat pour les paramètres de l'execution,
et ensuite lancer *xhpl* via *mpirun* pour avoir des traces.

****** Exemple de fichier HPL.dat
#+BEGIN_EXAMPLE
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any) 
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
18048         Ns
1            # of NBs
192           NBs
0            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
2            Ps
2            Qs
16.0         threshold
1            # of panel fact
2            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
1            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM)
1            # of lookahead depth
1            DEPTHs (>=0)
2            SWAP (0=bin-exch,1=long,2=mix)
64           swapping threshold
0            L1 in (0=transposed,1=no-transposed) form
0            U  in (0=transposed,1=no-transposed) form
1            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
#+END_EXAMPLE

puis lancer avec  =mpirun -n 4 ./xhpl=

On voit ensuite les fichiers dumpi dans le répertoire.
On peut les convertirs en texte via cette commande
=/path/to/dumpi/bin/dumpi2ascii <nomfichier.bin>=

***** ROSS
#+begin_src sh :session foo :results output :exports both 
cd ~/Documents/Stage_LIG_2017/logiciels
git clone -b master --single-branch git@github.com:carothersc/ROSS.git
cd ROSS
mkdir build
cd build
ARCH=x86_64 CC=mpicc CXX=mpicxx cmake -DCMAKE_INSTALL_PREFIX=../install ../
make -j 3
make install
#+end_src

***** CODES
#+begin_src sh :session foo
cd ~/Documents/Stage_LIG_2017/logiciels
wget ftp://ftp.mcs.anl.gov/pub/CODES/releases/codes-0.5.2.tar.gz
tar -xvf codes-0.5.2.tar.gz
mv codes-0.5.2 CODES
cd CODES
./prepare.sh
mkdir build
cd build
../configure --with-dumpi=/home/chevamax/Documents/Stage_LIG_2017/logiciels/sst-dumpi/install --prefix=/home/chevamax/Documents/Stage_LIG_2017/logiciels/CODES/install CC=mpicc PKG_CONFIG_PATH=../../ROSS/install/lib/pkgconfig
make && make install
make tests && make check
#+end_src

***** Tout est installé !


**** Réunion avec Florence
Il faut que je fasse une trace HPL sur 4 et 16 noeuds, puis que je la
rejoue sur CODES. Il faut que je trouve un moyen de visualiser les
traces. Ensuite je tenterais Grid5000 (cf [[https://www.grid5000.fr/mediawiki/index.php/Getting_Started][gettingStarted]]).

**** Traces

***** 4 noeuds
- Fichier HPL.dat
#+BEGIN_EXAMPLE
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any) 
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
20352         Ns
1            # of NBs
192           NBs
0            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
2            Ps
2            Qs
16.0         threshold
1            # of panel fact
2            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
1            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM)
1            # of lookahead depth
1            DEPTHs (>=0)
2            SWAP (0=bin-exch,1=long,2=mix)
64           swapping threshold
0            L1 in (0=transposed,1=no-transposed) form
0            U  in (0=transposed,1=no-transposed) form
1            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
#+END_EXAMPLE

#+begin_src sh :session foo :results output :exports both 
cd ~/Documents/Stage_LIG_2017/logiciels/hpl/bin/linux
mpirun -n 4 ./xhpl
#+end_src

#+RESULTS:
#+BEGIN_EXAMPLE
================================================================================
HPLinpack 2.2  --  High-Performance Linpack benchmark  --   February 24, 2016
Written by A. Petitet and R. Clint Whaley,  Innovative Computing Laboratory, UTK
Modified by Piotr Luszczek, Innovative Computing Laboratory, UTK
Modified by Julien Langou, University of Colorado Denver
================================================================================

An explanation of the input/output parameters follows:
T/V    : Wall time / encoded variant.
N      : The order of the coefficient matrix A.
NB     : The partitioning blocking factor.
P      : The number of process rows.
Q      : The number of process columns.
Time   : Time in seconds to solve the linear system.
Gflops : Rate of execution for solving the linear system.

The following parameter values will be used:

N      :   20352 
NB     :     192 
PMAP   : Row-major process mapping
P      :       2 
Q      :       2 
PFACT  :   Right 
NBMIN  :       4 
NDIV   :       2 
RFACT  :   Crout 
BCAST  :  1ringM 
DEPTH  :       1 
SWAP   : Mix (threshold = 64)
L1     : transposed form
U      : transposed form
EQUIL  : yes
ALIGN  : 8 double precision words

--------------------------------------------------------------------------------

- The matrix A is randomly generated for each test.
- The following scaled residual check will be computed:
      ||Ax-b||_oo / ( eps * ( || x ||_oo * || A ||_oo + || b ||_oo ) * N )
- The relative machine precision (eps) is taken to be               1.110223e-16
- Computational tests pass if scaled residuals are less than                16.0

================================================================================
T/V                N    NB     P     Q               Time                 Gflops
--------------------------------------------------------------------------------
WR11C2R4       20352   192     2     2             422.90              1.329e+01
HPL_pdgesv() start time Mon May 22 11:02:30 2017

HPL_pdgesv() end time   Mon May 22 11:09:33 2017

--------------------------------------------------------------------------------
||Ax-b||_oo/(eps*(||A||_oo*||x||_oo+||b||_oo)*N)=        0.0012039 ...... PASSED
================================================================================

Finished      1 tests with the following results:
              1 tests completed and passed residual checks,
              0 tests completed and failed residual checks,
              0 tests skipped because of illegal input values.
--------------------------------------------------------------------------------

End of Tests.
================================================================================
#+END_EXAMPLE

***** 16 noeuds
- Fichier HPL.dat
  
***** Visualisation
Il existe CommGram pour visualiser :
http://digitalcommons.unl.edu/cgi/viewcontent.cgi?article=1101&context=computerscidiss
Mais je trouve pas l'outil sur le web.
Beaucoup d'outils utilisent pourtant DUMPI, il doit bien y avoir
quelque chose pour les analyser autre que l'outil
fourni... http://portal.nersc.gov/project/CAL/designforward.htm

https://xgitlab.cels.anl.gov/gonsie/codes/raw/592f7e82f9c2ad611471d43d59740990e73c4725/src/network-workloads/conf/modelnet-mpi-test-dfly-amg-1728.conf

La doc CODES sur les traces n'est pas à jour, elle date d'avant le merge
entre codes-base et codes-net, ce qui n'aide pas...

SST possède des outils pour la visualisation mais rien à voir avec
DUMPI j'ai l'impression :
http://sst.sandia.gov/files/sstmacro_manual.pdf
Partie 3.9 et suite.

Ici quelques exemples de SST :
http://sst.sandia.gov/doxygen/sstmacro/dumpitracer.html
https://calccrypto.github.io/sst-macro/page_DumpiTutorial.html

pour le convertisseur otf de dumpi, il faut la libotf (et reinstaller
dumpi). On peut aussi générer des tests pour DUMPI (je sais pas si
c'est utile).

De base avec DUMPI on a accès à ca : 
#+begin_example
dumpistats --help
dumpistats:  Extract statistics from DUMPI trace files
Options:
   (-h|--help)                Print help screen and exit
   (-v|--verbose)             Verbose status output
   (-b|--bin)      timerange  Define a collection time range
   (-m|--mark)     /crt/end/  Create/end a bin at annotations
   (-g|--gather)   /crt/end/  Accumulate to an annotated bin
   (-c|--count)    funcname   Count entries into a function
   (-t|--time)     funcname   Accumulate time in a function
   (-s|--sent)     funcname   Count bytes sent by a function
   (-r|--recvd)    funcname   Count bytes recvd by function
   (-x|--exchange) funcname   Full send/recv exchange info
   (-l|--lump)     funcname   Lump (bin) messages by size
   (-p|--perfctr)  funcname   PAPI perfcounter info
   (-i|--in)       metafile   DUMPI metafile (required)
   (-o|--out)      fileroot   Output file root (required)

The timerange has the form:
  (all | mpi | BOUND to BOUND) [by TIME]
    where BOUND the form:
      (IDENTITY | TIME) [(+|-) TIME]
    and IDENTITY is:
      start | end | init | finalize | TIME
    and TIME is:
      (hh:)?(mm:)?[0-9]0-9+(.[0-9]*)?

The funcname has the form:
  all | mpi | non-mpi | sends | recvs | coll | wait | io | RE
    where RE is a case-insensitive regular expression
    (e.g. "MPI_Wait.*" or "mpio?_(wait.*|test.*))"
  All regular expressions are implicitly flanked by ^ and $,
  so "mpi_.?send" does not match MPI_Sendrecv

The annotated bins (-m and -g) use regular expressions
with a format similar to sed basic regular expressions, so:    -m '/begin bin/end bin/'
    -m '!begin bin!end bin!i'
    -g '| +start loop [0-9]+ *$|end loop [0-9]+$|'
are all valid annotations (note that backreferences are 
not allowed).  Escaped characters other than the delimiter
are passed directly to the regular expression parser.

Example 1:
  dumpistats --bin=all --time=mpi --time=other \
        -i dumpi.meta -o stats
     Writes a file called stats-0.dat with three columns:
       1:  The rank of each MPI node
       2:  Aggregate time spent in MPI calls
       3:  Aggregate time spent outside MPI calls

Example 2
  dumpistats --bin='init to finalize by 1:00' \ 
        --count=mpi_.*send -i dumpi.meta -o stats
     Writes files with send counts binned into 1 minute
     intervals.

Example 3
  dumpistats  --bin='begin+10 to end-10' -s all -r all \
         -i dumpi.meta -o stats \
      Writes a new file containing bytes sent and received
      starting 10 seconds after first and ending 10 seconds
      before last simulation timestamp
chevamax@Black-Pearl-2:~/Documents/Stag
#+end_example
*** 2017-05-23 mardi
**** Exemple de trace
***** ASCII
Il y a trois parties distinctes dans les fichier ASCII, qui se
répètent.
#+BEGIN_EXAMPLE
int source=1
int tag=1001
MPI_Comm comm=6 (user-defined-comm)
MPI_Request request=[2]
MPI_Irecv returning at walltime 59684.193756739, cputime 5.265173058 seconds in thread 0.
MPI_Send entering at walltime 59684.193758170, cputime 5.265174471 seconds in thread 0.
int count=388
MPI_Datatype datatype=14 (MPI_DOUBLE)
int dest=1
int tag=1001
MPI_Comm comm=6 (user-defined-comm)
MPI_Send returning at walltime 59684.193759116, cputime 5.265175437 seconds in thread 0.
MPI_Wait entering at walltime 59684.193760267, cputime 5.265176611 seconds in thread 0.
MPI_Request request=[2]
MPI_Status status=[{bytes=1568, cancelled=0, source=1, tag=1001, error=1}]
MPI_Wait returning at walltime 59684.193761705, cputime 5.265178044 seconds in thread 0.
MPI_Irecv entering at walltime 59684.193828567, cputime 5.265244802 seconds in thread 0.
int count=196
MPI_Datatype datatype=14 (MPI_DOUBLE)
int source=1
int tag=1001
MPI_Comm comm=6 (user-defined-comm)
MPI_Request request=[2]
MPI_Irecv returning at walltime 59684.193829258, cputime 5.265245560 seconds in thread 0.
MPI_Send entering at walltime 59684.193830658, cputime 5.265246970 seconds in thread 0.
int count=388
MPI_Datatype datatype=14 (MPI_DOUBLE)
int dest=1
int tag=1001
MPI_Comm comm=6 (user-defined-comm)
MPI_Send returning at walltime 59684.193831550, cputime 5.265247866 seconds in thread 0.
MPI_Wait entering at walltime 59684.193832698, cputime 5.265249003 seconds in thread 0.
MPI_Request request=[2]
MPI_Status status=[{bytes=1568, cancelled=0, source=1, tag=1001, error=1}]
MPI_Wait returning at walltime 59684.193833889, cputime 5.265250193 seconds in thread 0.
MPI_Irecv entering at walltime 59684.194138884, cputime 5.265555006 seconds in thread 0.
#+END_EXAMPLE

#+BEGIN_EXAMPLE
int address=-1014243776
MPI_Address returning at walltime 59684.354258600, cputime 5.425630894 seconds in thread 0.
MPI_Address entering at walltime 59684.354259540, cputime 5.425631843 seconds in thread 0.
int address=-1014162368
MPI_Address returning at walltime 59684.354259971, cputime 5.425632266 seconds in thread 0.
MPI_Address entering at walltime 59684.354260905, cputime 5.425633215 seconds in thread 0.
int address=-1014080960
MPI_Address returning at walltime 59684.354261328, cputime 5.425633619 seconds in thread 0.
MPI_Address entering at walltime 59684.354262258, cputime 5.425634561 seconds in thread 0.
int address=-1013999552
MPI_Address returning at walltime 59684.354262686, cputime 5.425634975 seconds in thread 0.
MPI_Address entering at walltime 59684.354263635, cputime 5.425635936 seconds in thread 0.
int address=-1013918144
MPI_Address returning at walltime 59684.354264054, cputime 5.425636343 seconds in thread 0.
MPI_Address entering at walltime 59684.354264893, cputime 5.425637232 seconds in thread 0.
int address=-1013836736
MPI_Address returning at walltime 59684.354265287, cputime 5.425637586 seconds in thread 0.
MPI_Address entering at walltime 59684.354266224, cputime 5.425638522 seconds in thread 0.
int address=-1013755328
MPI_Address returning at walltime 59684.354266644, cputime 5.425638946 seconds in thread 0.
MPI_Address entering at walltime 59684.354267566, cputime 5.425639865 seconds in thread 0.
int address=-1013673920
MPI_Address returning at walltime 59684.354267982, cputime 5.425640277 seconds in thread 0.
MPI_Address entering at walltime 59684.354268905, cputime 5.425641211 seconds in thread 0.
int address=-1013592512
MPI_Address returning at walltime 59684.354269316, cputime 5.425641609 seconds in thread 0.
MPI_Address entering at walltime 59684.354270244, cputime 5.425642549 seconds in thread 0.
int address=-1013511104
MPI_Address returning at walltime 59684.354270661, cputime 5.425642955 seconds in thread 0.
MPI_Address entering at walltime 59684.354271595, cputime 5.425643892 seconds in thread 0.
int address=-1013429696
MPI_Address returning at walltime 59684.354272026, cputime 5.425644307 seconds in thread 0.
MPI_Address entering at walltime 59684.354272967, cputime 5.425645269 seconds in thread 0.
#+END_EXAMPLE

#+BEGIN_EXAMPLE
int count=193
int lengths[193]=[9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 9984, 37057]
int indices[193]=[0, 0, 81408, 0, 162816, 0, 244224, 0, 325632, 0, 407040, 0, 488448, 0, 569856, 0, 651264, 0, 732672, 0, 814080, 0, 895488, 0, 976896, 0, 1058304, 0, 1139712, 0, 1221120, 0, 1302528, 0, 1383936, 0, 1465344, 0, 1546752, 0, 1628160, 0, 1709568, 0, 1790976, 0, 1872384, 0, 1953792, 0, 2035200, 0, 2116608, 0, 2198016, 0, 2279424, 0, 2360832, 0, 2442240, 0, 2523648, 0, 2605056, 0, 2686464, 0, 2767872, 0, 2849280, 0, 2930688, 0, 3012096, 0, 3093504, 0, 3174912, 0, 3256320, 0, 3337728, 0, 3419136, 0, 3500544, 0, 3581952, 0, 3663360, 0, 3744768, 0, 3826176, 0, 3907584, 0, 3988992, 0, 4070400, 0, 4151808, 0, 4233216, 0, 4314624, 0, 4396032, 0, 4477440, 0, 4558848, 0, 4640256, 0, 4721664, 0, 4803072, 0, 4884480, 0, 4965888, 0, 5047296, 0, 5128704, 0, 5210112, 0, 5291520, 0, 5372928, 0, 5454336, 0, 5535744, 0, 5617152, 0, 5698560, 0, 5779968, 0, 5861376, 0, 5942784, 0, 6024192, 0, 6105600, 0, 6187008, 0, 6268416, 0, 6349824, 0, 6431232, 0, 6512640, 0, 6594048, 0, 6675456, 0, 6756864, 0, 6838272, 0, 6919680, 0, 7001088, 0, 7082496, 0, 7163904, 0, 7245312, 0, 7326720, 0, 7408128, 0, 7489536, 0, 7570944, 0, 7652352, 0, 7733760, 0, 7815168]
MPI_Datatype oldtypes[193]=[14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]
MPI_Datatype newtype=28 (user-defined-datatype)
MPI_Type_struct returning at walltime 59684.354384131, cputime 5.425756419 seconds in thread 0.
MPI_Type_commit entering at walltime 59684.354408868, cputime 5.425781148 seconds in thread 0.
MPI_Datatype datatype=28 (user-defined-datatype)
MPI_Type_commit returning at walltime 59684.354423395, cputime 5.425795676 seconds in thread 0.
MPI_Send entering at walltime 59684.354425047, cputime 5.425797351 seconds in thread 0.
#+END_EXAMPLE

***** Binaire
On dispose du format binaire si on veut faire autre chose (doc)
#+BEGIN_EXAMPLE
/**
\page traceformat The DUMPI trace file format

The results of a DUMPI profiling run consists of 
- One ASCII metafile (briefly described in section METAFILE) for the
  entire run, and
- One binary trace file for each node (described in section TRACEFILE
  and subsections T0 through T8).


METAFILE

The metafile is a simple key/value ASCII file that is intended to be
human-readable and to facilitate grouping related trace files
together.


TRACEFILE

Each trace file consists of a 64-bit lead-in magic number and 8 data
records.  Only the lead-in magic and the index record (record T.8) are
positional.  The former occupies the first 8 bytes of the file and the
latter it occupies the last few bytes of the file (the exact number of bytes
is, unfortunately, dependent on the actual DUMPI version -- 
see section T8 for details).

T.0:  Lead-in magic:  The trace file starts with the 8-byte sequence
      {0xff, 0xaa, 0xdd, 'D', 'U', 'M', 'P', 'I'}

T.1:  The actual profiled calls
      - The stream starts with two 32-bit values representing the time
        bias (in seconds) for CPU and wall time, respectively.	  
      - Immediately following the time biases, is the time-ordered
        stream of profiled calls.
        Each profiled call has the following structure:
          1) A 16-bit index identifying the profiled call (defined in
             common/funclabels.h).  The value DUMPI_END_OF_STREAM
	     terminates the stream.
	  2) An 8-bit mask defining what optional fields are output on
             the stream (masks defined in common/settings.h).
	     Currently, the following masks are used:
	       - DUMPI_ENABLE_STATUS_MASK (for historical reasons, this
      	         mask occupies the two lowest order bits).  Specifies
                 that MPI_Status information is stored for this call.
	       - DUMPI_CPUTIME_MASK (value (1<<2)).  Specifies that
                 cpu time information (high resolution timers) is
                 stored for both function entry and exit.  See section
                 TIMEINFO for more information.
	       - DUMPI_WALLTIME_MASK (value (1<<3)).  Specifies that
	         wall time information is stored for function entry
                 and exit.  See subsection TIMEINFO.
	       - DUMPI_THREADID_MASK (value (1<<6)).  Specifies that
                 a 16-bit integer thread identifier is stored for the
      		 call.  See subsection THREADINFO.
	       - DUMPI_PERFINFO_MASK (value (1<<7)).  Specifies that
  	         performance counter information is stored.  See section
    		 PERFINFO.
	  3) Timer information.  Note that all time information is
      	     biased by subtracting the number of seconds at the start
      	     of simulation from the stored values.  Time values are
  	     stored as uint16_t for seconds and uint32_t for
             nanoseconds.  Time biases are stored at the beginning of
	     the stream.
	     a) If DUMPI_CPUTIME_MASK was enabled, CPU time is here.
 	     b) if DUMPI_WALLTIME_MASK was enabled, wall time is here.
	  4) Performance counter information
	     If DUMPI_PERFINFO_MASK was enabled, PAPI performance
	     counters are stored for the call.  The format for the
	     perfcounter information is:
	       - An 8-bit value indicating the number of active
	         perfcounters (let's call this 'perfcount').
	       - 'perfcount' pairs of two 64-bit integer values
	       	 indicating the state of each perfcounter when the
	       	 function was entered and exited.
	  5) Call arguments as defined in common/argtypes.h.  Note that
	       - Opaque MPI types (MPI_Comm, MPI_Op, etc.) are
	         hashed to zero-based integer values.  Pre-defined
		 objects (MPI_COMM_WORLD, MPI_ANY_SOURCE, etc.) are
		 mapped onto the values of the corresponding DUMPI types
		 (DUMPI_COMM_WORLD, DUMPI_ANY_SOURCE) as defined in
		 common/constants.h.
	       - Array (vector) arguments are stored as a 32-bit integer
	         representing array length followed by all elements of
		 the array.  Empty arrays and NULL array pointers are
		 both stored as the length argument 0 followed by no
		 values.
	       - Status arrays are stored as four separate arrays:
	         1) Array of int32_t for bytes sent/received
		 2) Array of int32_t for sources
		 3) Array of int8_t for 'cancelled' state flag
		 4) Array of int8_t for 'error' state flag
	       - Status arrays may be of length 0 even if
	         DUMPI_ENABLE_STATUS_MASK was active.  This is to
		 permit more compact profiles (in libdumpi, this is
		 true when the dumpi.conf file defines 'statuses' as
		 'success').

T.2:  A header record containing 
      - Version information (stored as three 8-bit values)
      - Time at the start of simulation (64-bits)
      - Hostname as reported by gethostname(2)
      - Username as reported by the LOGNAME environment variable
        or "<none>" if username is not defined.
      - Information about the network mesh dimensions (if available
        on the platform).  These include:
	   o Mesh dimension (set to zero if no mesh info is
	     available).
	   o Position of current node in mesh if available
	     (array of size mesh dimension).
	   o Size of mesh if available.  Initialized to zero
	     if mesh dimension is not zero but mesh size is not
	     available.

T.3:  A footer record containing:
      - A 64-bit magic number indicating the start of the record
        (0xf007fee7).
      - A list of 32-bit integers indicating of how many times each
        MPI call was encountered (DUMPI_ALL_FUNCTIONS entries --
        covers all MPI-2 calls).
      - A list of 32-bit integers indicating how often each call was
      	entered but not profiled (similar as above).

T.4:  A keyval record containing:
      - A 32-bit integer listing the number of key/value pairs stored.
      - A list of string pairs for each key/value entry.

T.6:  A listing of perfcounter labels.  This section may be empty, in
which case the index record points to offset 0.  Otherwise, this
section contains:
      - A 32-bit integer indicating the number of perfcounter labels.
      - A list of string names for each perfcounter.

T.7:  A listing of function names encountered in call tracing.  This
section may be empty, in which case the index record points to offset
0.  Otherwise, this section contains:
	- A 32-bit integer indicating the number of function
	  address/name pairs stored.
	- A list of paired 64-bit integers / string names for each
	function encountered.  If a name is not available for one or
	more function names, the name gets stored as "<none>".

T.8: An index record that lists the offsets into records T.1-7.  This
record is always the last record in the file.  This index record is a
not ideal (should probably be replaced with a set of named
sections), but currently consists of:
      - (last 64 bits): offset of keyval section
      - (preceding that): offset of footer section
      - (preceding that): offset of body (stream) section
      - (preceding that): offset of header section
      - (preceding that): offset of percounter labels OR header magic
        ({0xff, 0xaa, 0xdd, 'D', 'U', 'M', 'P', 'I'}) if this trace
	file precedes the addition of perfcounter labels.
      - (preceding that if perfcounter labels were included): offset
        of function names OR header magic if this trace file precedes
        the addition of perfcounter labels.
      - (preceding that if function names were included):  header
      	magic (eventually new sections might be prepended here).

*/
#+END_EXAMPLE

***** TODO OTF2

**** Tentative replay exemple sur CODES

CODES a l'air de pouvoir utiliser des trace *ScalaTrace* pour les
rejouer (cf =./model-net-dumpi-traces-dump --help= ). Je sais pas si
c'est mieux que DUMPI.

Via le fichier =README_traces.txt=, dans le dossier
CODES/src/network-worloads, ce [[http://portal.nersc.gov/project/CAL/designforward.ht][lien]] ainsi que ce [[https://xgitlab.cels.anl.gov/codes/codes/blob/c4cba873cf9d5621dd1115a01e1982c8d0e8b31e/src/models/mpi-trace-replay/conf/modelnet-mpi-test-dragonfly.conf][fichier]] j'ai réussi à
faire tourner l'exemple ci dessous (trace dumpi sur CODES).

#+BEGIN_EXAMPLE
./model-net-mpi-replay --sync=1 --num_net_traces=216 --workload_file=/home/chevamax/Documents/Stage_LIG_2017/logiciels/test/df_AMG_n216_dumpi/dumpi-2014.03.03.14.55.23- --workload_type="dumpi" --lp-io-dir=amg-216-trace --lp-io-use-suffix=1 -- ../../src/network-workloads/conf/modelnet-mpi-test-dfly-amg-216.conf
#+END_EXAMPLE

La commande ci-dessus me donne la sortie suivante :

#+BEGIN_EXAMPLE
Tue May 23 11:12:28 2017

ROSS Revision: 4c6a7d8eb9c784797d900edfc76725d62ec25941

tw_net_start: Found world size to be 1 

 Total nodes 1056 routers 264 groups 33 radix 16 

ROSS Core Configuration: 
	Total Nodes                                                  1
	Total Processors                                   [Nodes (1) x PE_per_Node (1)] 1
	Total KPs                                          [Nodes (1) x KPs (16)] 16
	Total LPs                                                 2376
	Simulation End Time                                300000000000.00
	LP-to-PE Mapping                                   model defined


ROSS Event Memory Allocation:
	Model events                                            608257
	Network events                                           50000
	Total events                                            658256

 *** START SEQUENTIAL SIMULATION ***

 *** END SIMULATION ***


 LP 0 unmatched irecvs 0 unmatched sends 0 Total sends 478 receives 478 collectives 0 delays 1218 wait alls 56 waits 0 send time 612826.428503 wait 14669328.061635
 LP 1 unmatched irecvs 0 unmatched sends 0 Total sends 832 receives 832 collectives 0 delays 1930 wait alls 60 waits 0 send time 1018385.000731 wait 64370657.327652
 LP 2 unmatched irecvs 0 unmatched sends 0 Total sends 566 receives 566 collectives 0 delays 1398 wait alls 60 waits 0 send time 750754.503860 wait 72563845.789648
 LP 3 unmatched irecvs 0 unmatched sends 0 Total sends 840 receives 840 collectives 0 delays 1946 wait alls 60 waits 0 send time 1047815.519626 wait 157051216.933560
 LP 9 unmatched irecvs 0 unmatched sends 0 Total sends 464 receives 464 collectives 0 delays 1184 wait alls 50 waits 0 send time 647397.328881 wait 66705324.503492
 LP 10 unmatched irecvs 0 unmatched sends 0 Total sends 386 receives 386 collectives 0 delays 1034 wait alls 56 waits 0 send time 503242.249048 wait 66246441.900921
 LP 11 unmatched irecvs 0 unmatched sends 0 Total sends 654 receives 654 collectives 0 delays 1574 wait alls 60 waits 0 send time 846491.070120 wait 117358929.038023
 LP 12 unmatched irecvs 0 unmatched sends 0 Total sends 790 receives 790 collectives 0 delays 1846 wait alls 60 waits 0 send time 1041571.325534 wait 70288613.070390
 LP 18 unmatched irecvs 0 unmatched sends 0 Total sends 1194 receives 1194 collectives 0 delays 2654 wait alls 60 waits 0 send time 1470155.471660 wait 68216556.238328
 LP 19 unmatched irecvs 0 unmatched sends 0 Total sends 1010 receives 1010 collectives 0 delays 2286 wait alls 60 waits 0 send time 1264102.027885 wait 66450400.852029
 LP 20 unmatched irecvs 0 unmatched sends 0 Total sends 956 receives 956 collectives 0 delays 2178 wait alls 60 waits 0 send time 1205111.164923 wait 59633424.426049
 LP 21 unmatched irecvs 0 unmatched sends 0 Total sends 528 receives 528 collectives 0 delays 1318 wait alls 56 waits 0 send time 723458.275000 wait 117875229.796452
 LP 27 unmatched irecvs 0 unmatched sends 0 Total sends 1026 receives 1026 collectives 0 delays 2324 wait alls 66 waits 0 send time 1235379.351462 wait 74247344.022784
 LP 28 unmatched irecvs 0 unmatched sends 0 Total sends 1004 receives 1004 collectives 0 delays 2274 wait alls 60 waits 0 send time 1255522.120947 wait 118504878.250013
 LP 29 unmatched irecvs 0 unmatched sends 0 Total sends 1066 receives 1066 collectives 0 delays 2398 wait alls 60 waits 0 send time 1336751.450998 wait 63630925.617630
 LP 30 unmatched irecvs 0 unmatched sends 0 Total sends 1042 receives 1042 collectives 0 delays 2356 wait alls 66 waits 0 send time 1303271.469921 wait 116979946.393221
 LP 36 unmatched irecvs 0 unmatched sends 0 Total sends 978 receives 978 collectives 0 delays 2222 wait alls 60 waits 0 send time 1264630.386888 wait 60750187.906107
 LP 37 unmatched irecvs 0 unmatched sends 0 Total sends 628 receives 628 collectives 0 delays 1522 wait alls 60 waits 0 send time 816591.158841 wait 159049402.123190
 LP 38 unmatched irecvs 0 unmatched sends 0 Total sends 756 receives 756 collectives 0 delays 1778 wait alls 60 waits 0 send time 962886.542565 wait 62828381.096530
 LP 39 unmatched irecvs 0 unmatched sends 0 Total sends 1224 receives 1224 collectives 0 delays 2714 wait alls 60 waits 0 send time 1516243.201509 wait 117957528.505235
 LP 45 unmatched irecvs 0 unmatched sends 0 Total sends 1058 receives 1058 collectives 0 delays 2382 wait alls 60 waits 0 send time 1320910.147259 wait 60146490.080305
 LP 46 unmatched irecvs 0 unmatched sends 0 Total sends 708 receives 708 collectives 0 delays 1672 wait alls 50 waits 0 send time 967492.464439 wait 158523458.934212
 LP 47 unmatched irecvs 0 unmatched sends 0 Total sends 1132 receives 1132 collectives 0 delays 2530 wait alls 60 waits 0 send time 1397302.027431 wait 74069915.010258
 LP 48 unmatched irecvs 0 unmatched sends 0 Total sends 740 receives 740 collectives 0 delays 1746 wait alls 60 waits 0 send time 928590.332869 wait 65232701.431432
 LP 54 unmatched irecvs 0 unmatched sends 0 Total sends 664 receives 664 collectives 0 delays 1594 wait alls 60 waits 0 send time 848973.949047 wait 36345958.118133
 LP 55 unmatched irecvs 0 unmatched sends 0 Total sends 674 receives 674 collectives 0 delays 1604 wait alls 50 waits 0 send time 938229.478640 wait 125516971.862382
 LP 56 unmatched irecvs 0 unmatched sends 0 Total sends 1028 receives 1028 collectives 0 delays 2328 wait alls 66 waits 0 send time 1267561.482412 wait 117911981.356183
 LP 57 unmatched irecvs 0 unmatched sends 0 Total sends 1236 receives 1236 collectives 0 delays 2744 wait alls 66 waits 0 send time 1504637.069302 wait 50347396.693650
 LP 63 unmatched irecvs 0 unmatched sends 0 Total sends 878 receives 878 collectives 0 delays 2022 wait alls 60 waits 0 send time 1146823.708011 wait 123363217.866624
 LP 64 unmatched irecvs 0 unmatched sends 0 Total sends 690 receives 690 collectives 0 delays 1646 wait alls 60 waits 0 send time 879885.796478 wait 227372017.567977
 LP 65 unmatched irecvs 0 unmatched sends 0 Total sends 646 receives 646 collectives 0 delays 1558 wait alls 60 waits 0 send time 774507.757742 wait 71956122.051773
 LP 66 unmatched irecvs 0 unmatched sends 0 Total sends 768 receives 768 collectives 0 delays 1798 wait alls 56 waits 0 send time 950385.223462 wait 158583089.307583
 LP 72 unmatched irecvs 0 unmatched sends 0 Total sends 670 receives 670 collectives 0 delays 1606 wait alls 60 waits 0 send time 849275.876803 wait 121573968.425720
 LP 73 unmatched irecvs 0 unmatched sends 0 Total sends 794 receives 794 collectives 0 delays 1854 wait alls 60 waits 0 send time 967002.342169 wait 226746422.904084
 LP 74 unmatched irecvs 0 unmatched sends 0 Total sends 676 receives 676 collectives 0 delays 1618 wait alls 60 waits 0 send time 853497.663715 wait 73897714.895026
 LP 75 unmatched irecvs 0 unmatched sends 0 Total sends 516 receives 516 collectives 0 delays 1294 wait alls 56 waits 0 send time 641329.482212 wait 184735895.207342
 LP 81 unmatched irecvs 0 unmatched sends 0 Total sends 650 receives 650 collectives 0 delays 1562 wait alls 56 waits 0 send time 858544.351669 wait 223511975.760137
 LP 82 unmatched irecvs 0 unmatched sends 0 Total sends 1008 receives 1008 collectives 0 delays 2282 wait alls 60 waits 0 send time 1287474.151241 wait 74911528.900648
 LP 83 unmatched irecvs 0 unmatched sends 0 Total sends 886 receives 886 collectives 0 delays 2038 wait alls 60 waits 0 send time 1173980.655245 wait 186291322.476267
 LP 84 unmatched irecvs 0 unmatched sends 0 Total sends 726 receives 726 collectives 0 delays 1708 wait alls 50 waits 0 send time 1006582.941256 wait 180308323.805768
 LP 90 unmatched irecvs 0 unmatched sends 0 Total sends 1080 receives 1080 collectives 0 delays 2432 wait alls 66 waits 0 send time 1358841.625623 wait 114358120.575814
 LP 91 unmatched irecvs 0 unmatched sends 0 Total sends 804 receives 804 collectives 0 delays 1874 wait alls 60 waits 0 send time 1009827.313515 wait 225479612.621467
 LP 92 unmatched irecvs 0 unmatched sends 0 Total sends 996 receives 996 collectives 0 delays 2258 wait alls 60 waits 0 send time 1292993.186195 wait 159080981.001880
 LP 93 unmatched irecvs 0 unmatched sends 0 Total sends 1044 receives 1044 collectives 0 delays 2344 wait alls 50 waits 0 send time 1409568.727912 wait 123803484.427334
 LP 99 unmatched irecvs 0 unmatched sends 0 Total sends 1010 receives 1010 collectives 0 delays 2276 wait alls 50 waits 0 send time 1392107.978241 wait 72580169.316250
 LP 100 unmatched irecvs 0 unmatched sends 0 Total sends 1952 receives 1952 collectives 0 delays 4182 wait alls 72 waits 0 send time 2346398.054515 wait 223514663.875979
 LP 101 unmatched irecvs 0 unmatched sends 0 Total sends 998 receives 998 collectives 0 delays 2252 wait alls 50 waits 0 send time 1362987.743583 wait 178904814.966390
 LP 102 unmatched irecvs 0 unmatched sends 0 Total sends 1016 receives 1016 collectives 0 delays 2298 wait alls 60 waits 0 send time 1296163.307307 wait 159821204.649910
 LP 108 unmatched irecvs 0 unmatched sends 0 Total sends 858 receives 858 collectives 0 delays 1982 wait alls 60 waits 0 send time 1098585.436320 wait 61204099.545769
 LP 109 unmatched irecvs 0 unmatched sends 0 Total sends 1852 receives 1852 collectives 0 delays 3980 wait alls 70 waits 0 send time 2231130.888345 wait 239282149.488297
 LP 110 unmatched irecvs 0 unmatched sends 0 Total sends 1036 receives 1036 collectives 0 delays 2328 wait alls 50 waits 0 send time 1417221.694278 wait 231406965.247936
 LP 111 unmatched irecvs 0 unmatched sends 0 Total sends 1096 receives 1096 collectives 0 delays 2448 wait alls 50 waits 0 send time 1469905.820924 wait 242108030.842040
 LP 117 unmatched irecvs 0 unmatched sends 0 Total sends 1508 receives 1508 collectives 0 delays 3282 wait alls 60 waits 0 send time 1893400.232530 wait 227244561.724871
 LP 118 unmatched irecvs 0 unmatched sends 0 Total sends 704 receives 704 collectives 0 delays 1664 wait alls 50 waits 0 send time 987026.752725 wait 182374233.768544
 LP 119 unmatched irecvs 0 unmatched sends 0 Total sends 708 receives 708 collectives 0 delays 1672 wait alls 50 waits 0 send time 980978.812301 wait 13967711.361794
 LP 120 unmatched irecvs 0 unmatched sends 0 Total sends 1344 receives 1344 collectives 0 delays 2954 wait alls 60 waits 0 send time 1720179.012817 wait 35015531.040038
 LP 126 unmatched irecvs 0 unmatched sends 0 Total sends 1614 receives 1614 collectives 0 delays 3494 wait alls 60 waits 0 send time 2023971.208713 wait 182946647.373766
 LP 127 unmatched irecvs 0 unmatched sends 0 Total sends 1642 receives 1642 collectives 0 delays 3550 wait alls 60 waits 0 send time 2015590.811251 wait 184289237.361690
 LP 128 unmatched irecvs 0 unmatched sends 0 Total sends 1346 receives 1346 collectives 0 delays 2958 wait alls 60 waits 0 send time 1700357.502209 wait 243228804.840325
 LP 129 unmatched irecvs 0 unmatched sends 0 Total sends 1214 receives 1214 collectives 0 delays 2694 wait alls 60 waits 0 send time 1518689.918331 wait 179953424.617609
 LP 135 unmatched irecvs 0 unmatched sends 0 Total sends 926 receives 926 collectives 0 delays 2118 wait alls 60 waits 0 send time 1246349.675652 wait 237034450.909029
 LP 136 unmatched irecvs 0 unmatched sends 0 Total sends 954 receives 954 collectives 0 delays 2164 wait alls 50 waits 0 send time 1352503.447149 wait 235505287.971080
 LP 137 unmatched irecvs 0 unmatched sends 0 Total sends 1460 receives 1460 collectives 0 delays 3196 wait alls 70 waits 0 send time 1852326.853503 wait 236632839.250267
 LP 138 unmatched irecvs 0 unmatched sends 0 Total sends 1066 receives 1066 collectives 0 delays 2388 wait alls 50 waits 0 send time 1409283.182707 wait 235555608.684319
 LP 144 unmatched irecvs 0 unmatched sends 0 Total sends 1752 receives 1752 collectives 0 delays 3776 wait alls 66 waits 0 send time 2130807.570266 wait 225930646.267494
 LP 145 unmatched irecvs 0 unmatched sends 0 Total sends 1130 receives 1130 collectives 0 delays 2532 wait alls 66 waits 0 send time 1388729.942234 wait 242848402.532029
 LP 146 unmatched irecvs 0 unmatched sends 0 Total sends 718 receives 718 collectives 0 delays 1698 wait alls 56 waits 0 send time 930406.156660 wait 229788144.347419
 LP 147 unmatched irecvs 0 unmatched sends 0 Total sends 670 receives 670 collectives 0 delays 1596 wait alls 50 waits 0 send time 945853.904861 wait 234202698.028066
 LP 153 unmatched irecvs 0 unmatched sends 0 Total sends 1562 receives 1562 collectives 0 delays 3396 wait alls 66 waits 0 send time 1893068.247829 wait 44977957.049517
 LP 154 unmatched irecvs 0 unmatched sends 0 Total sends 780 receives 780 collectives 0 delays 1826 wait alls 60 waits 0 send time 1038846.624604 wait 228435021.601487
 LP 155 unmatched irecvs 0 unmatched sends 0 Total sends 884 receives 884 collectives 0 delays 2034 wait alls 60 waits 0 send time 1153261.695121 wait 242093904.982951
 LP 156 unmatched irecvs 0 unmatched sends 0 Total sends 704 receives 704 collectives 0 delays 1674 wait alls 60 waits 0 send time 883647.081994 wait 226714793.456252
 LP 162 unmatched irecvs 0 unmatched sends 0 Total sends 848 receives 848 collectives 0 delays 1968 wait alls 66 waits 0 send time 1056655.404335 wait 157175170.273683
 LP 163 unmatched irecvs 0 unmatched sends 0 Total sends 1212 receives 1212 collectives 0 delays 2696 wait alls 66 waits 0 send time 1473940.846421 wait 28336559.684429
 LP 164 unmatched irecvs 0 unmatched sends 0 Total sends 1194 receives 1194 collectives 0 delays 2660 wait alls 66 waits 0 send time 1440356.469666 wait 151749253.578270
 LP 165 unmatched irecvs 0 unmatched sends 0 Total sends 682 receives 682 collectives 0 delays 1620 wait alls 50 waits 0 send time 955091.139227 wait 161779088.065750
 LP 171 unmatched irecvs 0 unmatched sends 0 Total sends 944 receives 944 collectives 0 delays 2154 wait alls 60 waits 0 send time 1221491.539740 wait 43063209.056568
 LP 172 unmatched irecvs 0 unmatched sends 0 Total sends 602 receives 602 collectives 0 delays 1470 wait alls 60 waits 0 send time 784025.269904 wait 233804447.033664
 LP 173 unmatched irecvs 0 unmatched sends 0 Total sends 942 receives 942 collectives 0 delays 2150 wait alls 60 waits 0 send time 1229456.029328 wait 50172193.310056
 LP 174 unmatched irecvs 0 unmatched sends 0 Total sends 968 receives 968 collectives 0 delays 2192 wait alls 50 waits 0 send time 1319939.372680 wait 227463054.419840
 LP 180 unmatched irecvs 0 unmatched sends 0 Total sends 1024 receives 1024 collectives 0 delays 2304 wait alls 50 waits 0 send time 1400669.257240 wait 55674515.977710
 LP 181 unmatched irecvs 0 unmatched sends 0 Total sends 1454 receives 1454 collectives 0 delays 3174 wait alls 60 waits 0 send time 1816148.078225 wait 181507834.768630
 LP 182 unmatched irecvs 0 unmatched sends 0 Total sends 1544 receives 1544 collectives 0 delays 3354 wait alls 60 waits 0 send time 1911634.255754 wait 224604363.142339
 LP 183 unmatched irecvs 0 unmatched sends 0 Total sends 1078 receives 1078 collectives 0 delays 2422 wait alls 60 waits 0 send time 1309799.522605 wait 230384066.827760
 LP 189 unmatched irecvs 0 unmatched sends 0 Total sends 1054 receives 1054 collectives 0 delays 2374 wait alls 60 waits 0 send time 1362222.775894 wait 189425317.992194
 LP 190 unmatched irecvs 0 unmatched sends 0 Total sends 1702 receives 1702 collectives 0 delays 3670 wait alls 60 waits 0 send time 2070140.487704 wait 117181727.419880
 LP 191 unmatched irecvs 0 unmatched sends 0 Total sends 1096 receives 1096 collectives 0 delays 2448 wait alls 50 waits 0 send time 1452532.883894 wait 224114053.684710
 LP 192 unmatched irecvs 0 unmatched sends 0 Total sends 1548 receives 1548 collectives 0 delays 3362 wait alls 60 waits 0 send time 1914415.247092 wait 227210177.590556
 LP 198 unmatched irecvs 0 unmatched sends 0 Total sends 1014 receives 1014 collectives 0 delays 2284 wait alls 50 waits 0 send time 1393252.678999 wait 220299486.476730
 LP 199 unmatched irecvs 0 unmatched sends 0 Total sends 1390 receives 1390 collectives 0 delays 3056 wait alls 70 waits 0 send time 1669083.321960 wait 241003019.512698
 LP 200 unmatched irecvs 0 unmatched sends 0 Total sends 1628 receives 1628 collectives 0 delays 3534 wait alls 72 waits 0 send time 1969004.464915 wait 185460021.241456
 LP 201 unmatched irecvs 0 unmatched sends 0 Total sends 1666 receives 1666 collectives 0 delays 3598 wait alls 60 waits 0 send time 2080485.562014 wait 227932490.141174
 LP 207 unmatched irecvs 0 unmatched sends 0 Total sends 1722 receives 1722 collectives 0 delays 3710 wait alls 60 waits 0 send time 2139705.407085 wait 176512745.363789
 LP 208 unmatched irecvs 0 unmatched sends 0 Total sends 1458 receives 1458 collectives 0 delays 3182 wait alls 60 waits 0 send time 1843616.685628 wait 189486438.128715
 LP 209 unmatched irecvs 0 unmatched sends 0 Total sends 1538 receives 1538 collectives 0 delays 3342 wait alls 60 waits 0 send time 1918725.054495 wait 239318145.981069
 LP 210 unmatched irecvs 0 unmatched sends 0 Total sends 740 receives 740 collectives 0 delays 1736 wait alls 50 waits 0 send time 1016436.312454 wait 231850048.656625
 LP 216 unmatched irecvs 0 unmatched sends 0 Total sends 992 receives 992 collectives 0 delays 2250 wait alls 60 waits 0 send time 1267154.230789 wait 177495309.095000
 LP 217 unmatched irecvs 0 unmatched sends 0 Total sends 1456 receives 1456 collectives 0 delays 3178 wait alls 60 waits 0 send time 1821569.537089 wait 116792071.752879
 LP 218 unmatched irecvs 0 unmatched sends 0 Total sends 1050 receives 1050 collectives 0 delays 2356 wait alls 50 waits 0 send time 1436108.782684 wait 37291272.684969
 LP 219 unmatched irecvs 0 unmatched sends 0 Total sends 1584 receives 1584 collectives 0 delays 3434 wait alls 60 waits 0 send time 1973944.999668 wait 49904082.837897
 LP 225 unmatched irecvs 0 unmatched sends 0 Total sends 1012 receives 1012 collectives 0 delays 2280 wait alls 50 waits 0 send time 1388698.228261 wait 126694818.180600
 LP 226 unmatched irecvs 0 unmatched sends 0 Total sends 1028 receives 1028 collectives 0 delays 2322 wait alls 60 waits 0 send time 1320794.752760 wait 118546753.671267
 LP 227 unmatched irecvs 0 unmatched sends 0 Total sends 822 receives 822 collectives 0 delays 1910 wait alls 60 waits 0 send time 1043424.735314 wait 163767703.897466
 LP 228 unmatched irecvs 0 unmatched sends 0 Total sends 724 receives 724 collectives 0 delays 1704 wait alls 50 waits 0 send time 1019108.346654 wait 120293854.572289
 LP 234 unmatched irecvs 0 unmatched sends 0 Total sends 1170 receives 1170 collectives 0 delays 2606 wait alls 60 waits 0 send time 1477524.275769 wait 163838276.502195
 LP 235 unmatched irecvs 0 unmatched sends 0 Total sends 1080 receives 1080 collectives 0 delays 2426 wait alls 60 waits 0 send time 1362518.229356 wait 72469903.266244
 LP 236 unmatched irecvs 0 unmatched sends 0 Total sends 1034 receives 1034 collectives 0 delays 2340 wait alls 66 waits 0 send time 1305745.383152 wait 181265556.555207
 LP 237 unmatched irecvs 0 unmatched sends 0 Total sends 736 receives 736 collectives 0 delays 1738 wait alls 60 waits 0 send time 930078.205976 wait 124599280.836448
 LP 243 unmatched irecvs 0 unmatched sends 0 Total sends 748 receives 748 collectives 0 delays 1762 wait alls 60 waits 0 send time 944942.837639 wait 226684255.961120
 LP 244 unmatched irecvs 0 unmatched sends 0 Total sends 1266 receives 1266 collectives 0 delays 2798 wait alls 60 waits 0 send time 1559772.421147 wait 224068310.261899
 LP 245 unmatched irecvs 0 unmatched sends 0 Total sends 882 receives 882 collectives 0 delays 2030 wait alls 60 waits 0 send time 1171132.628482 wait 59646838.696376
 LP 246 unmatched irecvs 0 unmatched sends 0 Total sends 884 receives 884 collectives 0 delays 2034 wait alls 60 waits 0 send time 1169541.450742 wait 230349262.080623
 LP 252 unmatched irecvs 0 unmatched sends 0 Total sends 1132 receives 1132 collectives 0 delays 2530 wait alls 60 waits 0 send time 1419571.729277 wait 117445327.827391
 LP 253 unmatched irecvs 0 unmatched sends 0 Total sends 496 receives 496 collectives 0 delays 1248 wait alls 50 waits 0 send time 697422.312509 wait 51882411.210824
 LP 254 unmatched irecvs 0 unmatched sends 0 Total sends 668 receives 668 collectives 0 delays 1592 wait alls 50 waits 0 send time 897448.488961 wait 220915271.187779
 LP 255 unmatched irecvs 0 unmatched sends 0 Total sends 1482 receives 1482 collectives 0 delays 3230 wait alls 60 waits 0 send time 1843559.665634 wait 125682220.057065
 LP 261 unmatched irecvs 0 unmatched sends 0 Total sends 1732 receives 1732 collectives 0 delays 3730 wait alls 60 waits 0 send time 2055488.948681 wait 171337339.221986
 LP 262 unmatched irecvs 0 unmatched sends 0 Total sends 2020 receives 2020 collectives 0 delays 4316 wait alls 70 waits 0 send time 2390286.865081 wait 179397186.992181
 LP 263 unmatched irecvs 0 unmatched sends 0 Total sends 1038 receives 1038 collectives 0 delays 2332 wait alls 50 waits 0 send time 1400244.520539 wait 78380897.412120
 LP 264 unmatched irecvs 0 unmatched sends 0 Total sends 854 receives 854 collectives 0 delays 1974 wait alls 60 waits 0 send time 1130986.389140 wait 185598053.656403
 LP 270 unmatched irecvs 0 unmatched sends 0 Total sends 1318 receives 1318 collectives 0 delays 2912 wait alls 70 waits 0 send time 1605993.188225 wait 183441365.822489
 LP 271 unmatched irecvs 0 unmatched sends 0 Total sends 1494 receives 1494 collectives 0 delays 3254 wait alls 60 waits 0 send time 1853253.940284 wait 237731108.339606
 LP 272 unmatched irecvs 0 unmatched sends 0 Total sends 1114 receives 1114 collectives 0 delays 2484 wait alls 50 waits 0 send time 1506073.121325 wait 187989091.856423
 LP 273 unmatched irecvs 0 unmatched sends 0 Total sends 1504 receives 1504 collectives 0 delays 3274 wait alls 60 waits 0 send time 1925987.933597 wait 186961890.194399
 LP 279 unmatched irecvs 0 unmatched sends 0 Total sends 1284 receives 1284 collectives 0 delays 2834 wait alls 60 waits 0 send time 1699702.868855 wait 41587294.618191
 LP 280 unmatched irecvs 0 unmatched sends 0 Total sends 962 receives 962 collectives 0 delays 2190 wait alls 60 waits 0 send time 1268313.802547 wait 56179800.029834
 LP 281 unmatched irecvs 0 unmatched sends 0 Total sends 772 receives 772 collectives 0 delays 1800 wait alls 50 waits 0 send time 1045713.702199 wait 242366453.174915
 LP 282 unmatched irecvs 0 unmatched sends 0 Total sends 1444 receives 1444 collectives 0 delays 3154 wait alls 60 waits 0 send time 1827816.130192 wait 239838693.289420
 LP 288 unmatched irecvs 0 unmatched sends 0 Total sends 1086 receives 1086 collectives 0 delays 2428 wait alls 50 waits 0 send time 1495648.511026 wait 242109938.601502
 LP 289 unmatched irecvs 0 unmatched sends 0 Total sends 1474 receives 1474 collectives 0 delays 3214 wait alls 60 waits 0 send time 1866654.582048 wait 239148605.136481
 LP 290 unmatched irecvs 0 unmatched sends 0 Total sends 1666 receives 1666 collectives 0 delays 3598 wait alls 60 waits 0 send time 2074126.473026 wait 231683272.233514
 LP 291 unmatched irecvs 0 unmatched sends 0 Total sends 1270 receives 1270 collectives 0 delays 2806 wait alls 60 waits 0 send time 1570096.533302 wait 229041214.090651
 LP 297 unmatched irecvs 0 unmatched sends 0 Total sends 1168 receives 1168 collectives 0 delays 2602 wait alls 60 waits 0 send time 1478174.260760 wait 228006413.133874
 LP 298 unmatched irecvs 0 unmatched sends 0 Total sends 1854 receives 1854 collectives 0 delays 3984 wait alls 70 waits 0 send time 2235385.680993 wait 54407837.495879
 LP 299 unmatched irecvs 0 unmatched sends 0 Total sends 1530 receives 1530 collectives 0 delays 3326 wait alls 60 waits 0 send time 1918623.175208 wait 43435109.217533
 LP 300 unmatched irecvs 0 unmatched sends 0 Total sends 1688 receives 1688 collectives 0 delays 3642 wait alls 60 waits 0 send time 2073585.683253 wait 180443386.817762
 LP 306 unmatched irecvs 0 unmatched sends 0 Total sends 1006 receives 1006 collectives 0 delays 2268 wait alls 50 waits 0 send time 1369678.066230 wait 234827300.894513
 LP 307 unmatched irecvs 0 unmatched sends 0 Total sends 1182 receives 1182 collectives 0 delays 2630 wait alls 60 waits 0 send time 1453872.587879 wait 225128096.688900
 LP 308 unmatched irecvs 0 unmatched sends 0 Total sends 774 receives 774 collectives 0 delays 1814 wait alls 60 waits 0 send time 986412.539371 wait 238588346.901442
 LP 309 unmatched irecvs 0 unmatched sends 0 Total sends 1064 receives 1064 collectives 0 delays 2394 wait alls 60 waits 0 send time 1368119.135462 wait 230947991.556343
 LP 315 unmatched irecvs 0 unmatched sends 0 Total sends 676 receives 676 collectives 0 delays 1608 wait alls 50 waits 0 send time 925767.213918 wait 229314849.631709
 LP 316 unmatched irecvs 0 unmatched sends 0 Total sends 1082 receives 1082 collectives 0 delays 2430 wait alls 60 waits 0 send time 1359575.569396 wait 241533502.538067
 LP 317 unmatched irecvs 0 unmatched sends 0 Total sends 958 receives 958 collectives 0 delays 2182 wait alls 60 waits 0 send time 1216238.557433 wait 235232023.804240
 LP 318 unmatched irecvs 0 unmatched sends 0 Total sends 544 receives 544 collectives 0 delays 1350 wait alls 56 waits 0 send time 728295.820487 wait 241818960.780068
 LP 324 unmatched irecvs 0 unmatched sends 0 Total sends 942 receives 942 collectives 0 delays 2156 wait alls 66 waits 0 send time 1140182.089447 wait 47864710.306853
 LP 325 unmatched irecvs 0 unmatched sends 0 Total sends 754 receives 754 collectives 0 delays 1774 wait alls 60 waits 0 send time 1023713.128732 wait 239851624.351898
 LP 326 unmatched irecvs 0 unmatched sends 0 Total sends 1178 receives 1178 collectives 0 delays 2622 wait alls 60 waits 0 send time 1446818.706926 wait 227632766.612120
 LP 327 unmatched irecvs 0 unmatched sends 0 Total sends 682 receives 682 collectives 0 delays 1620 wait alls 50 waits 0 send time 948953.171935 wait 238425191.492895
 LP 333 unmatched irecvs 0 unmatched sends 0 Total sends 930 receives 930 collectives 0 delays 2126 wait alls 60 waits 0 send time 1197751.448529 wait 235173176.706286
 LP 334 unmatched irecvs 0 unmatched sends 0 Total sends 748 receives 748 collectives 0 delays 1762 wait alls 60 waits 0 send time 921654.263274 wait 227369786.169390
 LP 335 unmatched irecvs 0 unmatched sends 0 Total sends 904 receives 904 collectives 0 delays 2074 wait alls 60 waits 0 send time 1175455.369354 wait 239444069.426787
 LP 336 unmatched irecvs 0 unmatched sends 0 Total sends 1574 receives 1574 collectives 0 delays 3420 wait alls 66 waits 0 send time 1909375.763095 wait 240876821.702868
 LP 342 unmatched irecvs 0 unmatched sends 0 Total sends 1064 receives 1064 collectives 0 delays 2384 wait alls 50 waits 0 send time 1431078.085745 wait 239582472.113191
 LP 343 unmatched irecvs 0 unmatched sends 0 Total sends 1022 receives 1022 collectives 0 delays 2300 wait alls 50 waits 0 send time 1392639.599693 wait 54306997.881879
 LP 344 unmatched irecvs 0 unmatched sends 0 Total sends 1392 receives 1392 collectives 0 delays 3050 wait alls 60 waits 0 send time 1762868.547964 wait 237377876.573738
 LP 345 unmatched irecvs 0 unmatched sends 0 Total sends 732 receives 732 collectives 0 delays 1720 wait alls 50 waits 0 send time 1009808.307314 wait 229509575.923357
 LP 351 unmatched irecvs 0 unmatched sends 0 Total sends 1096 receives 1096 collectives 0 delays 2458 wait alls 60 waits 0 send time 1395358.000737 wait 239002588.009873
 LP 352 unmatched irecvs 0 unmatched sends 0 Total sends 1082 receives 1082 collectives 0 delays 2420 wait alls 50 waits 0 send time 1468959.213742 wait 238612525.266457
 LP 353 unmatched irecvs 0 unmatched sends 0 Total sends 1540 receives 1540 collectives 0 delays 3346 wait alls 60 waits 0 send time 1910908.953035 wait 236151256.616066
 LP 354 unmatched irecvs 0 unmatched sends 0 Total sends 1070 receives 1070 collectives 0 delays 2396 wait alls 50 waits 0 send time 1460741.955959 wait 244232512.426837
 LP 360 unmatched irecvs 0 unmatched sends 0 Total sends 1070 receives 1070 collectives 0 delays 2396 wait alls 50 waits 0 send time 1439992.987388 wait 232491468.639140
 LP 361 unmatched irecvs 0 unmatched sends 0 Total sends 1002 receives 1002 collectives 0 delays 2270 wait alls 60 waits 0 send time 1268899.691438 wait 234563596.485585
 LP 362 unmatched irecvs 0 unmatched sends 0 Total sends 736 receives 736 collectives 0 delays 1728 wait alls 50 waits 0 send time 1047246.540606 wait 226312200.080464
 LP 363 unmatched irecvs 0 unmatched sends 0 Total sends 972 receives 972 collectives 0 delays 2200 wait alls 50 waits 0 send time 1346636.251382 wait 234003752.808560
 LP 369 unmatched irecvs 0 unmatched sends 0 Total sends 1762 receives 1762 collectives 0 delays 3790 wait alls 60 waits 0 send time 2158949.638434 wait 240479668.726626
 LP 370 unmatched irecvs 0 unmatched sends 0 Total sends 1684 receives 1684 collectives 0 delays 3634 wait alls 60 waits 0 send time 2045615.450660 wait 233456691.814360
 LP 371 unmatched irecvs 0 unmatched sends 0 Total sends 1410 receives 1410 collectives 0 delays 3086 wait alls 60 waits 0 send time 1793352.499286 wait 239029658.233294
 LP 372 unmatched irecvs 0 unmatched sends 0 Total sends 948 receives 948 collectives 0 delays 2162 wait alls 60 waits 0 send time 1232901.018381 wait 236571751.867198
 LP 378 unmatched irecvs 0 unmatched sends 0 Total sends 954 receives 954 collectives 0 delays 2174 wait alls 60 waits 0 send time 1252010.787490 wait 28872020.499920
 LP 379 unmatched irecvs 0 unmatched sends 0 Total sends 1270 receives 1270 collectives 0 delays 2806 wait alls 60 waits 0 send time 1627886.750878 wait 223550083.236020
 LP 380 unmatched irecvs 0 unmatched sends 0 Total sends 1506 receives 1506 collectives 0 delays 3278 wait alls 60 waits 0 send time 1877065.936016 wait 44484845.249219
 LP 381 unmatched irecvs 0 unmatched sends 0 Total sends 980 receives 980 collectives 0 delays 2216 wait alls 50 waits 0 send time 1347203.572137 wait 37974722.570828
 LP 387 unmatched irecvs 0 unmatched sends 0 Total sends 1702 receives 1702 collectives 0 delays 3676 wait alls 66 waits 0 send time 2071769.522280 wait 120930600.863587
 LP 388 unmatched irecvs 0 unmatched sends 0 Total sends 846 receives 846 collectives 0 delays 1958 wait alls 60 waits 0 send time 1121676.269522 wait 236390395.372274
 LP 389 unmatched irecvs 0 unmatched sends 0 Total sends 644 receives 644 collectives 0 delays 1554 wait alls 60 waits 0 send time 849074.614689 wait 239583967.466475
 LP 390 unmatched irecvs 0 unmatched sends 0 Total sends 898 receives 898 collectives 0 delays 2062 wait alls 60 waits 0 send time 1194248.256042 wait 77551255.308577
 LP 396 unmatched irecvs 0 unmatched sends 0 Total sends 1394 receives 1394 collectives 0 delays 3066 wait alls 72 waits 0 send time 1680447.482774 wait 181954755.003045
 LP 397 unmatched irecvs 0 unmatched sends 0 Total sends 1448 receives 1448 collectives 0 delays 3168 wait alls 66 waits 0 send time 1730700.253292 wait 179452043.558964
 LP 398 unmatched irecvs 0 unmatched sends 0 Total sends 1090 receives 1090 collectives 0 delays 2446 wait alls 60 waits 0 send time 1362520.825888 wait 184339756.060921
 LP 399 unmatched irecvs 0 unmatched sends 0 Total sends 964 receives 964 collectives 0 delays 2194 wait alls 60 waits 0 send time 1163915.966380 wait 226976312.408118
 LP 405 unmatched irecvs 0 unmatched sends 0 Total sends 654 receives 654 collectives 0 delays 1574 wait alls 60 waits 0 send time 785996.187805 wait 235819906.841401
 LP 406 unmatched irecvs 0 unmatched sends 0 Total sends 654 receives 654 collectives 0 delays 1570 wait alls 56 waits 0 send time 842502.145936 wait 182925092.226000
 LP 407 unmatched irecvs 0 unmatched sends 0 Total sends 734 receives 734 collectives 0 delays 1730 wait alls 56 waits 0 send time 924714.183380 wait 188442299.926165
 LP 408 unmatched irecvs 0 unmatched sends 0 Total sends 1032 receives 1032 collectives 0 delays 2340 wait alls 70 waits 0 send time 1235125.968845 wait 161082373.801387
 LP 414 unmatched irecvs 0 unmatched sends 0 Total sends 778 receives 778 collectives 0 delays 1828 wait alls 66 waits 0 send time 972096.350793 wait 231361833.270194
 LP 415 unmatched irecvs 0 unmatched sends 0 Total sends 726 receives 726 collectives 0 delays 1724 wait alls 66 waits 0 send time 840037.942789 wait 161424164.007532
 LP 416 unmatched irecvs 0 unmatched sends 0 Total sends 784 receives 784 collectives 0 delays 1836 wait alls 62 waits 0 send time 991389.414077 wait 182640364.070923
 LP 417 unmatched irecvs 0 unmatched sends 0 Total sends 1380 receives 1380 collectives 0 delays 3036 wait alls 70 waits 0 send time 1648899.118545 wait 233117396.568241
 LP 423 unmatched irecvs 0 unmatched sends 0 Total sends 690 receives 690 collectives 0 delays 1636 wait alls 50 waits 0 send time 973248.559611 wait 162699136.436757
 LP 424 unmatched irecvs 0 unmatched sends 0 Total sends 682 receives 682 collectives 0 delays 1620 wait alls 50 waits 0 send time 955682.437545 wait 230925787.404967
 LP 425 unmatched irecvs 0 unmatched sends 0 Total sends 1206 receives 1206 collectives 0 delays 2678 wait alls 60 waits 0 send time 1487774.469349 wait 228363345.677702
 LP 426 unmatched irecvs 0 unmatched sends 0 Total sends 728 receives 728 collectives 0 delays 1722 wait alls 60 waits 0 send time 912367.151058 wait 229756244.240830
 LP 432 unmatched irecvs 0 unmatched sends 0 Total sends 722 receives 722 collectives 0 delays 1710 wait alls 60 waits 0 send time 911450.421544 wait 40130943.189459
 LP 433 unmatched irecvs 0 unmatched sends 0 Total sends 1064 receives 1064 collectives 0 delays 2394 wait alls 60 waits 0 send time 1361151.609776 wait 74152714.250620
 LP 434 unmatched irecvs 0 unmatched sends 0 Total sends 972 receives 972 collectives 0 delays 2210 wait alls 60 waits 0 send time 1252078.728616 wait 227835027.875529
 LP 435 unmatched irecvs 0 unmatched sends 0 Total sends 1156 receives 1156 collectives 0 delays 2578 wait alls 60 waits 0 send time 1447239.062585 wait 228657241.661385
 LP 441 unmatched irecvs 0 unmatched sends 0 Total sends 788 receives 788 collectives 0 delays 1842 wait alls 60 waits 0 send time 1062313.289631 wait 237410160.582239
 LP 442 unmatched irecvs 0 unmatched sends 0 Total sends 884 receives 884 collectives 0 delays 2034 wait alls 60 waits 0 send time 1089451.411746 wait 121658383.355642
 LP 443 unmatched irecvs 0 unmatched sends 0 Total sends 950 receives 950 collectives 0 delays 2166 wait alls 60 waits 0 send time 1155609.993471 wait 164773488.395418
 LP 444 unmatched irecvs 0 unmatched sends 0 Total sends 1086 receives 1086 collectives 0 delays 2438 wait alls 60 waits 0 send time 1362374.449758 wait 161352193.949322
 LP 450 unmatched irecvs 0 unmatched sends 0 Total sends 1188 receives 1188 collectives 0 delays 2652 wait alls 70 waits 0 send time 1477398.179498 wait 120814719.110398
 LP 451 unmatched irecvs 0 unmatched sends 0 Total sends 1102 receives 1102 collectives 0 delays 2470 wait alls 60 waits 0 send time 1351933.540047 wait 120456427.367757
 LP 452 unmatched irecvs 0 unmatched sends 0 Total sends 1612 receives 1612 collectives 0 delays 3502 wait alls 72 waits 0 send time 1880752.859434 wait 226689385.494537
 LP 453 unmatched irecvs 0 unmatched sends 0 Total sends 694 receives 694 collectives 0 delays 1654 wait alls 60 waits 0 send time 878190.189927 wait 119678148.347902
 LP 459 unmatched irecvs 0 unmatched sends 0 Total sends 934 receives 934 collectives 0 delays 2140 wait alls 66 waits 0 send time 1122283.617665 wait 124098407.652423
 LP 460 unmatched irecvs 0 unmatched sends 0 Total sends 896 receives 896 collectives 0 delays 2058 wait alls 60 waits 0 send time 1150567.877600 wait 187384767.985001
 LP 461 unmatched irecvs 0 unmatched sends 0 Total sends 1174 receives 1174 collectives 0 delays 2614 wait alls 60 waits 0 send time 1423410.518199 wait 183216359.475160
 LP 462 unmatched irecvs 0 unmatched sends 0 Total sends 804 receives 804 collectives 0 delays 1874 wait alls 60 waits 0 send time 1074091.749002 wait 77431811.628409
 LP 468 unmatched irecvs 0 unmatched sends 0 Total sends 970 receives 970 collectives 0 delays 2206 wait alls 60 waits 0 send time 1211009.781027 wait 117800903.942812
 LP 469 unmatched irecvs 0 unmatched sends 0 Total sends 606 receives 606 collectives 0 delays 1478 wait alls 60 waits 0 send time 809266.469347 wait 231986628.903106
 LP 470 unmatched irecvs 0 unmatched sends 0 Total sends 464 receives 464 collectives 0 delays 1190 wait alls 56 waits 0 send time 584690.327968 wait 162310616.991503
 LP 471 unmatched irecvs 0 unmatched sends 0 Total sends 736 receives 736 collectives 0 delays 1744 wait alls 66 waits 0 send time 940218.685630 wait 186896575.091691
 LP 477 unmatched irecvs 0 unmatched sends 0 Total sends 866 receives 866 collectives 0 delays 1998 wait alls 60 waits 0 send time 1009355.984707 wait 48347050.325136
 LP 478 unmatched irecvs 0 unmatched sends 0 Total sends 776 receives 776 collectives 0 delays 1818 wait alls 60 waits 0 send time 934262.453814 wait 237456164.552619
 LP 479 unmatched irecvs 0 unmatched sends 0 Total sends 576 receives 576 collectives 0 delays 1418 wait alls 60 waits 0 send time 751647.854004 wait 235302036.020718
 LP 480 unmatched irecvs 0 unmatched sends 0 Total sends 468 receives 468 collectives 0 delays 1198 wait alls 56 waits 0 send time 572385.313953 wait 226989333.384371
	: Running Time = 10.3426 seconds

TW Library Statistics:
	Total Events Processed                                11540841
	Events Aborted (part of RBs)                                 0
	Events Rolled Back                                           0
	Event Ties Detected in PE Queues                             0
	Efficiency                                              100.00 %
	Total Remote (shared mem) Events Processed                   0
	Percent Remote Events                                     0.00 %
	Total Remote (network) Events Processed                      0
	Percent Remote Events                                     0.00 %

	Total Roll Backs                                             0
	Primary Roll Backs                                           0
	Secondary Roll Backs                                         0
	Fossil Collect Attempts                                      0
	Total GVT Computations                                       0

	Net Events Processed                                  11540841
	Event Rate (events/sec)                              1115858.1
	Total Events Scheduled Past End Time                         0

TW Memory Statistics:
	Events Allocated                                        658257
	Memory Allocated                                        469247
	Memory Wasted                                               28

TW Data Structure sizes in bytes (sizeof):
	PE struct                                                  608
	KP struct                                                  144
	LP struct                                                  128
	LP Model struct                                             64
	LP RNGs                                                     80
	Total LP                                                   272
	Event struct                                               144
	Event struct with Model                                    720

TW Clock Cycle Statistics (MAX values in secs at 1.0000 GHz):
	Priority Queue (enq/deq)                                0.0000
	AVL Tree (insert/delete)                                0.0000
	LZ4 (de)compression                                     0.0000
	Buddy system                                            0.0000
	Event Processing                                        0.0000
	Event Cancel                                            0.0000
	Event Abort                                             0.0000

	GVT                                                     0.0000
	Fossil Collect                                          0.0000
	Primary Rollbacks                                       0.0000
	Network Read                                            0.0000
	Statistics Computation                                  0.0000
	Statistics Write                                        0.0000
	Total Time (Note: Using Running Time above for Speedup)     24.7646

TW GVT Statistics: MPI AllReduce
	GVT Interval                                                16
	GVT Real Time Interval (cycles)                    0
	GVT Real Time Interval (sec)                        0.00000000
	Batch Size                                                  16

	Forced GVT                                                   0
	Total GVT Computations                                       0
	Total All Reduce Calls                                       0
	Average Reduction / GVT                                   -nan

 Total bytes sent 136925280 recvd 136925280 
 max runtime 832428174.181527 ns avg runtime 831592158.607247 
 max comm time 244256041.446027 avg comm time 165598826.375765 
 max send time 2390286.865081 avg send time 1321096.933746 
 max recv time 1242807411.964691 avg recv time 491966904.633888 
 max wait time 244232512.426837 avg wait time 165575909.276246 
LP-IO: writing output to amg-216-trace-11281-1495530749/
LP-IO: data files:
   amg-216-trace-11281-1495530749/dragonfly-router-traffic
   amg-216-trace-11281-1495530749/dragonfly-router-stats
   amg-216-trace-11281-1495530749/dragonfly-msg-stats
   amg-216-trace-11281-1495530749/model-net-category-all
   amg-216-trace-11281-1495530749/model-net-category-test
   amg-216-trace-11281-1495530749/mpi-replay-stats
 Average number of hops traversed 3.033524 average chunk latency 1.896739 us maximum chunk latency 17.016149 us avg message size 610.249207 bytes finished messages 224376 finished chunks 702636 

 ADAPTIVE ROUTING STATS: 574306 chunks routed minimally 128330 chunks routed non-minimally completed packets 702636 

 Total packets generated 449894 finished 449894
 
 #+END_EXAMPLE

Je sais pas trop si ca a fonctionné, mais plusieurs fichiers ont été
créé.
#+BEGIN_EXAMPLE
-rw-r--r-- 1 chevamax chevamax        0 mai   23 11:12 dragonfly-cn-sampling-0.bin
-rw-r--r-- 1 chevamax chevamax      245 mai   23 11:12 dragonfly-cn-sampling.meta
-rw-r--r-- 1 chevamax chevamax        0 mai   23 11:12 dragonfly-router-sampling-0.bin
-rw-r--r-- 1 chevamax chevamax      356 mai   23 11:12 dragonfly-router-sampling.meta
-rw-r--r-- 1 chevamax chevamax        0 mai   23 11:12 mpi-aggregate-logs-0.bin
-rw-r--r-- 1 chevamax chevamax 15605566 mai   23 11:12 mpi-op-logs
-rw-r--r-- 1 chevamax chevamax        0 mai   23 11:12 mpi-workload-meta-log
-rw-r--r-- 1 chevamax chevamax      991 mai   23 11:12 ross.csv
#+END_EXAMPLE

**** Tentative replay HPL sur CODES
Il faut maintenant que je trouve comment faire le fichier .conf pour
qu'il corresponde à ma machine.

D'après les informations obtenues avec la commande dumpistats ci
dessous, mes noeuds ont communiqué 2 à 2 (pour la configuration à
4). A 16, c'est différent.
#+BEGIN_EXAMPLE
dumpistats --bin'begin+10 to end-10' -x all -i dumpi-2017.05.22.11.02.24.meta -o statsT
#+END_EXAMPLE

Utilisation d'une configuration de base :
#+BEGIN_EXAMPLE
LPGROUPS
{
   MODELNET_GRP
   {
      repetitions="1";
      modelnet_simplenet="1";
      nw-lp="4";
   }
}
PARAMS
{
   packet_size="512";
   message_size="784";
   modelnet_order=( "simplenet" );
   # scheduler options
   modelnet_scheduler="fcfs";
   net_startup_ns="1.5";
   net_bw_mbps="20000";
}
#+END_EXAMPLE

en tentant avec ca :

#+begin_src sh :results output :exports both
./model-net-mpi-replay --sync=1 --num_net_traces=1 --workload_file=/home/chevamax/Documents/Stage_LIG_2017/simulation/hpl/4/dumpi-2017.05.22.11.02.24- --workload_type="dumpi" --lp-io-dir=hpl-trace --lp-io-use-suffix=1 -- /home/chevamax/Documents/Stage_LIG_2017/logiciels/CODES/src/network-workloads/conf/modelnet-mpi-test-hpl.conf
#+end_src

#+RESULTS:
#+BEGIN_EXAMPLE
Tue May 23 14:50:03 2017

ROSS Revision: 4c6a7d8eb9c784797d900edfc76725d62ec25941

tw_net_start: Found world size to be 1 

ROSS Core Configuration: 
	Total Nodes                                                  1
	Total Processors                                   [Nodes (1) x PE_per_Node (1)] 1
	Total KPs                                          [Nodes (1) x KPs (16)] 16
	Total LPs                                                    5
	Simulation End Time                                300000000000.00
	LP-to-PE Mapping                                   model defined


ROSS Event Memory Allocation:
	Model events                                              1281
	Network events                                           50000
	Total events                                             51280


 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type 
 Undefined data type *** START SEQUENTIAL SIMULATION ***

 *** END SIMULATION ***


 LP 1 unmatched irecvs 1 unmatched sends 0 Total sends 0 receives 1 collectives 0 delays 7 wait alls 0 waits 0 send time 0.000000 wait 0.000000
	: Running Time = 0.0000 seconds

TW Library Statistics:
	Total Events Processed                                       8
	Events Aborted (part of RBs)                                 0
	Events Rolled Back                                           0
	Event Ties Detected in PE Queues                             0
	Efficiency                                              100.00 %
	Total Remote (shared mem) Events Processed                   0
	Percent Remote Events                                     0.00 %
	Total Remote (network) Events Processed                      0
	Percent Remote Events                                     0.00 %

	Total Roll Backs                                             0
	Primary Roll Backs                                           0
	Secondary Roll Backs                                         0
	Fossil Collect Attempts                                      0
	Total GVT Computations                                       0

	Net Events Processed                                         8
	Event Rate (events/sec)                               307692.3
	Total Events Scheduled Past End Time                         0

TW Memory Statistics:
	Events Allocated                                         51281
	Memory Allocated                                         51168
	Memory Wasted                                              720

TW Data Structure sizes in bytes (sizeof):
	PE struct                                                  608
	KP struct                                                  144
	LP struct                                                  128
	LP Model struct                                            760
	LP RNGs                                                     80
	Total LP                                                   968
	Event struct                                               144
	Event struct with Model                                    928

TW Clock Cycle Statistics (MAX values in secs at 1.0000 GHz):
	Priority Queue (enq/deq)                                0.0000
	AVL Tree (insert/delete)                                0.0000
	LZ4 (de)compression                                     0.0000
	Buddy system                                            0.0000
	Event Processing                                        0.0000
	Event Cancel                                            0.0000
	Event Abort                                             0.0000

	GVT                                                     0.0000
	Fossil Collect                                          0.0000
	Primary Rollbacks                                       0.0000
	Network Read                                            0.0000
	Statistics Computation                                  0.0000
	Statistics Write                                        0.0000
	Total Time (Note: Using Running Time above for Speedup)      0.0001

TW GVT Statistics: MPI AllReduce
	GVT Interval                                                16
	GVT Real Time Interval (cycles)                    0
	GVT Real Time Interval (sec)                        0.00000000
	Batch Size                                                  16

	Forced GVT                                                   0
	Total GVT Computations                                       0
	Total All Reduce Calls                                       0
	Average Reduction / GVT                                   -nan

 Total bytes sent 0 recvd 4 
 max runtime 0.000000 ns avg runtime 0.000000 
 max comm time 0.000000 avg comm time -66232.000000 
 max send time 0.000000 avg send time 0.000000 
 max recv time 0.000000 avg recv time 0.000000 
 max wait time 0.000000 avg wait time 0.000000 
LP-IO: writing output to hpl-trace-25282-1495543803/
LP-IO: data files:
   hpl-trace-25282-1495543803/mpi-replay-stats
   hpl-trace-25282-1495543803/model-net-category-all
#+END_EXAMPLE

Ca à pas l'air de fonctionner...


Topologie de ma machine pour les experiences HPL (4/16 noeuds)
.conf Réalisation d'un .conf correct (via documentation)
dumpi: Y a t'il un soucis avec ma configuration DUMPI, qui a des
soucis avec les versions récentes de MPICH. (Utilisation de OpenMPI ?)

code source AMG : peut permettre d'aider en le compilant et
l'executant sur ma machine pour faire des traces.


**** WAITING Mail CODES
Pour avoir plus d'information 
