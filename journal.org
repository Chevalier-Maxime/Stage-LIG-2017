# -*- mode: org -*-
# -*- coding: utf-8 -*-
#+STARTUP: overview indent inlineimages logdrawer
#+TITLE:       Journal de bord
#+AUTHOR:      Maxime Chevalier 
#+LANGUAGE:    fr
#+TAGS: LIG(L) SimGrid(S) PSI3(P) CODES(C) ROSS(O) Space(A) Time(T)
#+TAGS: R(R) OrgMode(M)
#+EXPORT_SELECT_TAGS: Blog
#+OPTIONS:   H:3 num:t toc:t \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+OPTIONS:   TeX:t LaTeX:nil skip:nil d:nil todo:t pri:nil tags:not-in-toc
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+COLUMNS: %25ITEM %TODO %3PRIORITY %TAGS
#+SEQ_TODO: TODO(t!) STARTED(s!) WAITING(w@) APPT(a!) | DONE(d!) CANCELLED(c!) DEFERRED(f!)

* 2016
** 2016-03 March
*** 2016-03-07 Monday
**** [[https://github.com/alegrand/RR_webinars/blob/master/1_replicable_article_laboratory_notebook/index.org][First webinar on reproducible research: litterate programming]]
***** Emacs shortcuts
Here are a few convenient emacs shortcuts for those that have never
used emacs. In all of the emacs shortcuts, =C=Ctrl=, =M=Alt/Esc= and
=S=Shift=.  Note that you may want to use two hours to follow the emacs
tutorial (=C-h t=). In the configuration file CUA keys have been
activated and allow you to use classical copy/paste (=C-c/C-v=)
shortcuts. This can be changed from the Options menu.
  - =C-x C-c= exit
  - =C-x C-s= save buffer
  - =C-g= panic mode ;) type this whenever you want to exit an awful
    series of shortcuts
  - =C-Space= start selection marker although selection with shift and
    arrows should work as well
  - =C-l= reposition the screen
  - =C-_= (or =C-z= if CUA keys have been activated)
  - =C-s= search
  - =M-%= replace
  - =C-x C-h= get the list of emacs shortcuts
  - =C-c C-h= get the list of emacs shortcuts considering the mode you are
    currently using (e.g., C, Lisp, org, ...)
  There are a bunch of cheatsheets also available out there (e.g.,
  [[http://www.shortcutworld.com/en/linux/Emacs_23.2.1.html][this one for emacs]] and [[http://orgmode.org/orgcard.txt][this one for org-mode]] or this [[http://sachachua.com/blog/wp-content/uploads/2013/05/How-to-Learn-Emacs-v2-Large.png][graphical one]]).
***** Org-mode                                                  :OrgMode:
  Many emacs shortcuts start by =C-x=. Org-mode's shortcuts generaly
  start with =C-c=.
  - =Tab= fold/unfold
  - =C-c c= capture (finish capturing with =C-c C-c=, this is explained on
    the top of the buffer that just opened)
  - =C-c C-c= do something useful here (tag, execute, ...)
  - =C-c C-o= open link
  - =C-c C-t= switch todo
  - =C-c C-e= export
  - =M-Enter= new item/section
  - =C-c a= agenda (try the =L= option)
  - =C-c C-a= attach files
  - =C-c C-d= set a deadl1ine (use =S-arrows= to navigate in the dates)
  - =A-arrows= move subtree (add shift for the whole subtree)
***** Org-mode Babel (for literate programming)                 :OrgMode:
  - =<s + tab= template for source bloc. You can easily adapt it to get this:
      : #+BEGIN_SRC sh
      : ls
      : #+END_SRC
    Now if you =C-c C-c=, it will execute the block.
    #+BEGIN_EXAMPLE
  #+RESULTS:
  | #journal.org# |
  | journal.html  |
  | journal.org   |
  | journal.org~  |
    #+END_EXAMPLE
  
  - Source blocks have many options (formatting, arguments, names,
    sessions,...), which is why I have my own shortcuts =<b + tab= bash
    block (or =B= for sessions).
    #+BEGIN_EXAMPLE 
  #+begin_src sh :results output :exports both
  ls /tmp/*201*.pdf
  #+end_src

  #+RESULTS:
  : /tmp/2015_02_bordeaux_otl_tutorial.pdf
  : /tmp/2015-ASPLOS.pdf
  : /tmp/2015-Europar-Threadmap.pdf
  : /tmp/europar2016-1.pdf
  : /tmp/europar2016.pdf
  : /tmp/M2-PDES-planning-examens-janvier2016.pdf
    #+END_EXAMPLE
  - I have defined many such templates in my configuration. You can
    give a try to =<r=, =<R=, =<RR=, =<g=, =<p=, =<P=, =<m= ...
  - Some of these templates are not specific to babel: e.g., =<h=, =<l=,
    =<L=, =<c=, =<e=, ...
***** In case you want to play with ipython on a recent debian   :Python:
Here is what you should install:
#+begin_src sh :results output :exports both
sudo apt-get install python3-pip ipython3 ipython3-notebook python3-numpy python3-matplotlib
#+end_src

The ipython notebook can then be run with the following command:
#+begin_src sh :results output :exports both
ipython3 notebook
#+end_src

The latest version of this notebook is called [[http://jupyter.org/][Jupyter]] and is polyglot
like babel. Playing with it is easy as it's deployed on the cloud but
as I'm not a python expert I'm not sure to know how to deploy it locally.
***** In case you want to play with R/knitR/rstudio:                  :R:
Here is what you should install on debian:
#+BEGIN_SRC sh
sudo apt-get install r-base r-cran-ggplot2
#+END_SRC

Rstudio and knitr are unfortunately not packaged within debian so the
easiest is to download the corresponding debian package on the [[http://www.rstudio.com/ide/download/desktop][Rstudio
webpage]] and then to install it manually (depending on when you do
this, you can obviously change the version number).
#+BEGIN_SRC sh
wget https://download1.rstudio.org/rstudio-0.99.887-amd64.deb
sudo dpkg -i rstudio-0.99.887-amd64.deb
sudo apt-get -f install # to fix possibly missing dependencies
#+END_SRC
You will also need to install knitr. To this end, you should simply
run R (or Rstudio) and use the following command.
#+BEGIN_SRC R
install.packages("knitr")
#+END_SRC
If =r-cran-ggplot2= could not be installed for some reason, you can also
install it through R by doing:
#+BEGIN_SRC R
install.packages("ggplot2")
#+END_SRC

As you will experience, knitr is polyglot but not Rstudio, which
makes its use not as fluid when using other languages than R.
* 2017
** 2017-05 mai
*** 2017-05-09 mardi
**** DONE Lecture papiers [3/3]                                   :ATTACH:
:PROPERTIES:
:Attachments: PDS_fujimoto2015.pdf
:ID:       a3acf95b-21d5-4621-a955-41bab99b38f6
:END:
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-05-11 jeu. 15:12]
- State "TODO"       from "TODO"       [2017-05-11 jeu. 14:56]
- State "TODO"       from "TODO"       [2017-05-11 jeu. 11:23]
- State "TODO"       from "TODO"       [2017-05-11 jeu. 11:03]
- State "TODO"       from "TODO"       [2017-05-11 jeu. 09:53]
- State "TODO"       from "TODO"       [2017-05-10 mer. 17:23]
- State "TODO"       from "TODO"       [2017-05-10 mer. 16:06]
- State "TODO"       from "TODO"       [2017-05-10 mer. 16:04]
- State "TODO"       from "TODO"       [2017-05-10 mer. 16:04]
- State "TODO"       from "TODO"       [2017-05-10 mer. 16:04]
- State "TODO"       from "TODO"       [2017-05-10 mer. 16:03]
- State "TODO"       from "TODO"       [2017-05-10 mer. 15:56]
- State "TODO"       from "TODO"       [2017-05-10 mer. 15:32]
- State "TODO"       from "TODO"       [2017-05-10 mer. 15:27]
- State "TODO"       from "TODO"       [2017-05-10 mer. 15:15]
- State "TODO"       from "TODO"       [2017-05-10 mer. 15:11]
- State "TODO"       from "TODO"       [2017-05-10 mer. 15:11]
- State "TODO"       from "TODO"       [2017-05-10 mer. 15:11]
- State "TODO"       from "TODO"       [2017-05-10 mer. 15:11]
- State "TODO"       from "TODO"       [2017-05-10 mer. 14:39]
- State "TODO"       from "TODO"       [2017-05-10 mer. 13:56]
- State "TODO"       from "TODO"       [2017-05-10 mer. 13:48]
- State "TODO"       from "TODO"       [2017-05-10 mer. 13:48]
- State "TODO"       from "TODO"       [2017-05-10 mer. 13:48]
- State "TODO"       from "TODO"       [2017-05-10 mer. 13:13]
- State "TODO"       from "TODO"       [2017-05-10 mer. 11:06]
- State "TODO"       from "TODO"       [2017-05-10 mer. 11:06]
- State "TODO"       from "TODO"       [2017-05-10 mer. 10:40]
- State "TODO"       from "TODO"       [2017-05-10 mer. 10:38]
- State "TODO"       from "TODO"       [2017-05-10 mer. 10:35]
- State "TODO"       from "TODO"       [2017-05-10 mer. 10:35]
- State "TODO"       from "TODO"       [2017-05-10 mer. 10:35]
- State "TODO"       from "TODO"       [2017-05-10 mer. 10:33]
- State "TODO"       from "TODO"       [2017-05-10 mer. 10:18]
- State "TODO"       from "TODO"       [2017-05-10 mer. 09:40]
- State "TODO"       from "TODO"       [2017-05-09 mar. 16:49]
- State "TODO"       from "TODO"       [2017-05-09 mar. 16:49]
- State "TODO"       from "TODO"       [2017-05-09 mar. 16:49]
- State "TODO"       from "TODO"       [2017-05-09 mar. 16:30]
- State "TODO"       from "TODO"       [2017-05-09 mar. 16:27]
- State "TODO"       from "TODO"       [2017-05-09 mar. 16:15]
- State "TODO"       from "TODO"       [2017-05-09 mar. 16:15]
- State "TODO"       from "TODO"       [2017-05-09 mar. 16:15]
- State "TODO"       from "TODO"       [2017-05-09 mar. 15:54]
- State "TODO"       from "TODO"       [2017-05-09 mar. 15:54]
- State "TODO"       from "TODO"       [2017-05-09 mar. 15:36]
- State "TODO"       from "DONE"       [2017-05-09 mar. 15:36]
- State "DONE"       from "TODO"       [2017-05-09 mar. 15:36]
- State "TODO"       from "TODO"       [2017-05-09 mar. 15:36]
- State "TODO"       from "TODO"       [2017-05-09 mar. 15:36]
- State "TODO"       from "TODO"       [2017-05-09 mar. 15:36]
- State "TODO"       from              [2017-05-09 mar. 15:12]
:END:
- [X] simulation «[[file:Papiers/Timeparallelsimulation.pdf][temps parallèle]]» (extrait du livre de
      Fujimoto, 2000)
  - *Space parallel approch* : C'est la decomposition horizontale d'un
    programme, où chaque process maintient ses variables d'état tout au long de la simulation.
    - Plus flexible, et plus applicable (dans la plupart des cas).
  - *Time parallel approch* :
    - Propriétés : Parallélisme massif, indépendance des processeurs
      logiques (moins de synchronisation)
    - Approches : comment déterminer l'état initial des process (sauf le premier process), il faut corriger la trajectoire.
      - *Fix-up computation* : Etat initial random, qui ne match presque
        jamais, donc il faut faire une correction avec une seconde
        simulation (et ca fonctionne grâce à la contraction des
        ensembles de trajectoires) prenant en état initial l'état
        final du process précédant. Et quand ca match, c'est gagné!
        Fonction le mieux lorsque l'état final ne dépend pas de l'état
        initial (2 itérations et c'est fini). Lorsque ce n'est pas le
        cas, (pire cas) il faut pour N intervals, N itérations, soit
        du sequentiel avec des ressources pour du parallèle
        (bad!). *Exemple ou ca fonctionne* cache LRU.
      - *Precomputation of state at specific time division points* : Il
        se peut que dans certains programmes on puisse déterminer des
        points spécifiques (débordement de buffer par exemple) qui
        vont arriver et donc en faire des états de départ. *Exemple* :
        buffer avec N entrées de capacité 1 et une sortie de capacité C.
        - Soit il y a overflow
        - Soit il y a underflow
        - Du coup chaque processus détermine si il part d'un
          over/under et effectue sa simulation pour X services. Quand
          il a fini, il envoie le reste de sa file d'attente au
          processus d'après qui se charge de simuler l'interval entre
          l'état d'arrêt du processus précédent, et son postulat de départ.
        - À la fin, on peut calculer le nombre de service et de perte
          en additionnant les résultats de chaque processus.
        - Cependant ca pet échouer car les processus peuvent ne pas
          atteindre l'objectif (overflow souvent car c'est très
          rare). Il est donc très difficile d'identifier les points de division.
      - *Parallel prefix computations* :
        - Utilisation de récurence car il existe de très bon
          algorithmes pour faire du calcul prefix sur des systèmes parallèles.
        - Il faut faire attention au ratio nbCalculs/nbProcesseurs. En
          effet, si ce ratio tend vers 1, il y a des pertes à cause du
          temps de communication entre les processeurs (qui est du
          temps de calcul perdu).
        - /!\ Je n'ai pas compris l'exemple de cette partie (page 9 et 10).
    - Plutôt utilisé pour développer des algo de simulation parallèle
      spécifique.
    - Permet de parralléliser des cas où le space parralélisme ne
      fonctionne pas (ou peu), comme dans les exemples.
  - Dans certain cas, il est possible de mélanger les deux approches.

- [X] Et un [[file:Papiers/PDS_fujimoto2015.pdf][autre]] Fujimoto (2015) pour avoir une vision d’ensemble sur la
      simulation parallèle (sauf sur la technique «  temps-parallèle »  qui
      n’est pas mentionnée dans cet article)
  - Lecture :
    - *PDES* : Parallel Discrete Event Simulation. But : accelerer
      l'execution des simulation. Les "pas" de simulations sont
      irrégulier. Peut être vu comme une collection d'evenements
      sequentiels discret, qui interagissent par des messages
      datés. Un PDES doit fournir les mêmes résutats que le programme
      en séquentiel (ou parfois aproximativement les mêmes). Le
      principal problèlme c'est la synchrinisation entre les
      differents processus.

    - *Simulation distribué* : concerne l'execution de simulation sur
      des machines séparé "géographiquement", où l'agrégation de
      simulation pour un environnement de simulation (*exemple*
      simulateur de vol,...). Synchronisation = time management. De
      gros efforts ont été fait pour developer des standards
      d'interconnection de simulation (DIS,HLA) qui, entre autre
      réduisent le nombre de message envoyé.

    - *Synchronisation conservative* : Permet d'avoir le même résultat
      qu'une exécution séquentielle sur un processeur monocœur. Cette
      propriété peut être montré en s'assurant que chaque processus
      logique traite les messages par leurs dates.

      - Première génération : Pour qu'il y ait du parallèlisme, il
        faut cependant que certains LP (processus logique) puissent
        prendre de l'avance. Pour cela il faut s'assurer que l'on ne
        recevera pas d'event avec un horadatage plus petit que celui
        qu'on va executer (*ALGO CMB). *Contraintes* : réseau FIFO. Tant qu'il y a
        des messages dans les buffers le LP à l'information. Si le
        buffer est vide, il doit se bloquer /!\ il peut y avoir des
        interblocages. Pour les éviter les LPs envoient des messages
        nulls qui garantissent les horodatages. Les LP ont aussi un
        *lookahead* qui defini le temps min avant l'envoie d'un autre
        message (l'horadatage du prochain evenement doit être bien
        plus grand que le temps actuel). Cependant, si il est trop petit, de nombreux messages
        inutiles peuvent être envoyé si il y a blocage (cf exemple
        fin page 4).

      - Seconde génération : Dans un premiers temps, les nouveaux algo
        ont tenté de supprimer le problème de lookahead en utilisant
        le plus petit horadatage d'event dans le système, pour passer
        directement à la suite. D'autres approche complétement
        différentes de CMB ont été tenté, avec par exemple YAWNS qui
        utilise des points globaux de synchronisation (des
        barrières). *Schéma lookahead* question : Je suis pas sûr de
        comprendre comment ca marche... *Réponse* : SimGrid ne
        fonctionne pas sur ce modèle. C'est juste dire aux autres LPs
        que le LP ne va pas envoyer de message avant T+L, et qu'ils
        peuvent donc process jusque là.

    - *Synchronisation optimiste* : Les events ne sont plus éxécutés
      strictement dans l'ordre.(*TIME WARP*)contrairement aux algorithmes
      précédents, les erreurs sont possible, mais un mécanisme de
      rollback permet de retourner dans un état sain grâce à deu
      mécanismes :

      - *Mécanisme de control local* : Si un LP recoit un event daté de
        50 et qu'il en est à 100, il va faire un rollback
        jusqu'a 50. Cependant, si il y a eu modification des variables
        d'état, ou envoie de message ca ne peut pas être annulé. Pour
        les variables d'état il est possible de les sauvegarder avant
        modification (*copy state saving*) qui a un *cout* en temps de
        copie et en mémoire) ou faire de *l'incremental state saving*
        qui sauvegarder seulement les infos qu'on a modifié mais qui
        nécessite d'avoir les adresses des variables (à
        modifier/backup). Une autre technique est le *reverse
        computation* (si un event fait +1, on fait -1) qui est la plus
        avantageuse des 3, mais ca peut de
        pas être réalisable. Pour les messages, un système anti
        message récursif a été mis au point. On r'envoie le message
        identique avec un marqueur, si il a pasété traité, il est
        supprimé de la file, sinon il y a rollback pour le LP qui
        recoit l'anti-message (et ainsi de suite, pouvant conduire à
        des rollbacks en cascade /!\)

      - *Mécanisme de contrôle global* : GVT : Pas compris. C'est un
        état global, mais j'ai pas compris comment il est utilisé/ce
        qui est sauvegardé. Mécanisme de coupe comme vu en algo
        distribué (RICM4). Ok donc GVT c'est une barrière dans le
        temps avant laquelle on ne peut pas revenir lors d'un
        rollback. Du coup, il est possible de libérer les ressources
        utilisé pour sauvegarder les états avant cette barrière.
        https://www.acm-sigsim-mskr.org/Courseware/Fujimoto/Slides/FujimotoSlides-12-ComputingGlobalVirtualTime.pdf

        - D'autres pistes sont envisagées, comme limiter dans une
          fenêtre de temps les LPs (ce qui empêche certains LP d'être
          trop en avance et de faire beaucoup de rollback). Une autre
          technique et de retarder les envoies de messages jusqu'a ce
          que ce soit garantie que l'envoie ne va pas être rollback
          plus tard.

- [X] Les outils : 
  - [X] SimGrid un simulateur d’applications parallèles 
    http://simgrid.gforge.inria.fr (présentation générale http://simgrid.gforge.inria.fr/tutorials/simgrid-101.pdf)

    - SimDag : Framework pour application parralèles. Les tâches avec
      dépendances limitent la parralèlisme. On fourni à SimDag le
      graphe des tâches et ça retourne des informations sur les
      machines qui ont fait tels taches.

    - MPI : couche d'abstracton adapté à la programation parallèle
      (partie communication).

    - SMPI : Simule des application // avec MPI. Réalise le calcul
      pour de vrais en simulant l'architecture, mais en séquentiel. LE
      but c'est pas forcément le résultat, mais plutôt de voir si
      l'algorithme fonctionne bien sur l'architecture choisie.

    - MSG : Visualisation de données

    - Fonctionne comme en RO pour simuler les architechtures.

    - Permet plusieurs approches :

      - On-line : simulation sur sa propre machine. Mais /!\ à la
        topologie logique (grille par ex) qui est ensuite mappé sur
        une topologie physique différente. SimGrid peut également
        simuler cette différence.

      - Off-line : Execution du programme sur un super-calculateur
        puis récupération des traces. Avec ces trâces, rejouer avec
        des topologies différentes. Cependant cette approche nécéssite
        d'avoir accès à un super-calculateur, mais est limité pas la
        taille initiale de la topologie (on peut difficilement
        extrapoler). De plus, pour pouvoir jouer avec les trâce sur
        des configurations différentes, il faut que le code soit
        déterministe, hors il ne l'est pas nécessairement.

  - [X] PSi3 : Perfect simulator. S'arrête à la districbution
    stationnaire /!\ coût élevé
    - [X] un simulateur [développé par Inria] contenant une version
      parallèle « à la Fujimoto/Nicol » 
      https://gforge.inria.fr/projects/psi/ dédié aux files d'attentes
      réseaux (en temps discret). Le logiciel fournis des traces
      d'éxecution qui sont ensuite utilisable pour analyse (avec R par
      exemple). Ressemble beaucoup aux TD/DM de EP (les exemples).
    - [X]  [[file:Papiers/PDS_fujimoto2015.pdf][slides de présentation ci-joints (Briot/Vincent)]] Simulation
      de chaine de Markov, et utilisation des processus de vie et de
      mort. Le nombre d'etat doit être inferieur à 10⁷ pour les
      calculs numériques. Pour les simulations le cout est
      linéaire. Le but est de générer beaucoup d'exemples grâce un
      script de simulation pour ensuite les analyser. Psi3 permet de
      faire des statistiques sur les réseaux à file finie sur des
      évènements rare : rejet, blocage, ... avec la garantie
      d'indépendance entre les traces. La simulation utilises
      plusieurs coeurs (framework OpenMP cf RICM3). Il y a plusieurs
      approches pour la simulation :
      - Space //, Time // et les deux

      - Backward simulation : chaque coeur fait une trace.

      - Forward simulation *?? question*

      - Peret la //isation des entrées sorties.
  - [X] CODES : un simulateur [développé par Argonne] un simulateur
                parallèle d’applications parallèles
                https://press3.mcs.anl.gov/codes/ basé sur le
    framework ROSS. Ce simulateur a pour but d'augmenter la
    parallélisation sur du stackage de masse et pour les applications
    qui utilisent beaucoups de données. Dans le but de tester des
    architectures Exascale qui n'existe pas encore. Ca permet de tester des
    algorithmes avec une simulation de réseau faite par ROSS et des
    simulations d'I/O modélisé par CODE. Avec ce simulateur on peut
    mettre en évidence des goulots, évaluer la tolérance aux fautes,
    la mise à l'échelle et les techniques de
    "recovery". L'architechture TORUS (architecture réseau à plusieurs
    dimmentions) a été directement ajouté dans CODES et non dans
    ROSS. On peut donc ajouter nos propres modèles. Voici en
    attachement 2 articles présentant CODES
    -[X] [[file:Papiers/P1884.pdf][1]] 
    - 4.2 - Figure 3 : pas compris les résultats de l'expérience. 
    -[X] [[file:Papiers/LiuCarothers2012.pdf][2]] Possibilité de s'inspirer de ce papier pour la démarche sur
    des études
  - [X] ROSS :  simulateur parallèle, lui-même basé sur le
                mécanisme Time Warp 
                http://carothersc.github.io/ROSS/about.html . La
    simulation est basé sur des LPs, chacun modélisant un composant du
    système. Pour communiquer, les LPs utilisent des message horodaté.
                https://github.com/carothersc/ROSS. 
                
  - [X] Time Warp : Pour Time Warp il y a l’[[file:Papiers/Jefferson87.pdf][article]] de Jefferson et
                    al. qui résume à peu près. Utilisation d'un temps
    virtuel pour la synchronisation (Jefferson, cf Cours AD
    RICM4). Principe du rollback cité plus haut. Time Warp est à la
    base un OS, car le faire au dessus d'un autre OS n'ayant pas la
    même logique doublé tous les éléments (scheduling, I/O, ...). Time
    Warp est destiné aux applications utilisant un temps logique ou un
    temps de simulation dans leur modèle. La condition FIFO n'est plus
    nécessaire même si elle est préférable. Il y a régulierement des
    sauvegarde globales du système (de type GVT je suppose).
    - Anti-message : Comme vu plus haut, mais plus détailé. Chaque
      message envoyé engendre un anti-message dans le "buffer"
      d'emission qui n'est pas envoyé. Cependant, si il y a un
      rollback, le LP reprend son exécution et à chaque envoie de
      message, il compare avec les anti-message : si il y a un même
      message anti + nouveau, les deux sont supprimé (on a déjà envoyé
      le message), si il n'y a pas correspondance, un anti-message du
      nouveau est conservé. Tous les anti-message non représenté
      durant la réexecution doivent être annulé chez les autres
      LPs. Ensuite c'est l'algo en cascade.

    - La communication entre les processus ne se fait pas via des
      pipe,... il n'est donc pas nécéssaire de déclarer quel process
      communique avec quel process. Il suffi de faire un
      send. Question : != entre QueryMessage et EventMessage

    - Structure d'un process : cf page 10

    - Les processus s'executent qu'a la réception de message et font
      le traitement, ils ne font pas de calcul en dehors. Ils peuvent
      cependant s'envoyer eux-même des messages. Les processus doivent
      être deterministe (l'execution d'une même entrée doit donner la
      même sortie pour eviter les rollback en cascade. Pour les nombre
      aléa jouer avec la seed).

    - Utilisation de beaucoup de mémoire pour le GVT et pour la
      sauvegarde des anti-messages. Si il y a plus de place, le plus
      grand message (T dans le système, le plus loin dans le futur) est désenvoyé ce qui cause un rollback quelque
      part et donc libère de la place. Le méssage sera réenvoyé plus tard.

  - [X] Slide d'Arnaud sur les infrastructures de calcul :
   http://mescal.imag.fr/membres/arnaud.legrand/blog/2015/03/25/intervention_isn-gz.pdf
    - Tentative de mélanger les calculs et les communication pour
      réduire les barrières (MUMPS)

    - Explication simple d'un calcul de pivot sur une matrice
      diagonale.



**** Réunion Maxime Chevalier, simulation parallèle
- Lu chapitre simulation time // de Fujimoto
- A lu papier sur SG, PSI, CODES/ROSS (torus)
- A commencé à intégrer les notions de simulation time //, space //,
  simulation parfaite, simulation de Monte Carlo, à évènements
  discrets (pas forcément de chaine de Markov).
- À faire:
  - Journal:
    - Créer un repos github privé et nous donner les droits
      (alegrand, fperronnin).
    - On vérifie la config org-mode
  - Simulation:
    - Installer CODES/ROSS
    - Récupérer une trace de HPL (générée "en vrai" ou avec SimGrid)
    - Rejouer cette trace au dessus de CODES en séquentiel
    - Rejouer cette trace au dessus de SimGrid (en séquentiel donc)
    - Rejouer cette trace au dessus de CODES en multi-core
    - Rejouer cette trace au dessus de CODES en distribué (MPI)
    - Puis on avise pour le time //
**** Premiers pas avec org-mode
#+begin_src sh :results output :exports both
ls /tmp/
#+end_src

#+RESULTS:
: babel-58401Ra
: babel-8460yua
: emacs8460hfp
: systemd-private-309cd01bea0a4d7cbb3d3706e339b36a-colord.service-6SHoQ5
: systemd-private-309cd01bea0a4d7cbb3d3706e339b36a-rtkit-daemon.service-DraqAW
: tracker-extract-files.1000

#+begin_src python :results output :exports both
print("Hello")
#+end_src

#+RESULTS:
: Hello

#+begin_src R :results output :session *R* :exports both
summary(cars)
#+end_src

#+BEGIN_EXAMPLE
This seminar took place on March 7, 2016. The link to the video is below. Do not forget to check the section on software installation if you want to test yourself the demoed tools.

Table of Contents
#+END_EXAMPLE

**** Réunion avec Florence et Arnaud
***** DONE Mettre en place mon cahier de laboratoire [3/3]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-05-09 mar. 15:05]
- State "TODO"       from "TODO"       [2017-05-09 mar. 15:05]
- State "TODO"       from "TODO"       [2017-05-09 mar. 13:54]
- State "TODO"       from "STARTED"    [2017-05-09 mar. 13:54]
- State "STARTED"    from "TODO"       [2017-05-09 mar. 13:52]
- State "TODO"       from              [2017-05-09 mar. 13:52]
:END:

- [X] github
- [X] org-mode
- [X] intégrer le mail

Entered on [2017-05-09 mar. 13:45]
******
*** 2017-05-11 jeudi
**** Fin des lectures
**** Installation CODES/ROSS sur ma machine
***** STARTED ROSS                                                 :ROSS:
:LOGBOOK:
- State "STARTED"    from "TODO"       [2017-05-11 jeu. 17:51]
- State "TODO"       from              [2017-05-11 jeu. 17:51]
:END:
Lien Git : https://github.com/carothersc/ROSS
Requirement  : 
- C compiler (C11 prefered but not required)
- CMake : https://cmake.org (2.8 min) -> 3.6.2
#+begin_src sh
sudo yum install cmake
#+end_src
- Implémentation MPI : MPICH recommandé -> 3.2
#+begin_src sh
sudo yum install mpich
#+end_src
Machine : Fedora 25, gcc version 6.3.1, intel core i5, 8Go de RAM
****** Tentative installation 1
Ca ne fonctionne pas en suivant les étapes du git, je supprime le
dossier et je passe par un autre tuto.
****** Tentative d'installation 2
https://github.com/carothersc/ROSS/wiki/Installation
En fait j'ai une erreur dans la configuration de cmake...
#+BEGIN_EXAMPLE
CMake Error at /usr/share/cmake/Modules/CMakeDetermineCCompiler.cmake:57 (message):
  Could not find compiler set in environment variable CC:

  mpicc.
Call Stack (most recent call first):
  CMakeLists.txt:1 (PROJECT)


CMake Error: CMAKE_C_COMPILER not set, after EnableLanguage
-- Configuring incomplete, errors occurred!
See also "/home/chevamax/Documents/ross-build/CMakeFiles/CMakeOutput.log".
#+END_EXAMPLE

(lundi 15 mai)
En fait mpich n'était pas dans mon PATH...
On retante.
Ca ne marche toujours pas, mais je viens de
trouver. https://ask.fedoraproject.org/en/question/32864/mpirun-command-not-found/
Il faut charger le module pour pouvoir l'utiliser. Du coup il faut
ajouter cette ligne au fichier de conf : 

#+BEGIN_EXAMPLE
module load mpi/mpich-x86_64 
#+END_EXAMPLE

#+begin_src
cd
gedit .bash_profile
#+end_src

J'y ai cru mais en fait non...

*** 2017-05-15 lundi
**** TODO CODES                                                    :CODES:
:LOGBOOK:
- State "TODO"       from              [2017-05-11 jeu. 17:51]
:END:
Sources : https://press3.mcs.anl.gov/codes/downloads/
Version : 0.5.2
Entered on [2017-05-15 lun. 09:34]
